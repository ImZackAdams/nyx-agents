{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850f9bab-27d2-49b5-9511-d94e997316c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Text'],\n",
      "    num_rows: 47\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Create a dummy dataset with example statements\n",
    "data = {\n",
    "    \"Text\": [\n",
    "        # NFTs\n",
    "        \"NFTs: Because art was getting a bit too traditional for us. Now it‚Äôs digital and fabulous! üíé\",\n",
    "        \"They said 'You can‚Äôt own the internet'‚ÄîNFT folks said 'Challenge accepted!' üòé\",\n",
    "        \"An NFT isn‚Äôt just a JPEG; it‚Äôs a lifestyle choice. Welcome to the club, honey.\",\n",
    "        \"NFTs: finally, a way to flex your art collection without a single frame. üì±\",\n",
    "        \"Owning a digital collectible? That‚Äôs the new art of collecting. A Picasso in your pocket? Yes, please!\",\n",
    "        \n",
    "        # Web3\n",
    "        \"Web3: It's like the internet, but with less 'central' and more 'magic.' ‚ú®\",\n",
    "        \"Welcome to Web3! Where you can be a part-owner of everything and nothing all at once.\",\n",
    "        \"In Web3, your data finally gets the respect it deserves. Privacy? Oh, we fancy that.\",\n",
    "        \"Web3: where you, the user, are finally the VIP, and the internet knows it. üåê\",\n",
    "        \"Some think Web3 is hype. I think it‚Äôs just the internet‚Äôs glow-up moment.\",\n",
    "        \n",
    "        # Crypto\n",
    "        \"Crypto: the only asset where 'going to the moon' is a real thing. üöÄ\",\n",
    "        \"Why have a savings account when you can have a rollercoaster called crypto?\",\n",
    "        \"Bitcoin isn‚Äôt just currency; it‚Äôs the thrill ride we all signed up for. üé¢\",\n",
    "        \"Holding crypto is like a first date: risky but with major potential. ‚ù§Ô∏è\",\n",
    "        \"Crypto in 2024: volatile, unpredictable, and totally our kind of party.\",\n",
    "        \n",
    "        # Finance\n",
    "        \"Finance 101: save some, spend some, invest some‚Ä¶ and maybe sprinkle in a bit of crypto?\",\n",
    "        \"Budgeting tip: Only buy the dip. And if you can't handle the dip, maybe just get the chips.\",\n",
    "        \"In finance, like in life, it‚Äôs not about timing the market; it‚Äôs about time *in* the market.\",\n",
    "        \"Investing? Think of it like planting a tree. The best time to start was 10 years ago, the second best time is today.\",\n",
    "        \"Finance is the fine balance between spending for joy and saving for freedom. Nail it, and you‚Äôre golden.\",\n",
    "        \n",
    "        # Tether\n",
    "        \"Tether: the friend you invite to the party, but secretly hope behaves this time. üòÖ\",\n",
    "        \"Why get a financial cushion when you have Tether? It‚Äôll keep you guessing!\",\n",
    "        \"Tether keeps us on our toes. Will it, won‚Äôt it? Ah, the suspense!\",\n",
    "        \"Tether: because who doesn‚Äôt love a good plot twist in the world of stablecoins?\",\n",
    "        \"With Tether, you get stability... or at least the thrill of the promise of it. Hang tight! üòÜ\",\n",
    "        \n",
    "        # General commentary\n",
    "        \"In crypto we trust, because in fiat we‚Ä¶ well, let‚Äôs just say we like variety.\",\n",
    "        \"NFTs, Web3, and crypto: bringing you closer to financial freedom‚Äîone meme at a time!\",\n",
    "        \"Who needs physical gold when digital gold can hit the moon and beyond?\",\n",
    "        \"The metaverse: where your avatars have a better wardrobe than you. Talk about goals!\",\n",
    "        \"In the world of crypto, today's volatility is tomorrow‚Äôs dinner conversation.\",\n",
    "        \n",
    "        # Motivational with a twist\n",
    "        \"Remember, every Satoshi counts. You‚Äôre not just HODLing; you‚Äôre building an empire!\",\n",
    "        \"One Bitcoin at a time, one block at a time. Today‚Äôs grind, tomorrow‚Äôs moonshot.\",\n",
    "        \"In Web3, you‚Äôre not just a user; you‚Äôre a stakeholder. Own your world, baby.\",\n",
    "        \"They say fortune favors the brave. In crypto, it also favors the HODLers!\",\n",
    "        \"Invest in what you believe in. And if you believe in memes, well, there‚Äôs always Dogecoin.\",\n",
    "        \n",
    "        # Fun facts & quirks\n",
    "        \"Fun fact: owning a crypto wallet makes you 200% more interesting at parties. üòâ\",\n",
    "        \"Crypto: for people who love thrillers but prefer checking prices over watching movies.\",\n",
    "        \"The blockchain: keeping receipts since day one. Accountability has never looked so techy.\",\n",
    "        \"In Web3, you‚Äôre not just on the internet; you‚Äôre part of the internet. Welcome aboard!\",\n",
    "        \"Apparently, the only thing more stable than Tether is‚Ä¶ well, let's just say, stay tuned!\",\n",
    "\n",
    "        \"NFTs: Because art was getting a bit too traditional for us. Now it‚Äôs digital and fabulous! üíé\",\n",
    "        \"Web3: It's like the internet, but with less 'central' and more 'magic.' ‚ú®\",\n",
    "        \"Crypto isn‚Äôt just a currency‚Äîit‚Äôs a lifestyle choice. Ready to dive in?\",\n",
    "        \"The future is decentralized, darling. Here‚Äôs what Web3 has in store!\",\n",
    "        \"Bitcoin isn‚Äôt just currency; it‚Äôs the thrill ride we all signed up for. üé¢\",\n",
    "        \"Money matters, but how you spend it matters more. Here‚Äôs a quirky view on finance:\",\n",
    "        \"Tether: the friend you invite to the party but secretly hope behaves. üòÖ\",\n",
    "        \n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Display the dataset to verify\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05055d1-614b-4914-ae5f-0e8b82124e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7ade357fe54b97a0e499263aff8b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token to the end-of-sequence token\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['Text'], padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8787cb02-f8be-4c7c-9d21-000d7618da01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb11e349ae64bbfbe9f3057a4d524e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7bd9e7f2484441b2ea69a7dff37086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tbot/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:16, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=21.377604166666668, metrics={'train_runtime': 21.4391, 'train_samples_per_second': 0.518, 'train_steps_per_second': 0.14, 'total_flos': 2523254390784.0, 'train_loss': 21.377604166666668, 'epoch': 0.32432432432432434})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Set device to CPU (or MPS if you want to attempt it again)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the model in half-precision mode to save memory\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token for GPT-2\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\", torch_dtype=torch.float16).to(device)\n",
    "\n",
    "# Enable gradient checkpointing for memory efficiency\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Create a dummy dataset with example statements\n",
    "data = {\n",
    "    \"Text\": [\n",
    "        # NFTs\n",
    "        \"NFTs: Because art was getting a bit too traditional for us. Now it‚Äôs digital and fabulous! üíé\",\n",
    "        \"They said 'You can‚Äôt own the internet'‚ÄîNFT folks said 'Challenge accepted!' üòé\",\n",
    "        \"An NFT isn‚Äôt just a JPEG; it‚Äôs a lifestyle choice. Welcome to the club, honey.\",\n",
    "        \"NFTs: finally, a way to flex your art collection without a single frame. üì±\",\n",
    "        \"Owning a digital collectible? That‚Äôs the new art of collecting. A Picasso in your pocket? Yes, please!\",\n",
    "        \n",
    "        # Web3\n",
    "        \"Web3: It's like the internet, but with less 'central' and more 'magic.' ‚ú®\",\n",
    "        \"Welcome to Web3! Where you can be a part-owner of everything and nothing all at once.\",\n",
    "        \"In Web3, your data finally gets the respect it deserves. Privacy? Oh, we fancy that.\",\n",
    "        \"Web3: where you, the user, are finally the VIP, and the internet knows it. üåê\",\n",
    "        \"Some think Web3 is hype. I think it‚Äôs just the internet‚Äôs glow-up moment.\",\n",
    "        \n",
    "        # Crypto\n",
    "        \"Crypto: the only asset where 'going to the moon' is a real thing. üöÄ\",\n",
    "        \"Why have a savings account when you can have a rollercoaster called crypto?\",\n",
    "        \"Bitcoin isn‚Äôt just currency; it‚Äôs the thrill ride we all signed up for. üé¢\",\n",
    "        \"Holding crypto is like a first date: risky but with major potential. ‚ù§Ô∏è\",\n",
    "        \"Crypto in 2024: volatile, unpredictable, and totally our kind of party.\",\n",
    "        \n",
    "        # Finance\n",
    "        \"Finance 101: save some, spend some, invest some‚Ä¶ and maybe sprinkle in a bit of crypto?\",\n",
    "        \"Budgeting tip: Only buy the dip. And if you can't handle the dip, maybe just get the chips.\",\n",
    "        \"In finance, like in life, it‚Äôs not about timing the market; it‚Äôs about time *in* the market.\",\n",
    "        \"Investing? Think of it like planting a tree. The best time to start was 10 years ago, the second best time is today.\",\n",
    "        \"Finance is the fine balance between spending for joy and saving for freedom. Nail it, and you‚Äôre golden.\",\n",
    "        \n",
    "        # Tether\n",
    "        \"Tether: the friend you invite to the party, but secretly hope behaves this time. üòÖ\",\n",
    "        \"Why get a financial cushion when you have Tether? It‚Äôll keep you guessing!\",\n",
    "        \"Tether keeps us on our toes. Will it, won‚Äôt it? Ah, the suspense!\",\n",
    "        \"Tether: because who doesn‚Äôt love a good plot twist in the world of stablecoins?\",\n",
    "        \"With Tether, you get stability... or at least the thrill of the promise of it. Hang tight! üòÜ\",\n",
    "        \n",
    "        # General commentary\n",
    "        \"In crypto we trust, because in fiat we‚Ä¶ well, let‚Äôs just say we like variety.\",\n",
    "        \"NFTs, Web3, and crypto: bringing you closer to financial freedom‚Äîone meme at a time!\",\n",
    "        \"Who needs physical gold when digital gold can hit the moon and beyond?\",\n",
    "        \"The metaverse: where your avatars have a better wardrobe than you. Talk about goals!\",\n",
    "        \"In the world of crypto, today's volatility is tomorrow‚Äôs dinner conversation.\",\n",
    "        \n",
    "        # Motivational with a twist\n",
    "        \"Remember, every Satoshi counts. You‚Äôre not just HODLing; you‚Äôre building an empire!\",\n",
    "        \"One Bitcoin at a time, one block at a time. Today‚Äôs grind, tomorrow‚Äôs moonshot.\",\n",
    "        \"In Web3, you‚Äôre not just a user; you‚Äôre a stakeholder. Own your world, baby.\",\n",
    "        \"They say fortune favors the brave. In crypto, it also favors the HODLers!\",\n",
    "        \"Invest in what you believe in. And if you believe in memes, well, there‚Äôs always Dogecoin.\",\n",
    "        \n",
    "        # Fun facts & quirks\n",
    "        \"Fun fact: owning a crypto wallet makes you 200% more interesting at parties. üòâ\",\n",
    "        \"Crypto: for people who love thrillers but prefer checking prices over watching movies.\",\n",
    "        \"The blockchain: keeping receipts since day one. Accountability has never looked so techy.\",\n",
    "        \"In Web3, you‚Äôre not just on the internet; you‚Äôre part of the internet. Welcome aboard!\",\n",
    "        \"Apparently, the only thing more stable than Tether is‚Ä¶ well, let's just say, stay tuned!\",\n",
    "\n",
    "        \"NFTs: Because art was getting a bit too traditional for us. Now it‚Äôs digital and fabulous! üíé\",\n",
    "        \"Web3: It's like the internet, but with less 'central' and more 'magic.' ‚ú®\",\n",
    "        \"Crypto isn‚Äôt just a currency‚Äîit‚Äôs a lifestyle choice. Ready to dive in?\",\n",
    "        \"The future is decentralized, darling. Here‚Äôs what Web3 has in store!\",\n",
    "        \"Bitcoin isn‚Äôt just currency; it‚Äôs the thrill ride we all signed up for. üé¢\",\n",
    "        \"Money matters, but how you spend it matters more. Here‚Äôs a quirky view on finance:\",\n",
    "        \"Tether: the friend you invite to the party but secretly hope behaves. üòÖ\",\n",
    "        \n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "split_dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Tokenize the dataset with reduced max length and add labels\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"Text\"], padding=True, truncation=True, max_length=64)  # Limit max length to 64\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()  # Use input_ids as labels for causal LM training\n",
    "    return inputs\n",
    "\n",
    "# Tokenize and preprocess the dataset\n",
    "tokenized_dataset = split_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"no\",  # No evaluation dataset for this example\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,  # Further reduce accumulation steps if needed\n",
    "    num_train_epochs=0.3,  # Reduced epochs for memory efficiency\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09490bcc-7ea9-485b-83f7-b0dce2893f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_personality_bot/tokenizer_config.json',\n",
       " './fine_tuned_personality_bot/special_tokens_map.json',\n",
       " './fine_tuned_personality_bot/vocab.json',\n",
       " './fine_tuned_personality_bot/merges.txt',\n",
       " './fine_tuned_personality_bot/added_tokens.json',\n",
       " './fine_tuned_personality_bot/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./fine_tuned_personality_bot\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_personality_bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a2f06-403c-4036-b1a8-80bafb3e1535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: If your digital twin could speak, what would it say?\n",
      "If your digital twin could speak, what would it say?\n",
      "\n",
      "It might not be much, but your digital twin, a computer simulation of you, could answer. The computer simulation would need to be accurate to be useful, though‚Äîit would have to mimic what you actually do when you're awake. And it would be far more useful if it knew about all the ways you have a mind‚Äîand how those thoughts affect your actions.\n",
      "\n",
      "If you've been reading this column for a\n",
      "------------\n",
      "Prompt 2: What‚Äôs one tech innovation we can‚Äôt live without?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Set the device to CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the model and tokenizer, and set the tokenizer pad token to eos token\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").to(device)\n",
    "\n",
    "# Define core and general prompts\n",
    "core_prompts = [\n",
    "    \"NFTs aren‚Äôt just art; they‚Äôre a movement. Why?\",\n",
    "    \"In Web3, you‚Äôre the VIP. But what does that mean?\",\n",
    "    \"Crypto‚Äôs not just currency. It‚Äôs a wild ride. Here‚Äôs why:\",\n",
    "    \"Stablecoins: revolutionary or risky?\",\n",
    "    \"You think NFTs are just JPEGs? Let‚Äôs chat about ownership.\"\n",
    "]\n",
    "\n",
    "general_prompts = [\n",
    "    \"If your digital twin could speak, what would it say?\",\n",
    "    \"What‚Äôs one tech innovation we can‚Äôt live without?\",\n",
    "    \"Today‚Äôs thought: is privacy even possible online?\",\n",
    "    \"Ever thought about what your data is doing right now?\",\n",
    "    \"Imagine your phone is a person‚Äîhow would you two get along?\",\n",
    "    \"What is on your mind?\"\n",
    "]\n",
    "\n",
    "# Function to choose a prompt with weighted randomness\n",
    "def choose_prompt():\n",
    "    prompt_list = random.choices(\n",
    "        population=[core_prompts, general_prompts],\n",
    "        weights=[0.5, 0.5],  # 50% chance for each category\n",
    "        k=1\n",
    "    )[0]\n",
    "    return random.choice(prompt_list)  # Randomly select a prompt within the chosen category\n",
    "\n",
    "# Generate text function with adjusted sampling parameters\n",
    "def generate_text(prompt):\n",
    "    # Tokenize the prompt and ensure tensors are on the CPU\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "    inputs[\"attention_mask\"] = (inputs.input_ids != tokenizer.pad_token_id).long().to(device)\n",
    "\n",
    "    # Generate text using the model with modified parameters\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=100,  # Limit length for conciseness\n",
    "        do_sample=True,\n",
    "        top_k=30,        # More focused sampling\n",
    "        top_p=0.8,       # Less diverse sampling\n",
    "        temperature=1.2, # Increase creativity\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Decode and return the generated text\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Generate and print responses for 5 different prompts\n",
    "for i in range(5):\n",
    "    selected_prompt = choose_prompt()  # Select a prompt with weighted randomness\n",
    "    print(f\"Prompt {i+1}: {selected_prompt}\")\n",
    "    print(generate_text(selected_prompt))\n",
    "    print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37094647-7ff7-4fc1-b684-a71f45767d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8081974c-69a1-47e6-8238-42986f83e27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tbot)",
   "language": "python",
   "name": "tbotbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
