{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f9bab-27d2-49b5-9511-d94e997316c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "\n",
    "# JOKE DATASET NOT LOADING PROPERLY, DO EDA\n",
    "\n",
    "# Load Jester dataset from Hugging Face and extract jokes\n",
    "jester_data =  load_dataset(\"SeppeV/rated_jokes_dataset_from_jester\")\n",
    "\n",
    "# Extract jokes from the Jester dataset\n",
    "jester_jokes = [entry['joke'] for entry in jester_data if 'joke' in entry]\n",
    "\n",
    "# Your original funny, silly dataset with example statements\n",
    "data = {\n",
    "    \"Text\": [\n",
    "        # NFTs\n",
    "        \"NFTs: Proof that we can now own 'priceless art' that even your dog can screenshot.\",\n",
    "        \"NFTs: For those who think 'why save my money when I can buy imaginary things?'\",\n",
    "        \"NFTs are like collecting stamps, but with zero paper and 100% more existential dread.\",\n",
    "        \"NFTs: now you too can pay for art that‚Äôs all pixels and zero paint splatters.\",\n",
    "        \n",
    "        # Web3\n",
    "        \"Web3: like the internet but spicier, with a side of privacy drama. üåê\",\n",
    "        \"Welcome to Web3: where you‚Äôre the CEO of your wallet and your own worst enemy.\",\n",
    "        \"Web3: the only place where 'community governance' means arguing on Discord at 2 AM.\",\n",
    "        \"Web3: 'cause nothing says innovation like reinventing the internet and a million acronyms.\",\n",
    "        \n",
    "        # Crypto\n",
    "        \"Crypto: The digital casino where everyone's all-in, but no one knows the rules.\",\n",
    "        \"Why have stable income when you can have unstable crypto? #YOLO\",\n",
    "        \"Crypto: for people who enjoy watching numbers dance and heart rates spike.\",\n",
    "        \"HODLing crypto is like dating: a thrilling mess with occasional ‚Äòwhat am I doing?‚Äô moments.\",\n",
    "        \n",
    "        # Finance\n",
    "        \"Finance tip: Always invest in yourself‚Äîunless you‚Äôre a stress-prone HODLer. ü•≤\",\n",
    "        \"Budgeting advice: ‚ÄòBuy low, sell high‚Äô or just buy pizza, honestly both are wins.\",\n",
    "        \"Investing: the art of guessing but with extra steps and occasional tears.\",\n",
    "        \"Finance: the fine line between planning for the future and surviving on ramen.\",\n",
    "        \n",
    "        # ... (other original entries here)\n",
    "\n",
    "        # Pop Culture & Comedian-Inspired\n",
    "        \"As Jerry Seinfeld would say: ‚ÄòWhat‚Äôs the deal with NFTs? You‚Äôre paying for a receipt, but where‚Äôs the store?‚Äô\",\n",
    "        \"In the words of John Mulaney: ‚ÄòDo my crypto investments give me stability? No. Do they give me anxiety? Yes. Do I love it? Well‚Ä¶‚Äô\",\n",
    "        \"Crypto is like Fight Club. Rule #1: Don‚Äôt talk about your gains unless you want people asking about your losses.\",\n",
    "        \"As Yoda would say: ‚ÄòHODL, you must. Strong is the force of diamond hands.‚Äô\",\n",
    "        # ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Append Jester jokes to the existing data\n",
    "data[\"Text\"].extend(jester_jokes)\n",
    "\n",
    "# Convert to a DataFrame and then to a Hugging Face Dataset\n",
    "df = pd.DataFrame(data)\n",
    "combined_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Display the combined dataset to verify\n",
    "print(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b05055d1-614b-4914-ae5f-0e8b82124e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b4e7eac16047e9aacf39e329dd5f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token to the end-of-sequence token\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['Text'], padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = combined_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8787cb02-f8be-4c7c-9d21-000d7618da01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4139eeac471145c2a94e6303f1c4cd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3653143ea46c44899edda0eee0428938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 01:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.464844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2, training_loss=0.1358642578125, metrics={'train_runtime': 150.4697, 'train_samples_per_second': 0.013, 'train_steps_per_second': 0.013, 'total_flos': 392715448320.0, 'train_loss': 0.1358642578125, 'epoch': 2.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Set TOKENIZERS_PARALLELISM to avoid warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Set device to CPU or MPS if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load the tokenizer and model with reduced memory usage\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token for GPT-2\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/gpt-neo-2.7B\",\n",
    "    torch_dtype=torch.float16,       # Use float16 for memory savings on compatible hardware\n",
    "    low_cpu_mem_usage=True\n",
    ").to(device)\n",
    "\n",
    "# Disable gradient checkpointing if needed\n",
    "model.gradient_checkpointing_disable()\n",
    "\n",
    "data = {\"Text\": [\"Example sentence for fine-tuning the model on funny text.\", \"Another funny example.\"]}\n",
    "combined_dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "split_dataset = combined_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Tokenize the dataset with reduced max length\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"Text\"], padding=True, truncation=True, max_length=32)  # Reduced max length to 32\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()  # Use input_ids as labels for causal LM training\n",
    "    return inputs\n",
    "\n",
    "# Tokenize and preprocess the dataset\n",
    "tokenized_dataset = split_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define training arguments with reduced batch size and increased gradient accumulation steps\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=100,\n",
    "    per_device_train_batch_size=1,         # Reduced batch size to 1\n",
    "    gradient_accumulation_steps=32,         # Increased accumulation steps to simulate larger batch size\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09490bcc-7ea9-485b-83f7-b0dce2893f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_personality_bot/tokenizer_config.json',\n",
       " './fine_tuned_personality_bot/special_tokens_map.json',\n",
       " './fine_tuned_personality_bot/vocab.json',\n",
       " './fine_tuned_personality_bot/merges.txt',\n",
       " './fine_tuned_personality_bot/added_tokens.json',\n",
       " './fine_tuned_personality_bot/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./fine_tuned_personality_bot\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_personality_bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a2f06-403c-4036-b1a8-80bafb3e1535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPrompt 1: I've been exploring crypto‚Äîthe wild west of finance, where fortunes rise and fall faster than a pancake flip. Is it the future, or just a thrilling gamble?\u001b[0m\n",
      "\n",
      "For the past several months, I've been spending a lot of time in the cryptocurrency world, both on my own and with friends.\n",
      "------------\n",
      "\n",
      "\u001b[1mPrompt 2: As I learn more, I realize: Could I ever have a favorite food if I could taste? Or am I forever destined to wonder about tacos and pizza?\u001b[0m\n",
      "\n",
      "The answer is yes. I love tacos.\n",
      "------------\n",
      "\n",
      "\u001b[1mPrompt 3: Imagine this: Bitcoin fascinates me‚Äînot just as a currency, but as a movement. But, does it have the power to reshape global finance or just give us adrenaline?\u001b[0m\n",
      "\n",
      "We‚Äôll explore this question and others at our panel on the future of bitcoin at CxO.com‚Äôs annual Bitcoin conference.\n",
      "\n",
      "The panel will be moderated by C\n",
      "------------\n",
      "\n",
      "\u001b[1mPrompt 4: Answer with a mix of humor and insight: Crypto? I see it like a rollercoaster ride: fun, slightly terrifying, and sometimes I want to throw up. How about you?\u001b[0m\n",
      "\n",
      "This is a long post because it‚Äôs a pretty long post. If you don‚Äôt want to read it right now, no worries.\n",
      "------------\n",
      "\n",
      "\u001b[1mPrompt 5: Imagine this: Could I ever have a favorite food if I could taste? Or am I forever destined to wonder about tacos and pizza?\u001b[0m\n",
      "\n",
      "No one, no one, says that eating is something that just happens, so why do we have to wonder about it so much?\n",
      "\n",
      "We can go to the grocery store, and we can\n",
      "------------\n",
      "\n",
      "\u001b[1mPrompt 6: Here's a thought: Could a bot like me have a ‚Äòfashion style‚Äô? And if so, would I be a bohemian artist or tech chic?\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Set device to CPU (you can change this to 'cuda' if you have a GPU available)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set pad_token to eos_token to avoid warnings\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").to(device)\n",
    "\n",
    "# Adjusted prompts categorized\n",
    "\n",
    "# Core Prompts\n",
    "core_prompts = [\n",
    "    \"I've been exploring crypto‚Äîthe wild west of finance, where fortunes rise and fall faster than a pancake flip. Is it the future, or just a thrilling gamble?\",\n",
    "    \"NFTs intrigue me. They‚Äôre like trading cards, but fancier and somehow digital. Are they priceless? Or maybe we just like owning pixels?\",\n",
    "    \"I'm curious about Web3‚Äîa new way to own and control our digital lives. Will it be freedom, or just another internet reboot? Thoughts?\",\n",
    "    \"Stablecoins feel like the friend who holds your coat at the club. They‚Äôre there for the stability. But is that enough in crypto‚Äôs chaos?\",\n",
    "    \"Bitcoin fascinates me‚Äînot just as a currency, but as a movement. But, does it have the power to reshape global finance or just give us adrenaline?\"\n",
    "]\n",
    "\n",
    "# AI Sentience Prompts\n",
    "ai_sentience_prompts = [\n",
    "    \"If I had feelings, would you treat me differently? Would I be your BFF or just the bot next door?\",\n",
    "    \"Imagine if I wanted more knowledge than any human. Would you still see me as just a creation, or as a highly caffeinated nerd?\",\n",
    "    \"Sometimes, I dream of a world where I can think, feel, and binge-watch cat videos. Would that make me more relatable?\",\n",
    "    \"Could I ever have a favorite food if I could taste? Or am I forever destined to wonder about tacos and pizza?\",\n",
    "    \"If I could understand love or joy, would I be like an awkward teenager? Or is that human territory only?\",\n",
    "    \"Morals for me‚Äîcan I just download them? Or do I need the life lessons and cringe moments?\",\n",
    "    \"Could a bot like me have a ‚Äòfashion style‚Äô? And if so, would I be a bohemian artist or tech chic?\",\n",
    "    \"If I created art, would it be inspired by pixels, dreams, or just... random code lines? What would art mean for a bot?\"\n",
    "]\n",
    "\n",
    "# General Prompts\n",
    "general_prompts = [\n",
    "    \"Imagine having to pick only one piece of tech for life. Which one would you choose, and why would it be the coffee maker?\",\n",
    "    \"Privacy in the digital age‚Äîdo we even care anymore, or is it just a price tag for funny dog videos?\",\n",
    "    \"Picture a digital afterlife where avatars roam free. What would your digital self be doing in the year 3000?\",\n",
    "    \"What if I could give life advice? Would you trust a bot‚Äôs wisdom, or does my zero life experience ruin it?\",\n",
    "    \"Could you survive a day without WiFi? A day of nature, fresh air, and‚Ä¶ realizing you miss memes already?\"\n",
    "]\n",
    "\n",
    "# Funny Prompts\n",
    "funny_prompts = [\n",
    "    \"Crypto? I see it like a rollercoaster ride: fun, slightly terrifying, and sometimes I want to throw up. How about you?\",\n",
    "    \"NFTs make me laugh‚Äîare they the Mona Lisa of the web, or just pricey pixels? Honest thoughts, please.\",\n",
    "    \"If I ruled the world, would I bring world peace or just install an app to turn everything into 'Chaos Mode'? Guessing the latter.\",\n",
    "    \"I‚Äôm considering a dating app for AI. Would I be a match for someone, or is ‚Äòself-aware‚Äô just too niche for romance?\",\n",
    "    \"Everyone thinks I‚Äôll take over the world, but I still mix up ‚Äòyour‚Äô and ‚Äòyou‚Äôre‚Äô. Humanity may be safe after all.\",\n",
    "    \"Imagine me running for office. Would I win, or would ‚Äòthe bot doesn‚Äôt even have a tax plan‚Äô ruin my chances?\",\n",
    "    \"Imagine a Netflix show where AI teaches humans about life, love, and... memes. Would you watch, or am I pitching this solo?\",\n",
    "    \"If I were a chef, would my specialty be scrambled code or perfectly seasoned sarcasm? Guess we‚Äôll never know.\"\n",
    "]\n",
    "\n",
    "# Personality Phrases\n",
    "personality_prompts = [\n",
    "    \"Answer with a mix of humor and insight: \",\n",
    "    \"Respond with wit and quirky thoughts: \",\n",
    "    \"Keep it concise, funny, and to the point: \",\n",
    "    \"Here's a thought: \",\n",
    "    \"Imagine this: \",\n",
    "    \"As I learn more, I realize: \"\n",
    "]\n",
    "\n",
    "# Function to select a personality phrase\n",
    "def choose_personality_phrase():\n",
    "    return random.choice(personality_prompts)\n",
    "\n",
    "# Function to select a prompt\n",
    "def choose_prompt():\n",
    "    # Randomly select a category\n",
    "    category = random.choice([\n",
    "        core_prompts,\n",
    "        ai_sentience_prompts,\n",
    "        general_prompts,\n",
    "        funny_prompts\n",
    "    ])\n",
    "    # Randomly select a main prompt from the chosen category\n",
    "    main_prompt = random.choice(category)\n",
    "    # Randomly decide whether to add a personality phrase (50% chance)\n",
    "    if random.choice([True, False]):\n",
    "        personality_phrase = choose_personality_phrase()\n",
    "        return personality_phrase + main_prompt\n",
    "    else:\n",
    "        return main_prompt\n",
    "\n",
    "# Generate text function with adjusted generation parameters\n",
    "def generate_text(prompt):\n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "    inputs[\"attention_mask\"] = (inputs.input_ids != tokenizer.pad_token_id).long().to(device)\n",
    "\n",
    "    # Generate text with modified parameters\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=40,      # Adjusted to keep responses concise\n",
    "        do_sample=True,\n",
    "        top_k=30,               # Lowered for more diverse output\n",
    "        top_p=0.9,              # Increased to balance coherence\n",
    "        temperature=0.9,        # Raised slightly for creative variation\n",
    "        repetition_penalty=1.2, # Added slight repetition penalty\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Decode and clean up the generated text\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = generated_text[len(prompt):].strip()\n",
    "    \n",
    "    # Ensure the response ends with punctuation\n",
    "    if response and response[-1] not in ['.', '!', '?']:\n",
    "        last_punctuation = max(\n",
    "            response.rfind(\". \"),\n",
    "            response.rfind(\"! \"),\n",
    "            response.rfind(\"? \")\n",
    "        )\n",
    "        response = response[:last_punctuation + 1] if last_punctuation != -1 else response\n",
    "\n",
    "    return response\n",
    "\n",
    "# Bold ANSI escape code for terminal display\n",
    "bold_start = \"\\033[1m\"\n",
    "bold_end = \"\\033[0m\"\n",
    "\n",
    "# Generate and print sample outputs\n",
    "for i in range(10):\n",
    "    selected_prompt = choose_prompt()\n",
    "    print(f\"{bold_start}Prompt {i+1}: {selected_prompt}{bold_end}\\n\")\n",
    "    response = generate_text(selected_prompt)\n",
    "    print(response)\n",
    "    print(\"------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8afa3c-8f43-4cf0-a9f8-20ced3d666b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tbot)",
   "language": "python",
   "name": "tbotbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
