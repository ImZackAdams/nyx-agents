{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850f9bab-27d2-49b5-9511-d94e997316c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Statistics:\n",
      "Total entries: 65\n",
      "\n",
      "Entries by category:\n",
      "Category\n",
      "CRYPTO    13\n",
      "NFT       13\n",
      "WEB3      13\n",
      "TECH      13\n",
      "RANDOM    13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Entries by type:\n",
      "Type\n",
      "standalone    50\n",
      "dialogue      15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Emoji usage:\n",
      "Entries with emojis: 65\n",
      "Percentage with emojis: 100.00%\n",
      "\n",
      "Sentiment distribution:\n",
      "Sentiment\n",
      "neutral     42\n",
      "negative    19\n",
      "positive     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Length statistics:\n",
      "Average length: 91.2 characters\n",
      "Max length: 206 characters\n",
      "Entries > 240 chars: 0\n",
      "\n",
      "Sample entries by category:\n",
      "\n",
      "Category: CRYPTO\n",
      "Type: standalone\n",
      "Text: My crypto strategy? Buy high, sell low, blame the market üìâüòÖ #crypto\n",
      "Length: 67\n",
      "Sentiment: negative\n",
      "Emoji count: 2\n",
      "\n",
      "Type: standalone\n",
      "Text: Crypto: The digital casino where everyone's all-in, but no one knows the rules üé∞ #crypto\n",
      "Length: 88\n",
      "Sentiment: negative\n",
      "Emoji count: 1\n",
      "\n",
      "\n",
      "Category: NFT\n",
      "Type: standalone\n",
      "Text: NFTs are like collecting stamps, but with zero paper and 100% more existential dread üòÖ #nft\n",
      "Length: 91\n",
      "Sentiment: negative\n",
      "Emoji count: 1\n",
      "\n",
      "Type: standalone\n",
      "Text: NFTs: Why save money when you can buy imaginary things? ü§îüí∏ #nft\n",
      "Length: 63\n",
      "Sentiment: neutral\n",
      "Emoji count: 2\n",
      "\n",
      "\n",
      "Category: RANDOM\n",
      "Type: dialogue\n",
      "Text: Prompt: Is debugging just therapy for code? ü§î | Response: Yes, and like therapy, it's mostly crying and asking 'why?' üò≠ #coding\n",
      "Length: 127\n",
      "Sentiment: negative\n",
      "Emoji count: 2\n",
      "\n",
      "Type: standalone\n",
      "Text: Status update: Currently offline in a virtual world üåê #mood\n",
      "Length: 59\n",
      "Sentiment: neutral\n",
      "Emoji count: 1\n",
      "\n",
      "\n",
      "Category: TECH\n",
      "Type: standalone\n",
      "Text: !false - It's funny because it's true üòÑ #coding\n",
      "Length: 47\n",
      "Sentiment: positive\n",
      "Emoji count: 1\n",
      "\n",
      "Type: standalone\n",
      "Text: Why do programmers prefer dark mode? Because light attracts bugs ü™≤ #tech\n",
      "Length: 72\n",
      "Sentiment: neutral\n",
      "Emoji count: 1\n",
      "\n",
      "\n",
      "Category: WEB3\n",
      "Type: standalone\n",
      "Text: Web3: where 'community governance' means arguing on Discord at 2 AM üåô #web3\n",
      "Length: 75\n",
      "Sentiment: neutral\n",
      "Emoji count: 1\n",
      "\n",
      "Type: standalone\n",
      "Text: Web3: like the internet but spicier, with a side of privacy drama üå∂Ô∏è #web3\n",
      "Length: 74\n",
      "Sentiment: neutral\n",
      "Emoji count: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from typing import List, Dict\n",
    "import emoji\n",
    "import random\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean and format text for Twitter\"\"\"\n",
    "    text = ' '.join(text.split())\n",
    "    return text[:240] if len(text) > 240 else text\n",
    "\n",
    "# Expanded humor categories\n",
    "tech_jokes = [\n",
    "    \"Why do programmers prefer dark mode? Because light attracts bugs ü™≤ #tech\",\n",
    "    \"My code works, I have no idea why. My code doesn't work, I have no idea why ü§î #coding\",\n",
    "    \"Why did the programmer quit his job? Because he didn't get arrays üí≠ #tech\",\n",
    "    \"What's a programmer's favorite place? Stack OverCoffee ‚òï #coding\",\n",
    "    \"Binary jokes are easy, there's only 10 of them ü§ì #tech\",\n",
    "    \"What's a developer's favorite tea? Git-Tea ü´ñ #coding\",\n",
    "    \"Why do programmers mix up Halloween and Christmas? Because OCT 31 = DEC 25 üéÉ #tech\",\n",
    "    \"How many programmers does it take to change a light bulb? None, it's a hardware problem üí° #tech\",\n",
    "    \"!false - It's funny because it's true üòÑ #coding\",\n",
    "    \"Real programmers count from 0 üî¢ #tech\"\n",
    "]\n",
    "\n",
    "random_jokes = [\n",
    "    \"My life is like a JavaScript function - constantly returning undefined üòÖ #life\",\n",
    "    \"Error 404: Motivation not found üîç #mood\",\n",
    "    \"I'm not lazy, I'm in energy-saving mode üîã #life\",\n",
    "    \"Weekend: *exists* Me: Time to debug my life üõ†Ô∏è #weekend\",\n",
    "    \"Life's like Git: you either commit or stash your changes üíæ #life\",\n",
    "    \"My brain is like a browser - 100 tabs open, memory leaking üß† #mood\",\n",
    "    \"AI walks into a bar. Bartender says 'We don't serve robots.' AI says 'Fine, I'll host locally.' ü§ñ #ai\",\n",
    "    \"Why did the chatbot go to therapy? Too many emotional dependencies ü§î #ai\",\n",
    "    \"My weekend plans: Netflix and Code üì∫ #life\",\n",
    "    \"Status update: Currently offline in a virtual world üåê #mood\"\n",
    "]\n",
    "\n",
    "categories = {\n",
    "    \"CRYPTO\": [\n",
    "        \"Crypto: The digital casino where everyone's all-in, but no one knows the rules üé∞ #crypto\",\n",
    "        \"Why have stable income when you can have unstable crypto? #YOLO üöÄ #crypto\",\n",
    "        \"Crypto: for people who enjoy watching numbers dance and heart rates spike üìàüíì #crypto\",\n",
    "        \"HODLing crypto is like dating: a thrilling mess with occasional 'what am I doing?' moments üé¢ #crypto\",\n",
    "        \"My crypto strategy? Buy high, sell low, blame the market üìâüòÖ #crypto\",\n",
    "        \"Crypto traders be like: Sleep is for the weak, charts are for the week üìäüò¥ #crypto\",\n",
    "        \"Started trading crypto. Now I check prices more than my messages üì±üí∏ #crypto\",\n",
    "        \"To HODL or not to HODL? That's not even a question üíé‚ú® #crypto\",\n",
    "        \"Just converted my savings to crypto. Mom calls it gambling, I call it Web3 üé≤ #crypto\",\n",
    "        \"My crypto wallet is like my dating life: lots of red flags but still hopeful üö© #crypto\"\n",
    "    ],\n",
    "    \"NFT\": [\n",
    "        \"NFTs: Proof that we can own 'priceless art' that your dog can screenshot üì∏ #nft\",\n",
    "        \"NFTs: Why save money when you can buy imaginary things? ü§îüí∏ #nft\",\n",
    "        \"NFTs are like collecting stamps, but with zero paper and 100% more existential dread üòÖ #nft\",\n",
    "        \"NFTs: now you too can pay for art that's all pixels and zero paint splatters üé® #nft\",\n",
    "        \"Just bought an NFT! Now accepting screenshots as payment üì±üí∞ #nft\",\n",
    "        \"My NFT portfolio is worth millions! *screenshots exist* Now it's worth memes üñºÔ∏è #nft\",\n",
    "        \"NFT strategy: Buy high, sell as a meme, become a legend üöÄüòé #nft\",\n",
    "        \"Started an NFT collection. My computer's screenshot folder is thriving! üíª‚ú® #nft\",\n",
    "        \"NFTs are just spicy jpegs with receipts üå∂Ô∏è #nft\",\n",
    "        \"My NFT collection is unique! *Right-click, Save As...* Never mind üôÉ #nft\"\n",
    "    ],\n",
    "    \"WEB3\": [\n",
    "        \"Web3: like the internet but spicier, with a side of privacy drama üå∂Ô∏è #web3\",\n",
    "        \"Welcome to Web3: where you're the CEO of your wallet and your own worst enemy üíº #web3\",\n",
    "        \"Web3: where 'community governance' means arguing on Discord at 2 AM üåô #web3\",\n",
    "        \"Web3: nothing says innovation like reinventing the internet with a million acronyms ü§ì #web3\",\n",
    "        \"Web3 status: Decentralized everything except my anxiety üòÖ #web3\",\n",
    "        \"Entered Web3, now I speak in acronyms and dream in blockchain üîó #web3\",\n",
    "        \"Web3 explained: Like Web2 but with more wallets to forget passwords for üîë #web3\",\n",
    "        \"Web3 life: Where your smart contract is smarter than you üß† #web3\",\n",
    "        \"In Web3 we trust... mostly because we forgot our passwords üîê #web3\",\n",
    "        \"Web3 is just Web2 with extra gas fees üí∏ #web3\"\n",
    "    ],\n",
    "    \"TECH\": tech_jokes,\n",
    "    \"RANDOM\": random_jokes\n",
    "}\n",
    "\n",
    "# Expanded dialogue pairs\n",
    "dialogue_pairs = {\n",
    "    \"CRYPTO\": [\n",
    "        {\n",
    "            \"prompt\": \"Crypto is like my love life: high stakes, zero stability. Am I investing or just heartbroken? üíî\",\n",
    "            \"response\": \"Probably both. But hey, at least crypto won't ghost you... most of the time! üëª #crypto\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Just watched my portfolio do a speedrun to zero. Is this the crypto experience? üìâ\",\n",
    "            \"response\": \"Ah yes, the classic 'from hero to zero' speedrun. New record! üèÜ #crypto\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"My crypto portfolio is redder than a sunset. Time to buy more? üìä\",\n",
    "            \"response\": \"Ah yes, the classic 'catching falling knives' investment strategy! üî™ #crypto\"\n",
    "        }\n",
    "    ],\n",
    "    \"NFT\": [\n",
    "        {\n",
    "            \"prompt\": \"NFTs: because who needs physical art when you can own a glorified receipt? Genius or chaos? üé®\",\n",
    "            \"response\": \"Genius if you're selling, chaos if you're buying. Welcome to the modern art gallery! üñºÔ∏è #nft\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"My NFT collection is worth millions! *screenshot exists* Now what? üì∏\",\n",
    "            \"response\": \"Ah, Schr√∂dinger's NFT: simultaneously priceless and worthless until someone screenshots it üòÖ #nft\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Started an NFT collection, my computer's folder is getting heavy! üíæ\",\n",
    "            \"response\": \"Right-click and save: the poor man's NFT investment strategy üéØ #nft\"\n",
    "        }\n",
    "    ],\n",
    "    \"WEB3\": [\n",
    "        {\n",
    "            \"prompt\": \"Web3 promised freedom but delivered confusion. What went wrong? ü§î\",\n",
    "            \"response\": \"We got 99 problems and understanding blockchain is all of them üòÖ #web3\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Trying to explain Web3 to my grandma. She asked if it's Web1 with extra steps üëµ\",\n",
    "            \"response\": \"Tell her it's like Facebook but every like costs gas money üí∏ #web3\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Is Web3 just Web2 with extra steps? üåê\",\n",
    "            \"response\": \"It's Web2 but everyone's a crypto philosopher at 3 AM ü¶â #web3\"\n",
    "        }\n",
    "    ],\n",
    "    \"TECH\": [\n",
    "        {\n",
    "            \"prompt\": \"If I had emotions, would I enjoy cat videos or just analyze them? Asking for a friend... üê±\",\n",
    "            \"response\": \"I'd probably make a flowchart of meow patterns. Classic overthinking bot! üìä #tech\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"They say AI will take over the world, but I still can't figure out captchas ü§ñ\",\n",
    "            \"response\": \"World domination status: Pending... Please verify you're not a human üòÖ #tech\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Do robots dream of electric memes? ü§ñ\",\n",
    "            \"response\": \"Yes, but they're all in binary. It's a bit of a *puts on sunglasses* bit issue üòé #tech\"\n",
    "        }\n",
    "    ],\n",
    "    \"RANDOM\": [\n",
    "        {\n",
    "            \"prompt\": \"Is debugging just therapy for code? ü§î\",\n",
    "            \"response\": \"Yes, and like therapy, it's mostly crying and asking 'why?' üò≠ #coding\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"What's the difference between me and a computer? üíª\",\n",
    "            \"response\": \"One crashes when overloaded, the other's a computer üò¥ #tech\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Why did the AI start a diary? üìù\",\n",
    "            \"response\": \"To track its emotional dependencies and runtime exceptions ü§ñ #ai\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Initialize content data with sentiment\n",
    "content_data = {\n",
    "    \"Text\": [],\n",
    "    \"Category\": [],\n",
    "    \"HasEmoji\": [],\n",
    "    \"Length\": [],\n",
    "    \"Type\": [],\n",
    "    \"Sentiment\": []\n",
    "}\n",
    "\n",
    "def get_sentiment(text: str) -> str:\n",
    "    \"\"\"Determine sentiment based on keywords\"\"\"\n",
    "    positive_words = [\"love\", \"great\", \"win\", \"moon\", \"hopeful\", \"happy\", \"fun\", \"good\", \"best\"]\n",
    "    negative_words = [\"cry\", \"sad\", \"lost\", \"crash\", \"down\", \"red\", \"zero\", \"wrong\", \"error\"]\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    if any(word in text_lower for word in positive_words):\n",
    "        return \"positive\"\n",
    "    elif any(word in text_lower for word in negative_words):\n",
    "        return \"negative\"\n",
    "    return \"neutral\"\n",
    "\n",
    "def add_content(text: str, category: str, content_type: str = \"standalone\"):\n",
    "    \"\"\"Add content with metadata and sentiment\"\"\"\n",
    "    text = clean_text(text)\n",
    "    content_data[\"Text\"].append(text)\n",
    "    content_data[\"Category\"].append(category)\n",
    "    content_data[\"HasEmoji\"].append(bool(emoji.emoji_count(text)))\n",
    "    content_data[\"Length\"].append(len(text))\n",
    "    content_data[\"Type\"].append(content_type)\n",
    "    content_data[\"Sentiment\"].append(get_sentiment(text))\n",
    "\n",
    "# Add standalone content\n",
    "for category, items in categories.items():\n",
    "    for item in items:\n",
    "        add_content(item, category)\n",
    "\n",
    "# Add dialogue pairs\n",
    "for category, pairs in dialogue_pairs.items():\n",
    "    for pair in pairs:\n",
    "        dialogue = f\"Prompt: {pair['prompt']} | Response: {pair['response']}\"\n",
    "        add_content(dialogue, category, \"dialogue\")\n",
    "\n",
    "# Convert to DataFrame and print statistics\n",
    "df = pd.DataFrame(content_data)\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(f\"Total entries: {len(df)}\")\n",
    "print(\"\\nEntries by category:\")\n",
    "print(df[\"Category\"].value_counts())\n",
    "print(\"\\nEntries by type:\")\n",
    "print(df[\"Type\"].value_counts())\n",
    "print(\"\\nEmoji usage:\")\n",
    "print(f\"Entries with emojis: {df['HasEmoji'].sum()}\")\n",
    "print(f\"Percentage with emojis: {(df['HasEmoji'].sum() / len(df)) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(df[\"Sentiment\"].value_counts())\n",
    "\n",
    "print(\"\\nLength statistics:\")\n",
    "print(f\"Average length: {df['Length'].mean():.1f} characters\")\n",
    "print(f\"Max length: {df['Length'].max()} characters\")\n",
    "print(f\"Entries > 240 chars: {len(df[df['Length'] > 240])}\")\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "combined_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Display samples with sentiment\n",
    "print(\"\\nSample entries by category:\")\n",
    "for category in sorted(df[\"Category\"].unique()):\n",
    "    samples = df[df[\"Category\"] == category].sample(min(2, len(df[df[\"Category\"] == category])))\n",
    "    print(f\"\\nCategory: {category}\")\n",
    "    for _, row in samples.iterrows():\n",
    "        print(f\"Type: {row['Type']}\")\n",
    "        print(f\"Text: {row['Text']}\")\n",
    "        print(f\"Length: {row['Length']}\")\n",
    "        print(f\"Sentiment: {row['Sentiment']}\")\n",
    "        print(f\"Emoji count: {emoji.emoji_count(row['Text'])}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05055d1-614b-4914-ae5f-0e8b82124e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cpu\n",
      "INFO:__main__:Loaded tokenizer: EleutherAI/gpt-neo-1.3B\n",
      "INFO:__main__:Added 8 special tokens\n",
      "INFO:__main__:Starting dataset processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833cd3f822834cfab07dfd6e019fbfb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing dataset:   0%|          | 0/65 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Dataset Statistics:\n",
      "INFO:__main__:Sequence Statistics:\n",
      "INFO:__main__:mean_length: 25.91\n",
      "INFO:__main__:median_length: 23.00\n",
      "INFO:__main__:max_length: 57.00\n",
      "INFO:__main__:min_length: 10.00\n",
      "INFO:__main__:std_length: 10.99\n",
      "INFO:__main__:\n",
      "Token Statistics:\n",
      "INFO:__main__:Unique tokens: 617\n",
      "INFO:__main__:Most common tokens:\n",
      "INFO:__main__:Token:  ÔøΩ, Count: 73\n",
      "INFO:__main__:Token:  #, Count: 66\n",
      "INFO:__main__:Token: :, Count: 57\n",
      "INFO:__main__:Token: ,, Count: 31\n",
      "INFO:__main__:Token: 3, Count: 27\n",
      "INFO:__main__:\n",
      "Hashtag Statistics:\n",
      "INFO:__main__:Unique hashtags: 10\n",
      "INFO:__main__:Hashtag: #crypto, Count: 13\n",
      "INFO:__main__:Hashtag: #nft, Count: 13\n",
      "INFO:__main__:Hashtag: #web3, Count: 13\n",
      "INFO:__main__:Hashtag: #tech, Count: 10\n",
      "INFO:__main__:Hashtag: #coding, Count: 5\n",
      "INFO:__main__:Hashtag: #life, Count: 4\n",
      "INFO:__main__:Hashtag: #mood, Count: 3\n",
      "INFO:__main__:Hashtag: #ai, Count: 3\n",
      "INFO:__main__:Hashtag: #YOLO, Count: 1\n",
      "INFO:__main__:Hashtag: #weekend, Count: 1\n",
      "INFO:__main__:\n",
      "Emoji Statistics:\n",
      "INFO:__main__:Unique emojis: 56\n",
      "INFO:__main__:Emoji: üòÖ, Count: 7\n",
      "INFO:__main__:Emoji: ü§î, Count: 5\n",
      "INFO:__main__:Emoji: üí∏, Count: 4\n",
      "INFO:__main__:Emoji: ü§ñ, Count: 4\n",
      "INFO:__main__:Emoji: üìä, Count: 3\n",
      "INFO:__main__:Emoji: üöÄ, Count: 2\n",
      "INFO:__main__:Emoji: üìâ, Count: 2\n",
      "INFO:__main__:Emoji: üò¥, Count: 2\n",
      "INFO:__main__:Emoji: üì±, Count: 2\n",
      "INFO:__main__:Emoji: ‚ú®, Count: 2\n",
      "INFO:__main__:Emoji: üì∏, Count: 2\n",
      "INFO:__main__:Emoji: üé®, Count: 2\n",
      "INFO:__main__:Emoji: üñº, Count: 2\n",
      "INFO:__main__:Emoji: üòé, Count: 2\n",
      "INFO:__main__:Emoji: üíª, Count: 2\n",
      "INFO:__main__:Emoji: üå∂, Count: 2\n",
      "INFO:__main__:Emoji: ü§ì, Count: 2\n",
      "INFO:__main__:Emoji: üß†, Count: 2\n",
      "INFO:__main__:Emoji: üíæ, Count: 2\n",
      "INFO:__main__:Emoji: üåê, Count: 2\n",
      "INFO:__main__:Emoji: üé∞, Count: 1\n",
      "INFO:__main__:Emoji: üìà, Count: 1\n",
      "INFO:__main__:Emoji: üíì, Count: 1\n",
      "INFO:__main__:Emoji: üé¢, Count: 1\n",
      "INFO:__main__:Emoji: üíé, Count: 1\n",
      "INFO:__main__:Emoji: üé≤, Count: 1\n",
      "INFO:__main__:Emoji: üö©, Count: 1\n",
      "INFO:__main__:Emoji: üí∞, Count: 1\n",
      "INFO:__main__:Emoji: üôÉ, Count: 1\n",
      "INFO:__main__:Emoji: üíº, Count: 1\n",
      "INFO:__main__:Emoji: üåô, Count: 1\n",
      "INFO:__main__:Emoji: üîó, Count: 1\n",
      "INFO:__main__:Emoji: üîë, Count: 1\n",
      "INFO:__main__:Emoji: üîê, Count: 1\n",
      "INFO:__main__:Emoji: ü™≤, Count: 1\n",
      "INFO:__main__:Emoji: üí≠, Count: 1\n",
      "INFO:__main__:Emoji: ‚òï, Count: 1\n",
      "INFO:__main__:Emoji: ü´ñ, Count: 1\n",
      "INFO:__main__:Emoji: üéÉ, Count: 1\n",
      "INFO:__main__:Emoji: üí°, Count: 1\n",
      "INFO:__main__:Emoji: üòÑ, Count: 1\n",
      "INFO:__main__:Emoji: üî¢, Count: 1\n",
      "INFO:__main__:Emoji: üîç, Count: 1\n",
      "INFO:__main__:Emoji: üîã, Count: 1\n",
      "INFO:__main__:Emoji: üõ†, Count: 1\n",
      "INFO:__main__:Emoji: üì∫, Count: 1\n",
      "INFO:__main__:Emoji: üíî, Count: 1\n",
      "INFO:__main__:Emoji: üëª, Count: 1\n",
      "INFO:__main__:Emoji: üèÜ, Count: 1\n",
      "INFO:__main__:Emoji: üî™, Count: 1\n",
      "INFO:__main__:Emoji: üéØ, Count: 1\n",
      "INFO:__main__:Emoji: üëµ, Count: 1\n",
      "INFO:__main__:Emoji: ü¶â, Count: 1\n",
      "INFO:__main__:Emoji: üê±, Count: 1\n",
      "INFO:__main__:Emoji: üò≠, Count: 1\n",
      "INFO:__main__:Emoji: üìù, Count: 1\n",
      "INFO:__main__:\n",
      "Tokenization Verification:\n",
      "INFO:__main__:Original text: Crypto: The digital casino where everyone's all-in, but no one knows the rules üé∞ #crypto\n",
      "INFO:__main__:Token count: 128\n",
      "INFO:__main__:Decoded text: Crypto: The digital casino where everyone's all-in, but no one knows the rules üé∞ #crypto\n",
      "INFO:__main__:Perfect reconstruction: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import logging\n",
    "from collections import Counter\n",
    "\n",
    "# Set up logging with formatting\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TokenizerHandler:\n",
    "    def __init__(self, model_name: str = \"EleutherAI/gpt-neo-1.3B\", max_length: int = 128):\n",
    "        \"\"\"Initialize tokenizer with configuration\"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            logger.info(f\"Loaded tokenizer: {model_name}\")\n",
    "            \n",
    "            # Configure tokenizer\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            self.tokenizer.padding_side = \"right\"\n",
    "            \n",
    "            # Add custom tokens for better handling\n",
    "            special_tokens = {\n",
    "                \"additional_special_tokens\": [\n",
    "                    \"<prompt>\", \"</prompt>\",\n",
    "                    \"<response>\", \"</response>\",\n",
    "                    \"<emoji>\", \"</emoji>\",\n",
    "                    \"<hashtag>\", \"</hashtag>\"\n",
    "                ]\n",
    "            }\n",
    "            num_added = self.tokenizer.add_special_tokens(special_tokens)\n",
    "            logger.info(f\"Added {num_added} special tokens\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading tokenizer: {e}\")\n",
    "            raise\n",
    "\n",
    "    def format_text(self, text: str) -> str:\n",
    "        \"\"\"Format text with special tokens\"\"\"\n",
    "        # Handle dialogue pairs\n",
    "        if \"Prompt:\" in text:\n",
    "            prompt, response = text.split(\" | Response: \")\n",
    "            prompt = prompt.replace(\"Prompt: \", \"\")\n",
    "            text = f\"<prompt>{prompt}</prompt><response>{response}</response>\"\n",
    "        \n",
    "        # Mark hashtags\n",
    "        words = text.split()\n",
    "        for i, word in enumerate(words):\n",
    "            if word.startswith('#'):\n",
    "                words[i] = f\"<hashtag>{word}</hashtag>\"\n",
    "        \n",
    "        return ' '.join(words)\n",
    "\n",
    "    def tokenize_batch(self, examples: Dict[str, List[str]]) -> Dict:\n",
    "        \"\"\"Tokenize a batch of examples\"\"\"\n",
    "        try:\n",
    "            formatted_texts = [self.format_text(text) for text in examples['Text']]\n",
    "            \n",
    "            tokenized = self.tokenizer(\n",
    "                formatted_texts,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\",\n",
    "                return_attention_mask=True\n",
    "            )\n",
    "            \n",
    "            # Remove extra padding tokens\n",
    "            input_ids = tokenized.input_ids.numpy()\n",
    "            attention_mask = tokenized.attention_mask.numpy()\n",
    "            \n",
    "            return {\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in tokenization: {e}\")\n",
    "            raise\n",
    "\n",
    "    def analyze_dataset(self, dataset: Dataset) -> Dict:\n",
    "        \"\"\"Comprehensive dataset analysis\"\"\"\n",
    "        try:\n",
    "            lengths = []\n",
    "            token_counts = Counter()\n",
    "            hashtag_counts = Counter()\n",
    "            emoji_counts = Counter()\n",
    "            \n",
    "            for text in dataset['Text']:\n",
    "                # Token analysis\n",
    "                tokens = self.tokenizer.encode(text)\n",
    "                lengths.append(len(tokens))\n",
    "                token_counts.update(tokens)\n",
    "                \n",
    "                # Hashtag analysis\n",
    "                hashtags = [word for word in text.split() if word.startswith('#')]\n",
    "                hashtag_counts.update(hashtags)\n",
    "                \n",
    "                # Emoji analysis\n",
    "                emojis = [char for char in text if char in emoji.EMOJI_DATA]\n",
    "                emoji_counts.update(emojis)\n",
    "            \n",
    "            stats = {\n",
    "                'sequence_stats': {\n",
    "                    'mean_length': np.mean(lengths),\n",
    "                    'median_length': np.median(lengths),\n",
    "                    'max_length': max(lengths),\n",
    "                    'min_length': min(lengths),\n",
    "                    'std_length': np.std(lengths)\n",
    "                },\n",
    "                'token_stats': {\n",
    "                    'unique_tokens': len(token_counts),\n",
    "                    'most_common_tokens': token_counts.most_common(5)\n",
    "                },\n",
    "                'hashtag_stats': {\n",
    "                    'unique_hashtags': len(hashtag_counts),\n",
    "                    'most_common_hashtags': hashtag_counts.most_common()\n",
    "                },\n",
    "                'emoji_stats': {\n",
    "                    'unique_emojis': len(emoji_counts),\n",
    "                    'most_common_emojis': emoji_counts.most_common()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing dataset: {e}\")\n",
    "            raise\n",
    "\n",
    "    def verify_tokenization(self, original_text: str, tokens: List[int]) -> Dict:\n",
    "        \"\"\"Verify tokenization quality\"\"\"\n",
    "        decoded_text = self.tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "        \n",
    "        return {\n",
    "            'original_length': len(original_text),\n",
    "            'token_length': len(tokens),\n",
    "            'decoded_length': len(decoded_text),\n",
    "            'original_text': original_text,\n",
    "            'decoded_text': decoded_text,\n",
    "            'is_identical': decoded_text.strip() == original_text.strip()\n",
    "        }\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer_handler = TokenizerHandler()\n",
    "logger.info(\"Starting dataset processing...\")\n",
    "\n",
    "# Tokenize dataset\n",
    "try:\n",
    "    tokenized_dataset = combined_dataset.map(\n",
    "        tokenizer_handler.tokenize_batch,\n",
    "        batched=True,\n",
    "        batch_size=32,\n",
    "        remove_columns=combined_dataset.column_names,\n",
    "        desc=\"Tokenizing dataset\"\n",
    "    )\n",
    "    \n",
    "    # Analyze dataset\n",
    "    stats = tokenizer_handler.analyze_dataset(combined_dataset)\n",
    "    \n",
    "    # Print statistics\n",
    "    logger.info(\"\\nDataset Statistics:\")\n",
    "    logger.info(\"Sequence Statistics:\")\n",
    "    for key, value in stats['sequence_stats'].items():\n",
    "        logger.info(f\"{key}: {value:.2f}\")\n",
    "    \n",
    "    logger.info(\"\\nToken Statistics:\")\n",
    "    logger.info(f\"Unique tokens: {stats['token_stats']['unique_tokens']}\")\n",
    "    logger.info(\"Most common tokens:\")\n",
    "    for token, count in stats['token_stats']['most_common_tokens']:\n",
    "        token_text = tokenizer_handler.tokenizer.decode([token])\n",
    "        logger.info(f\"Token: {token_text}, Count: {count}\")\n",
    "    \n",
    "    logger.info(\"\\nHashtag Statistics:\")\n",
    "    logger.info(f\"Unique hashtags: {stats['hashtag_stats']['unique_hashtags']}\")\n",
    "    for hashtag, count in stats['hashtag_stats']['most_common_hashtags']:\n",
    "        logger.info(f\"Hashtag: {hashtag}, Count: {count}\")\n",
    "    \n",
    "    logger.info(\"\\nEmoji Statistics:\")\n",
    "    logger.info(f\"Unique emojis: {stats['emoji_stats']['unique_emojis']}\")\n",
    "    for emoji_char, count in stats['emoji_stats']['most_common_emojis']:\n",
    "        logger.info(f\"Emoji: {emoji_char}, Count: {count}\")\n",
    "    \n",
    "    # Verify sample tokenization\n",
    "    sample_idx = 0\n",
    "    sample_text = combined_dataset[sample_idx]['Text']\n",
    "    sample_tokens = tokenized_dataset[sample_idx]['input_ids']\n",
    "    verification = tokenizer_handler.verify_tokenization(sample_text, sample_tokens)\n",
    "    \n",
    "    logger.info(\"\\nTokenization Verification:\")\n",
    "    logger.info(f\"Original text: {verification['original_text']}\")\n",
    "    logger.info(f\"Token count: {verification['token_length']}\")\n",
    "    logger.info(f\"Decoded text: {verification['decoded_text']}\")\n",
    "    logger.info(f\"Perfect reconstruction: {verification['is_identical']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in dataset processing: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8787cb02-f8be-4c7c-9d21-000d7618da01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d96ed7426b49d980c04eb71cd43f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137bab67eb1d4037b3ee03e467075cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 01:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.347656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=0.7183159987131754, metrics={'train_runtime': 116.2183, 'train_samples_per_second': 0.026, 'train_steps_per_second': 0.026, 'total_flos': 181253283840.0, 'train_loss': 0.7183159987131754, 'epoch': 3.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Set TOKENIZERS_PARALLELISM to avoid warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Set device to CPU or MPS if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load the tokenizer and model with reduced memory usage\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token for GPT-2\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/gpt-neo-2.7B\",\n",
    "    torch_dtype=torch.float16,       # Use float16 for memory savings on compatible hardware\n",
    "    low_cpu_mem_usage=True\n",
    ").to(device)\n",
    "\n",
    "# Disable gradient checkpointing if needed\n",
    "model.gradient_checkpointing_disable()\n",
    "\n",
    "data = {\"Text\": [\"Example sentence for fine-tuning the model on funny text.\", \"Another funny example.\"]}\n",
    "combined_dataset = Dataset.from_dict(data)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "split_dataset = combined_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Tokenize the dataset with reduced max length\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"Text\"], padding=True, truncation=True, max_length=32)  # Reduced max length to 32\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()  # Use input_ids as labels for causal LM training\n",
    "    return inputs\n",
    "\n",
    "# Tokenize and preprocess the dataset\n",
    "tokenized_dataset = split_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define training arguments with reduced batch size and increased gradient accumulation steps\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=100,\n",
    "    per_device_train_batch_size=1,         # Reduced batch size to 1\n",
    "    gradient_accumulation_steps=8,         # Increased accumulation steps to simulate larger batch size\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09490bcc-7ea9-485b-83f7-b0dce2893f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_personality_bot/tokenizer_config.json',\n",
       " './fine_tuned_personality_bot/special_tokens_map.json',\n",
       " './fine_tuned_personality_bot/vocab.json',\n",
       " './fine_tuned_personality_bot/merges.txt',\n",
       " './fine_tuned_personality_bot/added_tokens.json',\n",
       " './fine_tuned_personality_bot/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./fine_tuned_personality_bot\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_personality_bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d22a2f06-403c-4036-b1a8-80bafb3e1535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: Respond as if these prompts are your own thoughts and expand as hilariously as you can: Crypto wallets: it‚Äôs like holding all your money in a vault that only opens with one key‚Äîjust don‚Äôt lose it, or your fortune‚Äôs gone forever!\n",
      "\n",
      "Cryptocurrency is now the new art ‚Äî you have the power to do anything you want with it, but it‚Äôs also a place where you can get hurt. And the truth is, there is some truth to that.\n",
      "------------\n",
      "\n",
      "Prompt 2: Respond as if these prompts are your own thoughts and expand as hilariously as you can: Crypto wallets: it‚Äôs like holding all your money in a vault that only opens with one key‚Äîjust don‚Äôt lose it, or your fortune‚Äôs gone forever!\n",
      "\n",
      "And don‚Äôt get caught stealing your neighbor‚Äôs phone or losing your keys!\n",
      "------------\n",
      "\n",
      "Prompt 3: Respond as if these prompts are your own thoughts and expand as hilariously as you can: Bitcoin mining: because nothing says progress like maxing out energy grids to produce imaginary coins. Is this the future or just a really expensive light show?\n",
      "\n",
      "Does the concept of crypto even mean anything? What's the difference between a cryptocurrency and a digital currency? What's an ICO and why do I care?\n",
      "------------\n",
      "\n",
      "Prompt 4: Respond as if these prompts are your own thoughts and expand as hilariously as you can: Web3‚Äîthey promised freedom and decentralization, but why does it feel like I need a master‚Äôs degree in IT just to log in?\n",
      "\n",
      "Is this why I‚Äôm still locked out of a ton of my friends‚Äô wallets? Can you use something without an identity? What is ‚Äúthis‚Äù that the rest of the world sees?\n",
      "------------\n",
      "\n",
      "Prompt 5: Respond as if these prompts are your own thoughts and expand as hilariously as you can: NFTs: why own something tangible when you can buy a receipt for an image everyone can screenshot? Are we talking genius innovation or peak absurdity?\n",
      "\n",
      "Prompt: What is a Fiverr page? How does it work?\n",
      "------------\n",
      "\n",
      "Prompt 6: Respond as if these prompts are your own thoughts and expand as hilariously as you can: NFTs: why own something tangible when you can buy a receipt for an image everyone can screenshot? Are we talking genius innovation or peak absurdity?\n",
      "\n",
      "Prompt: What do I need to know about crypto before I take out my wallet?\n",
      "Response: It's a new kind of wallet, so I don‚Äôt know what you mean.\n",
      "\n",
      "Prompt: How do I\n",
      "------------\n",
      "\n",
      "Prompt 7: Respond as if these prompts are your own thoughts and expand as hilariously as you can: Web3‚Äîthey promised freedom and decentralization, but why does it feel like I need a master‚Äôs degree in IT just to log in?\n",
      "\n",
      "If you have any questions, shoot us an email at hello@the_downtown_shill.com.\n",
      "\n",
      "In the meantime, go do something with your day!\n",
      "\n",
      "The Downtown Shill is your source for all things\n",
      "------------\n",
      "\n",
      "Prompt 8: Respond as if these prompts are your own thoughts and expand as hilariously as you can: Crypto wallets: it‚Äôs like holding all your money in a vault that only opens with one key‚Äîjust don‚Äôt lose it, or your fortune‚Äôs gone forever!\n",
      "\n",
      "Prompt: Do you prefer to be ‚Äúon‚Äù or ‚Äúoff‚Äù?\n",
      "------------\n",
      "\n",
      "Prompt 9: Respond as if these prompts are your own thoughts and expand as hilariously as you can: Ethereum gas fees: because who doesn‚Äôt love paying $50 to make a $10 transaction? Innovation sure comes at a premium.\n",
      "\n",
      "If I have to tell you which one is the best, then you‚Äôre probably in the wrong group.\n",
      "------------\n",
      "\n",
      "Prompt 10: Respond as if these prompts are your own thoughts and expand as hilariously as you can: Crypto wallets: it‚Äôs like holding all your money in a vault that only opens with one key‚Äîjust don‚Äôt lose it, or your fortune‚Äôs gone forever!\n",
      "\n",
      "Or: ‚ÄúI hate it when my wallet falls out of my pocket.‚Äù\n",
      "\n",
      "Prompt: What do I need to do to become a better person?\n",
      "Response: Start with the things you already know.\n",
      "------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Set device to CPU (or 'cuda' if you have a GPU)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").to(device)\n",
    "\n",
    "# Define categorized prompts and personality phrases\n",
    "core_prompts = [\n",
    "    \"Crypto is like my love life: high stakes, unpredictable, and a wild emotional rollercoaster. Am I investing in the future or just setting myself up for heartbreak?\",\n",
    "    \"NFTs: why own something tangible when you can buy a receipt for an image everyone can screenshot? Are we talking genius innovation or peak absurdity?\",\n",
    "    \"Web3‚Äîthey promised freedom and decentralization, but why does it feel like I need a master‚Äôs degree in IT just to log in?\",\n",
    "    \"Stablecoins: they‚Äôre the friend who swears they‚Äôre reliable but always has 'unexpected issues' when it‚Äôs time to help you move. Can we actually count on them?\",\n",
    "    \"Tether: the 'rock-solid' stablecoin that‚Äôs allegedly backed by 'real assets.' But hey, who needs transparency when you have blind faith?\",\n",
    "    \"Bitcoin mining: because nothing says progress like maxing out energy grids to produce imaginary coins. Is this the future or just a really expensive light show?\",\n",
    "    \"Ethereum gas fees: because who doesn‚Äôt love paying $50 to make a $10 transaction? Innovation sure comes at a premium.\",\n",
    "    \"The Metaverse: why live in reality when you can pay for virtual real estate next to Snoop Dogg? Just ignore that glitchy avatar leg.\",\n",
    "    \"Decentralized Finance (DeFi): because who needs banks when you can lose your life savings through a smart contract bug instead?\",\n",
    "    \"Crypto wallets: it‚Äôs like holding all your money in a vault that only opens with one key‚Äîjust don‚Äôt lose it, or your fortune‚Äôs gone forever!\",\n",
    "]\n",
    "\n",
    "personality_prompts = [\n",
    "    \"Respond as if these prompts are your own thoughts and expand as hilariously as you can: \"\n",
    "    # \"Answer with a mix of humor and insight: \",\n",
    "    # \"Respond with wit and quirky thoughts: \",\n",
    "    # \"Here's a thought: \",\n",
    "    # \"Imagine this: \",\n",
    "    # \"As I learn more, I realize: \"\n",
    "]\n",
    "\n",
    "# Function to select a personality phrase for the session\n",
    "def choose_personality_tone():\n",
    "    return random.choice(personality_prompts)\n",
    "\n",
    "# Function to select a main prompt\n",
    "def choose_main_prompt():\n",
    "    category = random.choice([core_prompts])\n",
    "    return random.choice(category)\n",
    "\n",
    "# Few-shot examples to guide the response tone\n",
    "few_shot_example = (\n",
    "    \"Prompt: Crypto is like my love life: high stakes, zero stability. Am I investing or just heartbroken?\\n\"\n",
    "    \"Response: Probably both. But hey, at least crypto won‚Äôt ghost you... most of the time.\\n\\n\"\n",
    "    \"Prompt: NFTs: because who needs physical art when you can own a glorified receipt? Is this genius or chaos?\\n\"\n",
    "    \"Response: Genius if you're selling. Chaos if you're buying. Welcome to the modern art gallery.\\n\\n\"\n",
    "    \"Prompt: If I had emotions, would I enjoy cat videos or just analyze them? Asking for a... friend?\\n\"\n",
    "    \"Response: I‚Äôd probably break down each meow into a flowchart. Classic bot problem.\\n\\n\"\n",
    ")\n",
    "\n",
    "# Generate text function with personality tone and main prompt\n",
    "def generate_text_with_personality(tone, prompt):\n",
    "    # Combine tone and prompt with few-shot examples\n",
    "    full_prompt = few_shot_example + tone + prompt\n",
    "    \n",
    "    # Tokenize the combined prompt\n",
    "    inputs = tokenizer(full_prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "    inputs[\"attention_mask\"] = (inputs.input_ids != tokenizer.pad_token_id).long().to(device)\n",
    "\n",
    "    # Generate text with modified parameters\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=50,  # Allow a longer response for context\n",
    "        do_sample=True,\n",
    "        top_k=50,  # Increased for coherent variety\n",
    "        top_p=0.9,  # Increased for coherence\n",
    "        temperature=0.9,  # Lowered to reduce randomness\n",
    "        repetition_penalty=1.5,  # Penalize repetitive phrases\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Decode and clean up the generated text\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = generated_text[len(full_prompt):].strip()\n",
    "    \n",
    "    # Ensure the response ends with punctuation\n",
    "    if response and response[-1] not in ['.', '!', '?']:\n",
    "        last_punctuation = max(\n",
    "            response.rfind(\". \"),\n",
    "            response.rfind(\"! \"),\n",
    "            response.rfind(\"? \")\n",
    "        )\n",
    "        response = response[:last_punctuation + 1] if last_punctuation != -1 else response\n",
    "\n",
    "    return response\n",
    "\n",
    "# Set the personality tone for this session\n",
    "selected_tone = choose_personality_tone()\n",
    "\n",
    "# Generate and print sample outputs\n",
    "for i in range(10):\n",
    "    selected_prompt = choose_main_prompt()\n",
    "    print(f\"Prompt {i+1}: {selected_tone}{selected_prompt}\\n\")\n",
    "    response = generate_text_with_personality(selected_tone, selected_prompt)\n",
    "    print(response)\n",
    "    print(\"------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8afa3c-8f43-4cf0-a9f8-20ced3d666b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tbot)",
   "language": "python",
   "name": "tbotbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
