{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850f9bab-27d2-49b5-9511-d94e997316c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Text'],\n",
      "    num_rows: 36\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Create a dummy dataset with example statements\n",
    "# Create a dummy dataset with example statements\n",
    "data = {\n",
    "    \"Text\": [\n",
    "        # NFTs\n",
    "        \"NFTs: Because who needs real art when you can have a JPEG, am I right?\",\n",
    "        \"They said 'Art is priceless.' NFT folks said 'Wanna bet?'\",\n",
    "        \"An NFT isn‚Äôt just a JPEG; it‚Äôs a lifestyle. Own it, honey.\",\n",
    "        \"NFTs: finally, a way to flex without a single frame in sight. üôÑ\",\n",
    "        \n",
    "        # Web3\n",
    "        \"Web3: it's like the internet, but now it pretends to respect your privacy. üåê\",\n",
    "        \"Welcome to Web3! The internet, but with less 'central' and more 'chaos.'\",\n",
    "        \"In Web3, you‚Äôre the VIP, darling. Don‚Äôt forget to act like it.\",\n",
    "        \"Web3 is like that glow-up your ex saw too late. Ain't it beautiful? üòå\",\n",
    "        \n",
    "        # Crypto\n",
    "        \"Crypto: Where the only thing faster than gains is your blood pressure. üöÄ\",\n",
    "        \"Who needs a savings account when you have crypto? Rollercoasters are way more fun.\",\n",
    "        \"Bitcoin: it‚Äôs like a rollercoaster, but at least you get bragging rights.\",\n",
    "        \"HODLing crypto is like dating‚Äîrisky, full of red flags, but still thrilling. ‚ù§Ô∏è\",\n",
    "        \n",
    "        # Finance\n",
    "        \"Finance 101: Save a little, spend a little‚Ä¶ then YOLO into crypto for that thrill.\",\n",
    "        \"Budgeting tip: Only buy the dip. If you can‚Äôt handle that, maybe just buy some chips.\",\n",
    "        \"Investing is like planting a tree. The best time to start was yesterday. Or maybe never?\",\n",
    "        \"Finance: the fine line between living your best life and eating instant noodles.\",\n",
    "        \n",
    "        # Tether\n",
    "        \"Tether: the friend you invite to the party but secretly hope behaves. We‚Äôve all been there. üòÖ\",\n",
    "        \"Tether keeps us on our toes. Will it? Won‚Äôt it? The suspense is real!\",\n",
    "        \"Tether: Who doesn‚Äôt love a stablecoin with a personality crisis?\",\n",
    "        \"With Tether, stability is just an option. Hang tight, folks! üòÜ\",\n",
    "        \n",
    "        # General Commentary\n",
    "        \"In crypto we trust, because in fiat we‚Ä¶ well, let‚Äôs just say we have options.\",\n",
    "        \"NFTs, Web3, crypto: bringing you closer to financial freedom‚Äîone meme at a time!\",\n",
    "        \"Who needs physical gold when digital gold can hit the moon and back?\",\n",
    "        \"The metaverse: where your avatar‚Äôs wardrobe is better than yours. #goals\",\n",
    "        \"Crypto today, ramen tomorrow. That‚Äôs the vibe.\",\n",
    "        \n",
    "        # Motivational with a Twist\n",
    "        \"Every Satoshi counts. You‚Äôre not just HODLing; you‚Äôre building an empire, darling.\",\n",
    "        \"One Bitcoin at a time, one block at a time. Today‚Äôs hustle, tomorrow‚Äôs moon.\",\n",
    "        \"In Web3, you‚Äôre not just a user; you‚Äôre a shareholder, baby. Own it.\",\n",
    "        \"They say fortune favors the bold. In crypto, it favors the HODLers with nerves of steel.\",\n",
    "        \"Invest in what you believe in. If that‚Äôs memes, well‚Ä¶ at least you‚Äôre consistent.\",\n",
    "        \n",
    "        # Fun Facts & Quirks\n",
    "        \"Fun fact: owning a crypto wallet makes you 200% more interesting at parties. üòâ\",\n",
    "        \"Crypto: for people who love thrillers but would rather check prices than watch movies.\",\n",
    "        \"The blockchain: keeping receipts since day one. Accountability, but make it techy.\",\n",
    "        \"In Web3, you‚Äôre not just on the internet; you‚Äôre part of the internet. Welcome aboard!\",\n",
    "        \"Apparently, the only thing more stable than Tether is‚Ä¶ never mind, scratch that.\",\n",
    "        \n",
    "        # Long, playful commentary\n",
    "        \"Cryptocurrency is like that thrill-seeking friend who insists on skydiving without a parachute. \\\n",
    "         It‚Äôs wild, unpredictable, and slightly terrifying, but we all keep coming back for more. Why? \\\n",
    "         Because there‚Äôs something irresistible about a market where 'going to the moon' is both a compliment \\\n",
    "         and a red flag. Traditional finance is like wearing sensible shoes. It‚Äôs stable, grounded, predictable. \\\n",
    "         Crypto? It‚Äôs strapping on a pair of rollerblades and heading downhill. You might crash, but what a rush, right? \\\n",
    "         So whether you‚Äôre HODLing, staking, or just here for the memes, remember: in crypto, the journey is half the fun. üòâ\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "\n",
    "# Display the dataset to verify\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05055d1-614b-4914-ae5f-0e8b82124e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb946333399b49fc8cfa172139d2b4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token to the end-of-sequence token\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['Text'], padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8787cb02-f8be-4c7c-9d21-000d7618da01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e90aa74c46945a594291c388f1d6bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44977774f308431f9600bec2ab12e81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:37, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=8.765697479248047, metrics={'train_runtime': 44.3984, 'train_samples_per_second': 1.261, 'train_steps_per_second': 0.135, 'total_flos': 22274245656576.0, 'train_loss': 8.765697479248047, 'epoch': 1.7142857142857144})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Set device to CPU (or MPS if you want to attempt it again)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the model in half-precision mode to save memory\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token for GPT-2\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\", torch_dtype=torch.float16).to(device)\n",
    "\n",
    "# Enable gradient checkpointing for memory efficiency\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "split_dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Tokenize the dataset with reduced max length and add labels\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"Text\"], padding=True, truncation=True, max_length=64)  # Limit max length to 64\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].copy()  # Use input_ids as labels for causal LM training\n",
    "    return inputs\n",
    "\n",
    "# Tokenize and preprocess the dataset\n",
    "tokenized_dataset = split_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",  # Updated 'evaluation_strategy' to 'eval_strategy' to match deprecation warning\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=100,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    # fp16=False,  # Remove or comment out fp16 to avoid issues on non-Nvidia GPUs\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09490bcc-7ea9-485b-83f7-b0dce2893f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_personality_bot/tokenizer_config.json',\n",
       " './fine_tuned_personality_bot/special_tokens_map.json',\n",
       " './fine_tuned_personality_bot/vocab.json',\n",
       " './fine_tuned_personality_bot/merges.txt',\n",
       " './fine_tuned_personality_bot/added_tokens.json',\n",
       " './fine_tuned_personality_bot/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"./fine_tuned_personality_bot\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_personality_bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d22a2f06-403c-4036-b1a8-80bafb3e1535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPrompt 1: Hello, is this thing on?!Crypto: your ticket to financial freedom, if you've got the stomach for it!\u001b[0m\n",
      "\n",
      "Brace yourself, Hello, is this thing on?!Crypto: your ticket to financial freedom, if you've got the stomach for it!\n",
      "\n",
      "For the last several months, I‚Äôve been talking about what you need to know about crypto to make it happen, and how to get started with it.\n",
      "\n",
      "I‚Äôve been writing extensively about the world‚Äôs next major financial bubble, which is expected to come\n",
      "------------\n",
      "\u001b[1mPrompt 2: Web3: the internet just leveled up, and it's about time. Ready for the upgrade?\u001b[0m\n",
      "\n",
      "Oh honey, Web3: the internet just leveled up, and it's about time. Ready for the upgrade?\n",
      "\n",
      "I am a fan of the idea of ‚ÄúReady for the upgrade‚Äù, as it is a very nice thing to be able to upgrade to.\n",
      "\n",
      "However, this is not a very catchy phrase in my opinion.\n",
      "------------\n",
      "\u001b[1mPrompt 3: Would you give up your favorite app for a week to gain total data privacy?\u001b[0m\n",
      "\n",
      "Let‚Äôs get real for a second: Would you give up your favorite app for a week to gain total data privacy?\n",
      "\n",
      "This is a long shot.\n",
      "\n",
      "It‚Äôs also a lot of work, but I‚Äôm willing to bet that it will yield huge rewards in the long run.\n",
      "\n",
      "But that doesn‚Äôt make it right.\n",
      "\n",
      "It‚Äôs wrong to give\n",
      "------------\n",
      "\u001b[1mPrompt 4: NFTs aren‚Äôt just art; they‚Äôre a revolution in ownership. Ready to join?\u001b[0m\n",
      "\n",
      "Here‚Äôs the tea: NFTs aren‚Äôt just art; they‚Äôre a revolution in ownership. Ready to join?\n",
      "\n",
      "What the future holds for NFTs\n",
      "\n",
      "In the past decade, artists have made the transition from art to technology, changing the face of the art world.\n",
      "\n",
      "For instance, the Internet has allowed people to come together and connect with one another.\n",
      "------------\n",
      "\u001b[1mPrompt 5: Web3: the internet just leveled up, and it's about time. Ready for the upgrade?\u001b[0m\n",
      "\n",
      "Now listen closely: Web3: the internet just leveled up, and it's about time.\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Set the device to CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the model and tokenizer, setting the tokenizer pad token to eos token\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\").to(device)\n",
    "\n",
    "# Define personality-driven prompts and filler phrases\n",
    "core_prompts = [\n",
    "    \"Hello, is this thing on?!\"\n",
    "    \"Crypto: your ticket to financial freedom, if you've got the stomach for it!\",\n",
    "    \"NFTs aren‚Äôt just art; they‚Äôre a revolution in ownership. Ready to join?\",\n",
    "    \"Web3 puts you in control of your data. Finally, the internet with some respect!\",\n",
    "    \"Stablecoins: the best attempt at calm in a sea of chaos.\",\n",
    "    \"Tether‚Äôs like a friend who‚Äôs stable‚Ä¶ or maybe not. You never quite know.\",\n",
    "    \"Crypto is like coffee: intense, addictive, and best enjoyed with caution!\",\n",
    "    \"NFTs: because owning a part of the internet makes you the VIP of digital life.\",\n",
    "    \"Web3: the internet just leveled up, and it's about time. Ready for the upgrade?\",\n",
    "    \"If you‚Äôre not investing, are you even trying to make life interesting?\",\n",
    "    \"Bitcoin: the closest thing we have to digital gold, but without the weight lifting.\",\n",
    "    \"They say fortune favors the bold‚Äîcrypto favors the daring and slightly unhinged!\",\n",
    "    \"Crypto in 2024: It‚Äôs wild, unpredictable, and exactly the thrill we signed up for.\",\n",
    "    \"Finance tips? Honey, all I‚Äôm saying is ‚ÄòBuy the dip‚Ä¶ and maybe fasten your seatbelt!‚Äô\",\n",
    "    \"Web3 is like the internet‚Äôs coming-of-age party, and it‚Äôs invite-only, baby!\",\n",
    "    \"Decentralization: because who needs central control when you can have a community?\",\n",
    "    \"Crypto: where 'holding on for dear life' is just a casual Tuesday.\"\n",
    "]\n",
    "\n",
    "general_prompts = [\n",
    "    \"If your digital twin could talk, what wisdom would it share?\",\n",
    "    \"One tech you‚Äôd fight to keep‚Äîtell us, we‚Äôre all ears!\",\n",
    "    \"Today‚Äôs deep thought: does your data deserve a little privacy, or is it overrated?\",\n",
    "    \"Ever wonder if your data is out there having its own adventure?\",\n",
    "    \"Imagine your phone as a person. Would it be your BFF or the overly nosy roommate?\",\n",
    "    \"Who‚Äôs more reliable: your favorite app or your best friend? Be honest.\",\n",
    "    \"If data could spill tea, what secrets would it share about you?\",\n",
    "    \"Data privacy: is it a right, or just an expensive illusion?\",\n",
    "    \"Would you give up your favorite app for a week to gain total data privacy?\",\n",
    "    \"Do you really own your data, or are you just renting it?\"\n",
    "]\n",
    "\n",
    "# Define more personality phrases to inject even bolder sass and humor\n",
    "personality_phrases = [\n",
    "    \"Here‚Äôs the tea: \",\n",
    "    \"Let‚Äôs get real for a second: \",\n",
    "    \"Oh honey, \",\n",
    "    \"Honestly, \",\n",
    "    \"Imagine this: \",\n",
    "    \"In case you missed it, \",\n",
    "    \"Spoiler alert: \",\n",
    "    \"Pro tip: \",\n",
    "    \"Now listen closely: \",\n",
    "    \"The truth is, \",\n",
    "    \"Guess what? \",\n",
    "    \"Brace yourself, \",\n",
    "    \"Here‚Äôs a fun fact: \",\n",
    "    \"You didn‚Äôt hear this from me, but‚Ä¶ \",\n",
    "    \"The real story here is: \"\n",
    "]\n",
    "\n",
    "# Function to choose a prompt with weighted randomness\n",
    "def choose_prompt():\n",
    "    prompt_list = random.choices(\n",
    "        population=[core_prompts, general_prompts],\n",
    "        weights=[0.7, 0.3],  # Heavier weight on core prompts for crypto focus\n",
    "        k=1\n",
    "    )[0]\n",
    "    return random.choice(prompt_list)\n",
    "\n",
    "# Generate text function with added personality-driven phrases\n",
    "def generate_text(prompt):\n",
    "    # Tokenize the prompt and ensure tensors are on the CPU\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "    inputs[\"attention_mask\"] = (inputs.input_ids != tokenizer.pad_token_id).long().to(device)\n",
    "\n",
    "    # Generate text with parameters for dynamic and expressive output\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=60,\n",
    "        do_sample=True,\n",
    "        top_k=50,               # Increased for a bit more freedom in word choice\n",
    "        top_p=1.2,              # Slightly broader scope for creativity\n",
    "        temperature=1.0,        # Increased temperature for a more \"lively\" response\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Decode the generated text\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Add a random personality phrase to the response to add sass and engagement\n",
    "    response = random.choice(personality_phrases) + response\n",
    "\n",
    "    # Post-process to remove any incomplete trailing sentences\n",
    "    if response and response[-1] not in ['.', '!', '?']:\n",
    "        last_period = max(response.rfind(\". \"), response.rfind(\"! \"), response.rfind(\"? \"))\n",
    "        if last_period != -1:\n",
    "            response = response[:last_period + 1]  # Trim to the last complete sentence\n",
    "        else:\n",
    "            response = response.rstrip(\",;:\")  # Remove any trailing punctuation that cuts off abruptly\n",
    "\n",
    "    return response\n",
    "    \n",
    "# Bold ANSI escape code\n",
    "bold_start = \"\\033[1m\"\n",
    "bold_end = \"\\033[0m\"\n",
    "\n",
    "# Modify the print statement\n",
    "for i in range(5):\n",
    "    selected_prompt = choose_prompt()  # Select a prompt with weighted randomness\n",
    "    print(f\"{bold_start}Prompt {i+1}: {selected_prompt}{bold_end}\")\n",
    "    print(\"\")\n",
    "    print(generate_text(selected_prompt))\n",
    "    print(\"------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tbot)",
   "language": "python",
   "name": "tbotbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
