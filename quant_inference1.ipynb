{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ca7d66-07e0-4e74-8c6c-2c0fa5fa4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:15:14,436 - INFO - Setting up model from ./fine_tuned_personality_bot/\n",
      "2024-11-19 12:15:15,647 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bb493248dc40b1bd77fd9c6f3cf5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:15:23,293 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "2024-11-19 12:15:23,295 - INFO - Model setup completed successfully\n",
      "2024-11-19 12:15:23,295 - INFO - Bot initialized successfully\n",
      "2024-11-19 12:15:23,295 - INFO - Starting test run with sample prompts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Run with Sample Prompts ===\n",
      "\n",
      "Prompt 1: How do gas fees compare between Ethereum and Solana?\n",
      "\n",
      "Response: Yooo, what's good fam? Just had my popcorn ready for another epic thread on #blockchain basics!\n",
      "Runtime: 23.98 seconds\n",
      "\n",
      "Prompt 2: Tell me why NFTs are either a scam or the future.\n",
      "\n",
      "Response: Who's flipping this? Yooo, what's good my NFT fam! I'm lowkey hyped for #NiftyDAOs... #TokenizedArt\n",
      "Runtime: 22.25 seconds\n",
      "\n",
      "Prompt 3: What's your take on Bitcoin as digital gold?\n",
      "\n",
      "Response: Quick thought: Yooo, what's good fam?\n",
      "Runtime: 19.47 seconds\n",
      "\n",
      "Prompt 4: Explain staking in the context of DeFi but make it funny.\n",
      "\n",
      "Response: Yooo, what's good my Gs! Just dropped some DEFI knowledge like hotcakes at .\n",
      "Runtime: 22.37 seconds\n",
      "\n",
      "Prompt 5: Give me a wild prediction for crypto in 2030.\n",
      "\n",
      "Response: Support level breakdown: Yooo, what's good fam? Just broke down some alpha metrics for #Bitcoin - realized volatility is up 30% YoYo since FOMO mode kicked in post halving!\n",
      "Runtime: 21.85 seconds\n",
      "\n",
      "Prompt 6: What's a DAO, and should I care?\n",
      "\n",
      "Response: Yooo, what's good fam? Crypto bros wanna know why I'm low-key salty on TikTok creators getting paid in Bitcoin for creating content around #NFT art What is this world comin' at?! Who else sees this?\n",
      "Runtime: 21.73 seconds\n",
      "\n",
      "Prompt 7: Can you explain why everyone's obsessed with Layer 2 solutions?\n",
      "\n",
      "Response: Just dropped some new knowledge on my Discord server, fam! We went deep into #SmartContracts & I spilled tea that most devs think they're impervious to exploits But let me tell you... Devs, thoughts?\n",
      "Runtime: 21.91 seconds\n",
      "\n",
      "Prompt 8: What's the wildest crypto meme you've seen this week?\n",
      "\n",
      "Response: Yooo, what's good fam? Just dropped some knowledge on my latest thread - don't get FUD'ed by HODLers! Thoughts?\n",
      "Runtime: 19.03 seconds\n",
      "\n",
      "Prompt 9: How do I avoid FOMO during bull runs?\n",
      "\n",
      "Response: Yooo, what's good fam? Just dropped some sick beats on my latest #MarketAnalysis video - I broke down why $ETH is tanking like it owes me money. #TechnicalAnalysis #PriceAction\n",
      "Runtime: 21.40 seconds\n",
      "\n",
      "Prompt 10: Is it too late to get into crypto? Be honest!\n",
      "\n",
      "Response: What if I told you: Yooo, what's good fam? It's your boy CryptoCrypto here!\n",
      "Runtime: 21.51 seconds\n",
      "\n",
      "Prompt 11: How would you describe Web3 to someone who barely uses the internet?\n",
      "\n",
      "Response: Yooo, what's good fam?! Crypto bros need some knowledge drops!\n",
      "Runtime: 22.10 seconds\n",
      "\n",
      "Prompt 12: What's your hottest take on decentralized finance?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:19:42,818 - INFO - Entering interactive mode...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Food for thought: Yooo, what's good fam? Just dropped out my latest vid on #Bitcoin 101 for newbies. Change my mind.\n",
      "Runtime: 21.93 seconds\n",
      "\n",
      "=== Interactive Mode ===\n",
      "Enter your prompts (type 'quit' to exit):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your prompt:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting... Thanks for using CryptoPersonalityBot!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import Tuple, List, Dict\n",
    "import random\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from torch.quantization import quantize_dynamic\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Device and model configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"./fine_tuned_personality_bot/\"  # Update with your model path\n",
    "\n",
    "class PersonalityBot:\n",
    "    def __init__(self, model_path: str = MODEL_PATH):\n",
    "        self.model_path = model_path\n",
    "        self.model, self.tokenizer = self.setup_model()\n",
    "        \n",
    "    def setup_model(self) -> Tuple[AutoModelForCausalLM, AutoTokenizer]:\n",
    "        \"\"\"Initialize and configure the model and tokenizer.\"\"\"\n",
    "        logger.info(f\"Setting up model from {self.model_path}\")\n",
    "    \n",
    "        if not os.path.exists(self.model_path):\n",
    "            raise FileNotFoundError(f\"Model not found at {self.model_path}\")\n",
    "    \n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(self.model_path, use_fast=True)\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Tokenizer loading failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "        try:\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_path,\n",
    "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "                low_cpu_mem_usage=True,\n",
    "                use_safetensors=True,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "            model.eval()\n",
    "            logger.info(\"Model setup completed successfully\")\n",
    "            return model, tokenizer\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Model loading failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def categorize_prompt(self, prompt: str) -> str:\n",
    "        \"\"\"Categorize input prompt for contextual response generation.\"\"\"\n",
    "        categories: Dict[str, List[str]] = {\n",
    "            \"market_analysis\": [\n",
    "                \"price\", \"market\", \"chart\", \"analysis\", \"trend\", \"prediction\",\n",
    "                \"bull\", \"bear\", \"trading\", \"volume\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"blockchain\", \"protocol\", \"layer\", \"scaling\", \"code\", \"development\",\n",
    "                \"smart contract\", \"gas\", \"network\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"defi\", \"yield\", \"farming\", \"liquidity\", \"stake\", \"lending\",\n",
    "                \"borrow\", \"apy\", \"tvl\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"nft\", \"art\", \"collectible\", \"mint\", \"opensea\", \"rarity\",\n",
    "                \"floor price\", \"pfp\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"community\", \"dao\", \"governance\", \"vote\", \"proposal\",\n",
    "                \"alpha\", \"degen\", \"fud\", \"fomo\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        prompt_lower = prompt.lower()\n",
    "        for category, keywords in categories.items():\n",
    "            if any(keyword in prompt_lower for keyword in keywords):\n",
    "                return category\n",
    "        return \"general\"\n",
    "\n",
    "    def generate_hook(self, category: str) -> str:\n",
    "        \"\"\"Generate category-specific attention hooks with an expanded list.\"\"\"\n",
    "        hooks = {\n",
    "            \"market_analysis\": [\n",
    "                \"Market alert:\", \"Chart check:\", \"Price watch:\",\n",
    "                \"Trading insight:\", \"Market alpha:\",\n",
    "                \"Trend spotting:\", \"Candlelight stories:\", \"RSI deep dive:\",\n",
    "                \"Volatility watch:\", \"Support level breakdown:\",\n",
    "                \"Resistance zone spotted:\", \"Market movers:\",\n",
    "                \"All eyes on the charts:\", \"Is this a bull trap?\",\n",
    "                \"Breakout or fakeout?\", \"Today's key levels:\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Tech deep dive:\", \"Builder's corner:\", \"Protocol watch:\",\n",
    "                \"Dev update:\", \"Architecture take:\",\n",
    "                \"Blockchain in focus:\", \"Gas fee breakdown:\", \"Scaling challenges:\",\n",
    "                \"Layer 2 spotlight:\", \"New upgrade analysis:\",\n",
    "                \"Consensus mechanism debate:\", \"Crypto tech wars:\",\n",
    "                \"Network optimization insights:\", \"Codebase comparison:\",\n",
    "                \"Innovator's edge:\", \"Protocol vulnerabilities exposed:\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"DeFi alpha:\", \"Yield watch:\", \"Smart money move:\",\n",
    "                \"Protocol alert:\", \"TVL update:\",\n",
    "                \"Farming frenzy:\", \"Liquidity trends:\", \"Borrowing breakdown:\",\n",
    "                \"Stakeholder spotlight:\", \"APR vs APY debate:\",\n",
    "                \"Risk-adjusted returns:\", \"What's your yield strategy?\",\n",
    "                \"Stablecoin flow insights:\", \"Vault innovations:\",\n",
    "                \"Lending protocol comparison:\", \"DeFi's next big move:\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"NFT alpha:\", \"Collection watch:\", \"Mint alert:\",\n",
    "                \"Floor check:\", \"Digital art take:\",\n",
    "                \"Art reveal:\", \"Rare trait spotted:\", \"Is this the next blue chip?\",\n",
    "                \"Profile picture wars:\", \"Who's flipping this?\",\n",
    "                \"NFT drama explained:\", \"Rarity analysis:\",\n",
    "                \"Auction insights:\", \"Utility vs hype debate:\",\n",
    "                \"Next-gen collectibles:\", \"Art meets utility:\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Culture take:\", \"DAO watch:\", \"Governance alert:\",\n",
    "                \"Community vibe:\", \"Alpha leak:\",\n",
    "                \"The crypto ethos:\", \"FOMO or FUD?\", \"Web3 lifestyle:\",\n",
    "                \"Building the future:\", \"Influencer drama explained:\",\n",
    "                \"Community-driven innovation:\", \"DAO proposal debates:\",\n",
    "                \"Web3's cultural revolution:\", \"Crypto memes decoded:\",\n",
    "                \"The rise of governance tokens:\", \"Who else is building?\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Hot take:\", \"Unpopular opinion:\", \"Plot twist:\",\n",
    "                \"Real talk:\", \"Quick thought:\",\n",
    "                \"Imagine this:\", \"What if I told you:\", \"Could this be true?\",\n",
    "                \"Something to chew on:\", \"Hereâ€™s an idea:\",\n",
    "                \"Change my mind:\", \"Big picture time:\",\n",
    "                \"Food for thought:\", \"The future is calling:\", \"What comes next?\",\n",
    "                \"Letâ€™s break it down:\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_hooks = hooks.get(category, hooks[\"general\"])\n",
    "        return random.choice(category_hooks) if random.random() < 0.4 else \"\"\n",
    "    \n",
    "\n",
    "    def add_emojis(self, text: str, category: str) -> str:\n",
    "        \"\"\"Add contextual emojis based on content category, with limited frequency.\"\"\"\n",
    "        emoji_sets = {\n",
    "            \"market_analysis\": [\"ðŸ“ˆ\", \"ðŸ“Š\", \"ðŸ’¹\", \"ðŸ“‰\", \"ðŸ’¸\", \"ðŸŽ¯\", \"ðŸ“±\"],\n",
    "            \"tech_discussion\": [\"âš¡ï¸\", \"ðŸ”§\", \"ðŸ’»\", \"ðŸ› ï¸\", \"ðŸ”¨\", \"ðŸ§®\", \"ðŸ”‹\"],\n",
    "            \"defi\": [\"ðŸ¦\", \"ðŸ’°\", \"ðŸ§\", \"ðŸ’³\", \"ðŸ”„\", \"âš–ï¸\", \"ðŸŽ°\"],\n",
    "            \"nft\": [\"ðŸŽ¨\", \"ðŸ–¼ï¸\", \"ðŸŽ­\", \"ðŸŽª\", \"ðŸŽŸï¸\", \"ðŸŽ®\", \"ðŸƒ\"],\n",
    "            \"culture\": [\"ðŸŒ\", \"ðŸ¤\", \"ðŸ—£ï¸\", \"ðŸŽ­\", \"ðŸŽª\", \"ðŸŽ¯\", \"ðŸŽ²\"],\n",
    "            \"general\": [\"ðŸš€\", \"ðŸ’Ž\", \"ðŸŒ™\", \"ðŸ”¥\", \"ðŸ’¡\", \"ðŸŽ¯\", \"â­ï¸\"]\n",
    "        }\n",
    "        \n",
    "        # Add emojis with 30% probability\n",
    "        if random.random() > 0.2:\n",
    "            return text\n",
    "    \n",
    "        category_emojis = emoji_sets.get(category, emoji_sets[\"general\"])\n",
    "        emoji_count = random.randint(1, 2)\n",
    "        chosen_emojis = random.sample(category_emojis, emoji_count)\n",
    "        \n",
    "        return f\"{text} {''.join(chosen_emojis)}\"\n",
    "\n",
    "\n",
    "    def generate_engagement_phrase(self, category: str) -> str:\n",
    "        \"\"\"Generate contextual engagement prompts.\"\"\"\n",
    "        phrases = {\n",
    "            \"market_analysis\": [\n",
    "                \"What's your price target?\",\n",
    "                \"Bulls or bears?\",\n",
    "                \"Who's buying this dip?\",\n",
    "                \"Thoughts on this setup?\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Devs, thoughts?\",\n",
    "                \"Valid architecture?\",\n",
    "                \"Spotted any issues?\",\n",
    "                \"Who's building similar?\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"What's your yield strategy?\",\n",
    "                \"Aping in?\",\n",
    "                \"Found better rates?\",\n",
    "                \"Risk level?\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"Cope or hope?\",\n",
    "                \"Floor predictions?\",\n",
    "                \"Mining this?\",\n",
    "                \"Art or utility?\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Based or nah?\",\n",
    "                \"Who else sees this?\",\n",
    "                \"Your governance take?\",\n",
    "                \"DAO voters wya?\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Thoughts?\",\n",
    "                \"Based?\",\n",
    "                \"Who's with me?\",\n",
    "                \"Change my mind.\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_phrases = phrases.get(category, phrases[\"general\"])\n",
    "        return random.choice(category_phrases) if random.random() < 0.3 else \"\"\n",
    "\n",
    "    def add_hashtags(self, text: str, category: str) -> str:\n",
    "        \"\"\"Add relevant hashtags based on content and character limit, with limited frequency.\"\"\"\n",
    "        hashtags = {\n",
    "            \"market_analysis\": [\n",
    "                \"#CryptoTrading\", \"#TechnicalAnalysis\", \"#CryptoMarkets\",\n",
    "                \"#Trading\", \"#Charts\", \"#PriceAction\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"#Blockchain\", \"#CryptoTech\", \"#Web3Dev\", \"#DLT\",\n",
    "                \"#SmartContracts\", \"#BuilderSpace\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"#DeFi\", \"#YieldFarming\", \"#Staking\", \"#DeFiSeason\",\n",
    "                \"#PassiveIncome\", \"#DeFiYield\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"#NFTs\", \"#NFTCommunity\", \"#NFTCollector\", \"#NFTArt\",\n",
    "                \"#NFTProject\", \"#TokenizedArt\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"#CryptoCulture\", \"#DAOs\", \"#Web3\", \"#CryptoTwitter\",\n",
    "                \"#CryptoLife\", \"#BuildingWeb3\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"#Crypto\", \"#Web3\", \"#Bitcoin\", \"#Ethereum\",\n",
    "                \"#CryptoTwitter\", \"#BuildingTheFuture\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "        # Add hashtags with 40% probability\n",
    "        if random.random() > 0.2:\n",
    "            return text\n",
    "    \n",
    "        remaining_chars = 280 - len(text)\n",
    "        if remaining_chars < 15:  # Not enough space for hashtags\n",
    "            return text\n",
    "    \n",
    "        category_hashtags = hashtags.get(category, hashtags[\"general\"])\n",
    "        selected_hashtags = []\n",
    "        \n",
    "        # Add 1-2 hashtags while respecting character limit\n",
    "        for _ in range(random.randint(1, 2)):\n",
    "            if not category_hashtags or remaining_chars < 15:\n",
    "                break\n",
    "            hashtag = random.choice(category_hashtags)\n",
    "            if len(hashtag) + 1 <= remaining_chars:\n",
    "                selected_hashtags.append(hashtag)\n",
    "                category_hashtags.remove(hashtag)\n",
    "                remaining_chars -= len(hashtag) + 1\n",
    "    \n",
    "        return f\"{text} {' '.join(selected_hashtags)}\"\n",
    "\n",
    "    def clean_response(self, text: str, category: str) -> str:\n",
    "        \"\"\"Clean and format the response for Twitter.\"\"\"\n",
    "        # Remove unwanted patterns\n",
    "        text = re.sub(r'@\\w+|http\\S+|\\[.*?\\]|\\(.*?\\)|\"|Q:|A:', '', text)\n",
    "        text = re.sub(r'\\b(Note|Example|Rules).*?(?=[.!?]|$)', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Split into sentences and filter\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        sentences = [s for s in sentences if len(s) > 20 and re.search(r'[.!?]$', s)]\n",
    "        \n",
    "        if not sentences:\n",
    "            return self.get_fallback(category)\n",
    "        \n",
    "        # Combine sentences with proper spacing\n",
    "        response = ' '.join(sentences[:2])\n",
    "        \n",
    "        # Add engaging elements\n",
    "        hook = self.generate_hook(category)\n",
    "        if hook:\n",
    "            response = f\"{hook} {response}\"\n",
    "        \n",
    "        engagement = self.generate_engagement_phrase(category)\n",
    "        if engagement:\n",
    "            response = f\"{response} {engagement}\"\n",
    "        \n",
    "        return response[:240]  # Leave room for hashtags/emojis\n",
    "\n",
    "    def get_fallback(self, category: str) -> str:\n",
    "        \"\"\"Generate category-specific fallback responses.\"\"\"\n",
    "        fallbacks = {\n",
    "            \"market_analysis\": [\n",
    "                \"Charts looking juicy today! Anyone else seeing this setup? ðŸ“ˆ\",\n",
    "                \"Market's giving mixed signals but the volume tells a different story ðŸ‘€\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Sometimes the best protocols are the ones no one's talking about yet ðŸ› ï¸\",\n",
    "                \"Imagine still building without considering Layer 2 scaling ðŸ’»\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"Your yields are only as good as your risk management ðŸ¦\",\n",
    "                \"DeFi summer never ended, we just got better at farming ðŸŒ¾\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"Art is subjective, but floor prices aren't ðŸŽ¨\",\n",
    "                \"Your NFT portfolio tells a story. Make it a good one ðŸ–¼ï¸\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Web3 culture is what we make it. Build accordingly ðŸŒ\",\n",
    "                \"Sometimes the real alpha is the friends we made along the way ðŸ¤\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Just caught myself thinking about the future of crypto while making coffee â˜•ï¸\",\n",
    "                \"Your portfolio is only as strong as your conviction ðŸ’Ž\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_fallbacks = fallbacks.get(category, fallbacks[\"general\"])\n",
    "        return random.choice(category_fallbacks)\n",
    "\n",
    "    def filter_tone(self, response: str) -> str:\n",
    "        \"\"\"Filter response tone and adjust if needed.\"\"\"\n",
    "        sentiment = TextBlob(response).sentiment\n",
    "        \n",
    "        if sentiment.polarity < -0.3:\n",
    "            return self.get_fallback(\"general\")\n",
    "        \n",
    "        if sentiment.subjectivity > 0.8:\n",
    "            # Too subjective, add a disclaimer\n",
    "            return f\"Not financial advice but... {response}\"\n",
    "            \n",
    "        return response\n",
    "    \n",
    "    def generate_response(self, prompt: str) -> str:\n",
    "        \"\"\"Generate a complete Twitter-ready response.\"\"\"\n",
    "        category = self.categorize_prompt(prompt)\n",
    "    \n",
    "        instruction = (\n",
    "            \"Mix the style of George Hotz and the comedian Theo Von. \"\n",
    "            \"You are a hilarious crypto and finance expert who aims to educate people and answer their questions accurately. \"\n",
    "            \"Use alot of slang and jargon. \"\n",
    "            \n",
    "            f\"Write a witty and engaging tweet about {category}-related topics. \"\n",
    "           \n",
    "            \n",
    "        )\n",
    "    \n",
    "        context = f\"{instruction}\\n\\nTweet:\"\n",
    "    \n",
    "        inputs = self.tokenizer(\n",
    "            context,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512  # Increased to accommodate the full context\n",
    "        ).to(device)\n",
    "    \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=80,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.7,\n",
    "                    top_k=60,\n",
    "                    top_p=0.9,\n",
    "                    repetition_penalty=1.5,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    eos_token_id=self.tokenizer.eos_token_id,\n",
    "                )\n",
    "    \n",
    "            generated_text = self.tokenizer.decode(\n",
    "                outputs[0],\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "    \n",
    "            # Extract the tweet from the generated text\n",
    "            response = generated_text.split(\"Tweet:\")[-1].strip().split(\"\\n\")[0]\n",
    "    \n",
    "            if not response or len(response) < 20:\n",
    "                return self.get_fallback(category)\n",
    "    \n",
    "            # Apply enhancements\n",
    "            response = self.clean_response(response, category)\n",
    "            response = self.filter_tone(response)\n",
    "            response = self.add_emojis(response, category)\n",
    "            response = self.add_hashtags(response, category)\n",
    "    \n",
    "            return response[:280]  # Ensure the response fits within Twitter's character limit\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating response: {str(e)}\")\n",
    "            return self.get_fallback(category)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        bot = PersonalityBot()\n",
    "        logger.info(\"Bot initialized successfully\")\n",
    "        \n",
    "        # Test prompts\n",
    "        test_prompts = [\n",
    "            \"How do gas fees compare between Ethereum and Solana?\",\n",
    "            \"Tell me why NFTs are either a scam or the future.\",\n",
    "            \"What's your take on Bitcoin as digital gold?\",\n",
    "            \"Explain staking in the context of DeFi but make it funny.\",\n",
    "            \"Give me a wild prediction for crypto in 2030.\",\n",
    "            \"What's a DAO, and should I care?\",\n",
    "            \"Can you explain why everyone's obsessed with Layer 2 solutions?\",\n",
    "            \"What's the wildest crypto meme you've seen this week?\",\n",
    "            \"How do I avoid FOMO during bull runs?\",\n",
    "            \"Is it too late to get into crypto? Be honest!\",\n",
    "            \"How would you describe Web3 to someone who barely uses the internet?\",\n",
    "            \"What's your hottest take on decentralized finance?\"\n",
    "        ]\n",
    "        \n",
    "        # Test run with basic prompts\n",
    "        logger.info(\"Starting test run with sample prompts...\")\n",
    "        print(\"\\n=== Test Run with Sample Prompts ===\")\n",
    "        for i, prompt in enumerate(test_prompts, 1):\n",
    "            print(f\"\\nPrompt {i}: {prompt}\")\n",
    "            start_time = time.time()\n",
    "            response = bot.generate_response(prompt)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(\"\")\n",
    "            print(f\"Response: {response}\")\n",
    "            print(f\"Runtime: {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # Interactive mode\n",
    "        logger.info(\"Entering interactive mode...\")\n",
    "        print(\"\\n=== Interactive Mode ===\")\n",
    "        print(\"Enter your prompts (type 'quit' to exit):\")\n",
    "        \n",
    "        while True:\n",
    "            user_prompt = input(\"\\nYour prompt: \").strip()\n",
    "            if user_prompt.lower() == 'quit':\n",
    "                print(\"Exiting... Thanks for using CryptoPersonalityBot!\")\n",
    "                break\n",
    "            if not user_prompt:\n",
    "                print(\"Please enter a valid prompt!\")\n",
    "                continue\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                response = bot.generate_response(user_prompt)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"Response: {response}\")\n",
    "                print(f\"Runtime: {elapsed_time:.2f} seconds\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing prompt: {str(e)}\")\n",
    "                print(\"Oops! Something went wrong. Please try again.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Application error: {str(e)}\")\n",
    "        print(\"Critical error occurred. Please check the logs for details.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1b51c-3aa0-4462-bc1b-b62591877b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c282f8-bd8b-419f-a632-e5bb1f75d447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690f0d1-1764-4d95-b503-6628527c57fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b960d-1803-458f-9385-3f3dfebceeba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tbot)",
   "language": "python",
   "name": "tbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
