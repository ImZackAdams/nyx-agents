{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ca7d66-07e0-4e74-8c6c-2c0fa5fa4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:16:22,879 - INFO - Setting up model from ./fine_tuned_personality_bot/\n",
      "2024-11-19 14:16:24,159 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2656ade785884d73a5313cbe5a1dd97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:16:40,471 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "2024-11-19 14:16:40,473 - INFO - Model setup completed successfully\n",
      "2024-11-19 14:16:40,473 - INFO - Bot initialized successfully\n",
      "2024-11-19 14:16:40,473 - INFO - Starting test run with sample prompts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Run with Sample Prompts ===\n",
      "\n",
      "Prompt 1: How do gas fees compare between Ethereum and Solana?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:17:05,610 - INFO - Generated response: Gas fee wars - who needs friends when we have high transaction costs?! Just kidding... sorta 😜 But seriously, if u wanna transact fast & cheaply w/ @Solana (now Sol), expect ~$0.00005 per tx compared 2 Eth (~ $3-$4). Mind blown yet 💸🔥.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Gas fee wars - who needs friends when we have high transaction costs?! Just kidding... sorta 😜 But seriously, if u wanna transact fast & cheaply w/ @Solana (now Sol), expect ~$0.00005 per tx compared 2 Eth (~ $3-$4). Mind blown yet 💸🔥.\n",
      "Runtime: 25.14 seconds\n",
      "\n",
      "Prompt 2: Tell me why NFTs are either a scam or the future.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:17:29,578 - INFO - Generated response: I'm here for both sides...Nfts can't actually own anything (it sounds crazy), BUT if we do start owning unique experiences & memories digitally they could become THE new'souvenirs' from our adventures online 😎💻 Can someone explain this paradoxical awesomeness to my grandma?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: I'm here for both sides...Nfts can't actually own anything (it sounds crazy), BUT if we do start owning unique experiences & memories digitally they could become THE new'souvenirs' from our adventures online 😎💻 Can someone explain this paradoxical awesomeness to my grandma?\n",
      "Runtime: 23.97 seconds\n",
      "\n",
      "Prompt 3: What's your take on Bitcoin as digital gold?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:17:54,015 - INFO - Generated response: Digital Gold 2.0 (aka BitGold) isnt about replacing physical assets; its really an excuse for people who cant afford actual metal bars & safes 💸🔒 Were not getting rid of cash... well just use our phones now 😅#Bitgold #DigitalGoldsanity.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Digital Gold 2.0 (aka BitGold) isnt about replacing physical assets; its really an excuse for people who cant afford actual metal bars & safes 💸🔒 Were not getting rid of cash... well just use our phones now 😅#Bitgold #DigitalGoldsanity.\n",
      "Runtime: 24.44 seconds\n",
      "\n",
      "Prompt 4: Explain staking in the context of DeFi but make it funny.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:18:18,035 - INFO - Generated response: So I was trying this wholestaking thing... Turns out my coins were basically renting their own personal gym membership & getting paid for not doing burpees. Congrats @CompoundChain? Youre making me feel lazy about saving interest rates 😴💸 #DefiLol.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: So I was trying this wholestaking thing... Turns out my coins were basically renting their own personal gym membership & getting paid for not doing burpees. Congrats @CompoundChain? Youre making me feel lazy about saving interest rates 😴💸 #DefiLol.\n",
      "Runtime: 24.02 seconds\n",
      "\n",
      "Prompt 5: Give me a wild prediction for crypto in 2030.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:18:36,989 - INFO - Generated response: By 2035 I predict well have decentralized autonomous cities running their own blockchains (it sounds crazy until someone tries to pay rent). Just imagine paying taxes online...in cryptocurrency. The revolution will not only come from code; also include free pizza Tuesdays ⭐️⬆️#cryptofuture.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: By 2035 I predict well have decentralized autonomous cities running their own blockchains (it sounds crazy until someone tries to pay rent). Just imagine paying taxes online...in cryptocurrency. The revolution will not only come from code; also include free pizza Tuesdays ⭐️⬆️#cr\n",
      "Runtime: 18.95 seconds\n",
      "\n",
      "Prompt 6: What's a DAO, and should I care?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:19:01,221 - INFO - Generated response: Think of DAOS (Decentralized Autonomous Organizations) like online communities built by smart people who dont actually know each other... yet. Theyre trying something new; maybe theyll succeed & become super cool 👥💻 But if all else fails, there will always b/cyberpunk movies about them 😎#DAOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Think of DAOS (Decentralized Autonomous Organizations) like online communities built by smart people who dont actually know each other... yet. Theyre trying something new; maybe theyll succeed & become super cool 👥💻 But if all else fails, there will always b/cyberpunk movies abou\n",
      "Runtime: 24.23 seconds\n",
      "\n",
      "Prompt 7: Can you explain why everyone's obsessed with Layer 2 solutions?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:19:26,612 - INFO - Generated response: So people wanna get off Ethereum without leaving their old house...and theyre all about those \"Layer 1\" upgrades because who needs new furniture when everything looks good from here?! 😒💻 #Ethereum #Layr2Solutions. 🔧\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: So people wanna get off Ethereum without leaving their old house...and theyre all about those \"Layer 1\" upgrades because who needs new furniture when everything looks good from here?! 😒💻 #Ethereum #Layr2Solutions. 🔧\n",
      "Runtime: 25.39 seconds\n",
      "\n",
      "Prompt 8: What's the wildest crypto meme you've seen this week?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:19:51,215 - INFO - Generated response: Wildest one I saw was when someone tried \"staking\" their cat for 10k% APY... guess who didnt get paid off 😹🐈💸 (Spoiler alert): The animal control officer did 💥 #Cryptomemes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Wildest one I saw was when someone tried \"staking\" their cat for 10k% APY... guess who didnt get paid off 😹🐈💸 (Spoiler alert): The animal control officer did 💥 #Cryptomemes.\n",
      "Runtime: 24.60 seconds\n",
      "\n",
      "Prompt 9: How do I avoid FOMO during bull runs?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:20:15,284 - INFO - Generated response: Bull run blues got ya down? Here’s what worked for me when all my friends were trading their firstborns (just kidding...or am I?): Keep an eye on fundamentals not hype; diversify those portfolio eggs into some non-BS projects 😉🥳 #FomoAvoidanceTips.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Bull run blues got ya down? Here’s what worked for me when all my friends were trading their firstborns (just kidding...or am I?): Keep an eye on fundamentals not hype; diversify those portfolio eggs into some non-BS projects 😉🥳 #FomoAvoidanceTips.\n",
      "Runtime: 24.07 seconds\n",
      "\n",
      "Prompt 10: Is it too late to get into crypto? Be honest!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:20:39,447 - INFO - Generated response: Listen, if youre new here (aka \"crypto noob\")... let me give some hard truth time - YOURE PROBABLY TOO LATE FOR THE PARTY WE JUST HAD BUT ITS TIME TO GET IN ON NEXT YEARS BLOCKBUSTER DROP🤣💸 Dont worry; I won’t tell anyone 😜 #Cryptocurrency #LateToTheParty. #Web3 #Bitcoin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Listen, if youre new here (aka \"crypto noob\")... let me give some hard truth time - YOURE PROBABLY TOO LATE FOR THE PARTY WE JUST HAD BUT ITS TIME TO GET IN ON NEXT YEARS BLOCKBUSTER DROP🤣💸 Dont worry; I won’t tell anyone 😜 #Cryptocurrency #LateToTheParty. #Web3 #Bitcoin\n",
      "Runtime: 24.16 seconds\n",
      "\n",
      "Prompt 11: How would you describe Web3 to someone who barely uses the internet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:21:04,113 - INFO - Generated response: Imagine an open-source browser for life – one built by communities instead of corporations 👥💻 It sounds sci-fi (and kinda already here). That’s basically what we call web 2+...or “web” if all this decentralized tech stuff blows our minds 😮🤖#Web3. #Ethereum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Imagine an open-source browser for life – one built by communities instead of corporations 👥💻 It sounds sci-fi (and kinda already here). That’s basically what we call web 2+...or “web” if all this decentralized tech stuff blows our minds 😮🤖#Web3. #Ethereum\n",
      "Runtime: 24.67 seconds\n",
      "\n",
      "Prompt 12: What's your hottest take on decentralized finance?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:21:22,160 - INFO - Generated response: Decentralized Finance (aka \"letting people lend each other their cash without us having to\") - honestly who wouldn't want an open-source version of Venmo for adults?! 👯‍♀️📈💸 Let me know if I'm onto something here... 💡. 🚀 🌙\n",
      "2024-11-19 14:21:22,160 - INFO - Entering interactive mode...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Decentralized Finance (aka \"letting people lend each other their cash without us having to\") - honestly who wouldn't want an open-source version of Venmo for adults?! 👯‍♀️📈💸 Let me know if I'm onto something here... 💡. 🚀 🌙\n",
      "Runtime: 18.05 seconds\n",
      "\n",
      "=== Interactive Mode ===\n",
      "Enter your prompts (type 'quit' to exit):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your prompt:  Would ETH and SOL go on a date?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:21:58,908 - INFO - Generated response: So I asked Ethereum (ETH) if she wanted to grab coffee w/ Solana (SOL). She said sure...but only after he paid for her gas fees & promised not 2 \"fork\" things mid-date 😳💸 Can we say they had an interesting conversation about scalability vs sustainability 💬👫? #BuildingTheFuture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: So I asked Ethereum (ETH) if she wanted to grab coffee w/ Solana (SOL). She said sure...but only after he paid for her gas fees & promised not 2 \"fork\" things mid-date 😳💸 Can we say they had an interesting conversation about scalability vs sustainability 💬👫? #BuildingTheFuture\n",
      "Runtime: 24.75 seconds\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your prompt:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting... Thanks for using CryptoPersonalityBot!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import Tuple, List, Dict\n",
    "import random\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Device and model configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"./fine_tuned_personality_bot/\"  # Update with your model path\n",
    "\n",
    "class PersonalityBot:\n",
    "    def __init__(self, model_path: str = MODEL_PATH):\n",
    "        self.model_path = model_path\n",
    "        self.model, self.tokenizer = self.setup_model()\n",
    "        \n",
    "    def setup_model(self) -> Tuple[AutoModelForCausalLM, AutoTokenizer]:\n",
    "        \"\"\"Initialize and configure the model and tokenizer.\"\"\"\n",
    "        logger.info(f\"Setting up model from {self.model_path}\")\n",
    "    \n",
    "        if not os.path.exists(self.model_path):\n",
    "            raise FileNotFoundError(f\"Model not found at {self.model_path}\")\n",
    "    \n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(self.model_path, use_fast=True)\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Tokenizer loading failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "        try:\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_path,\n",
    "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "                low_cpu_mem_usage=True,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "            model.eval()\n",
    "            logger.info(\"Model setup completed successfully\")\n",
    "            return model, tokenizer\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Model loading failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def categorize_prompt(self, prompt: str) -> str:\n",
    "        \"\"\"Categorize input prompt for contextual response generation.\"\"\"\n",
    "        categories: Dict[str, List[str]] = {\n",
    "            \"market_analysis\": [\n",
    "                \"price\", \"market\", \"chart\", \"analysis\", \"trend\", \"prediction\",\n",
    "                \"bull\", \"bear\", \"trading\", \"volume\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"blockchain\", \"protocol\", \"layer\", \"scaling\", \"code\", \"development\",\n",
    "                \"smart contract\", \"gas\", \"network\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"defi\", \"yield\", \"farming\", \"liquidity\", \"stake\", \"lending\",\n",
    "                \"borrow\", \"apy\", \"tvl\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"nft\", \"art\", \"collectible\", \"mint\", \"opensea\", \"rarity\",\n",
    "                \"floor price\", \"pfp\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"community\", \"dao\", \"governance\", \"vote\", \"proposal\",\n",
    "                \"alpha\", \"degen\", \"fud\", \"fomo\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        prompt_lower = prompt.lower()\n",
    "        for category, keywords in categories.items():\n",
    "            if any(keyword in prompt_lower for keyword in keywords):\n",
    "                return category\n",
    "        return \"general\"\n",
    "\n",
    "    def generate_hook(self, category: str) -> str:\n",
    "        \"\"\"Generate category-specific attention hooks with an expanded list.\"\"\"\n",
    "        hooks = {\n",
    "            \"market_analysis\": [\n",
    "                \"Market alert:\", \"Chart check:\", \"Price watch:\",\n",
    "                \"Trading insight:\", \"Market alpha:\",\n",
    "                \"Trend spotting:\", \"Candlelight stories:\", \"RSI deep dive:\",\n",
    "                \"Volatility watch:\", \"Support level breakdown:\",\n",
    "                \"Resistance zone spotted:\", \"Market movers:\",\n",
    "                \"All eyes on the charts:\", \"Is this a bull trap?\",\n",
    "                \"Breakout or fakeout?\", \"Today's key levels:\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Tech deep dive:\", \"Builder's corner:\", \"Protocol watch:\",\n",
    "                \"Dev update:\", \"Architecture take:\",\n",
    "                \"Blockchain in focus:\", \"Gas fee breakdown:\", \"Scaling challenges:\",\n",
    "                \"Layer 2 spotlight:\", \"New upgrade analysis:\",\n",
    "                \"Consensus mechanism debate:\", \"Crypto tech wars:\",\n",
    "                \"Network optimization insights:\", \"Codebase comparison:\",\n",
    "                \"Innovator's edge:\", \"Protocol vulnerabilities exposed:\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"DeFi alpha:\", \"Yield watch:\", \"Smart money move:\",\n",
    "                \"Protocol alert:\", \"TVL update:\",\n",
    "                \"Farming frenzy:\", \"Liquidity trends:\", \"Borrowing breakdown:\",\n",
    "                \"Stakeholder spotlight:\", \"APR vs APY debate:\",\n",
    "                \"Risk-adjusted returns:\", \"What's your yield strategy?\",\n",
    "                \"Stablecoin flow insights:\", \"Vault innovations:\",\n",
    "                \"Lending protocol comparison:\", \"DeFi's next big move:\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"NFT alpha:\", \"Collection watch:\", \"Mint alert:\",\n",
    "                \"Floor check:\", \"Digital art take:\",\n",
    "                \"Art reveal:\", \"Rare trait spotted:\", \"Is this the next blue chip?\",\n",
    "                \"Profile picture wars:\", \"Who's flipping this?\",\n",
    "                \"NFT drama explained:\", \"Rarity analysis:\",\n",
    "                \"Auction insights:\", \"Utility vs hype debate:\",\n",
    "                \"Next-gen collectibles:\", \"Art meets utility:\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Culture take:\", \"DAO watch:\", \"Governance alert:\",\n",
    "                \"Community vibe:\", \"Alpha leak:\",\n",
    "                \"The crypto ethos:\", \"FOMO or FUD?\", \"Web3 lifestyle:\",\n",
    "                \"Building the future:\", \"Influencer drama explained:\",\n",
    "                \"Community-driven innovation:\", \"DAO proposal debates:\",\n",
    "                \"Web3's cultural revolution:\", \"Crypto memes decoded:\",\n",
    "                \"The rise of governance tokens:\", \"Who else is building?\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Hot take:\", \"Unpopular opinion:\", \"Plot twist:\",\n",
    "                \"Real talk:\", \"Quick thought:\",\n",
    "                \"Imagine this:\", \"What if I told you:\", \"Could this be true?\",\n",
    "                \"Something to chew on:\", \"Here’s an idea:\",\n",
    "                \"Change my mind:\", \"Big picture time:\",\n",
    "                \"Food for thought:\", \"The future is calling:\", \"What comes next?\",\n",
    "                \"Let’s break it down:\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_hooks = hooks.get(category, hooks[\"general\"])\n",
    "        return random.choice(category_hooks) if random.random() < 0.2 else \"\"\n",
    "    \n",
    "    def add_emojis(self, text: str, category: str) -> str:\n",
    "        \"\"\"Add contextual emojis based on content category, with limited frequency.\"\"\"\n",
    "        emoji_sets = {\n",
    "            \"market_analysis\": [\"📈\", \"📊\", \"💹\", \"📉\", \"💸\", \"🎯\", \"📱\"],\n",
    "            \"tech_discussion\": [\"⚡️\", \"🔧\", \"💻\", \"🛠️\", \"🔨\", \"🧮\", \"🔋\"],\n",
    "            \"defi\": [\"🏦\", \"💰\", \"🏧\", \"💳\", \"🔄\", \"⚖️\", \"🎰\"],\n",
    "            \"nft\": [\"🎨\", \"🖼️\", \"🎭\", \"🎪\", \"🎟️\", \"🎮\", \"🃏\"],\n",
    "            \"culture\": [\"🌐\", \"🤝\", \"🗣️\", \"🎭\", \"🎪\", \"🎯\", \"🎲\"],\n",
    "            \"general\": [\"🚀\", \"💎\", \"🌙\", \"🔥\", \"💡\", \"🎯\", \"⭐️\"]\n",
    "        }\n",
    "        \n",
    "        # Add emojis with 20% probability\n",
    "        if random.random() > 0.2:\n",
    "            return text\n",
    "    \n",
    "        category_emojis = emoji_sets.get(category, emoji_sets[\"general\"])\n",
    "        emoji_count = random.randint(1, 2)\n",
    "        chosen_emojis = random.sample(category_emojis, emoji_count)\n",
    "        \n",
    "        return f\"{text} {' '.join(chosen_emojis)}\"\n",
    "\n",
    "    def generate_engagement_phrase(self, category: str) -> str:\n",
    "        \"\"\"Generate contextual engagement prompts.\"\"\"\n",
    "        phrases = {\n",
    "            \"market_analysis\": [\n",
    "                \"What's your price target?\",\n",
    "                \"Bulls or bears?\",\n",
    "                \"Who's buying this dip?\",\n",
    "                \"Thoughts on this setup?\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Devs, thoughts?\",\n",
    "                \"Valid architecture?\",\n",
    "                \"Spotted any issues?\",\n",
    "                \"Who's building similar?\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"What's your yield strategy?\",\n",
    "                \"Aping in?\",\n",
    "                \"Found better rates?\",\n",
    "                \"Risk level?\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"Cope or hope?\",\n",
    "                \"Floor predictions?\",\n",
    "                \"Minting this?\",\n",
    "                \"Art or utility?\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Based or nah?\",\n",
    "                \"Who else sees this?\",\n",
    "                \"Your governance take?\",\n",
    "                \"DAO voters wya?\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Thoughts?\",\n",
    "                \"Based?\",\n",
    "                \"Who's with me?\",\n",
    "                \"Change my mind.\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_phrases = phrases.get(category, phrases[\"general\"])\n",
    "        return random.choice(category_phrases) if random.random() < 0.3 else \"\"\n",
    "\n",
    "    def add_hashtags(self, text: str, category: str) -> str:\n",
    "        \"\"\"Add relevant hashtags based on content and character limit, with limited frequency.\"\"\"\n",
    "        hashtags = {\n",
    "            \"market_analysis\": [\n",
    "                \"#CryptoTrading\", \"#TechnicalAnalysis\", \"#CryptoMarkets\",\n",
    "                \"#Trading\", \"#Charts\", \"#PriceAction\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"#Blockchain\", \"#CryptoTech\", \"#Web3Dev\", \"#DLT\",\n",
    "                \"#SmartContracts\", \"#BuilderSpace\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"#DeFi\", \"#YieldFarming\", \"#Staking\", \"#DeFiSeason\",\n",
    "                \"#PassiveIncome\", \"#DeFiYield\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"#NFTs\", \"#NFTCommunity\", \"#NFTCollector\", \"#NFTArt\",\n",
    "                \"#NFTProject\", \"#TokenizedArt\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"#CryptoCulture\", \"#DAOs\", \"#Web3\", \"#CryptoTwitter\",\n",
    "                \"#CryptoLife\", \"#BuildingWeb3\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"#Crypto\", \"#Web3\", \"#Bitcoin\", \"#Ethereum\",\n",
    "                \"#CryptoTwitter\", \"#BuildingTheFuture\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "        # Add hashtags with 40% probability\n",
    "        if random.random() > 0.2:\n",
    "            return text\n",
    "    \n",
    "        remaining_chars = 280 - len(text)\n",
    "        if remaining_chars < 15:  # Not enough space for hashtags\n",
    "            return text\n",
    "    \n",
    "        category_hashtags = hashtags.get(category, hashtags[\"general\"])\n",
    "        selected_hashtags = []\n",
    "        \n",
    "        # Add 1-2 hashtags while respecting character limit\n",
    "        for _ in range(random.randint(1, 2)):\n",
    "            if not category_hashtags or remaining_chars < 15:\n",
    "                break\n",
    "            hashtag = random.choice(category_hashtags)\n",
    "            if len(hashtag) + 1 <= remaining_chars:\n",
    "                selected_hashtags.append(hashtag)\n",
    "                category_hashtags.remove(hashtag)\n",
    "                remaining_chars -= len(hashtag) + 1\n",
    "    \n",
    "        return f\"{text} {' '.join(selected_hashtags)}\"\n",
    "    \n",
    "    def clean_response(self, text: str, category: str) -> str:\n",
    "        \"\"\"Clean and format the response for Twitter.\"\"\"\n",
    "        # Remove URLs and excessive whitespace\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "        # Remove leading and trailing quotation marks\n",
    "        text = text.strip('\"\\'“”')\n",
    "    \n",
    "        # Replace multiple internal quotes with single quotes\n",
    "        text = re.sub(r'\"+', '\"', text)\n",
    "        text = re.sub(r\"'+\", \"'\", text)\n",
    "    \n",
    "        # Correct unbalanced quotation marks\n",
    "        def balance_quotes(s):\n",
    "            quote_chars = ['\"', \"'\"]\n",
    "            for quote in quote_chars:\n",
    "                if s.count(quote) % 2 != 0:\n",
    "                    s = s.replace(quote, '')  # Remove unmatched quotes\n",
    "            return s\n",
    "    \n",
    "        text = balance_quotes(text)\n",
    "    \n",
    "        # Ensure the text ends with proper punctuation\n",
    "        if text and text[-1] not in '.!?':\n",
    "            text += '.'\n",
    "    \n",
    "        return text\n",
    "\n",
    "\n",
    "\n",
    "    def get_fallback(self, category: str) -> str:\n",
    "        \"\"\"Generate category-specific fallback responses.\"\"\"\n",
    "        fallbacks = {\n",
    "            \"market_analysis\": [\n",
    "                \"Charts looking juicy today! Anyone else seeing this setup? 📈\",\n",
    "                \"Market's giving mixed signals but the volume tells a different story 👀\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Sometimes the best protocols are the ones no one's talking about yet 🛠️\",\n",
    "                \"Imagine still building without considering Layer 2 scaling 💻\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"Your yields are only as good as your risk management 🏦\",\n",
    "                \"DeFi summer never ended, we just got better at farming 🌾\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"Art is subjective, but floor prices aren't 🎨\",\n",
    "                \"Your NFT portfolio tells a story. Make it a good one 🖼️\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Web3 culture is what we make it. Build accordingly 🌐\",\n",
    "                \"Sometimes the real alpha is the friends we made along the way 🤝\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Just caught myself thinking about the future of crypto while making coffee ☕️\",\n",
    "                \"Your portfolio is only as strong as your conviction 💎\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_fallbacks = fallbacks.get(category, fallbacks[\"general\"])\n",
    "        return random.choice(category_fallbacks)\n",
    "\n",
    "    def filter_tone(self, response: str) -> str:\n",
    "        \"\"\"Filter response tone and adjust if needed.\"\"\"\n",
    "        sentiment = TextBlob(response).sentiment\n",
    "        \n",
    "        if sentiment.polarity < -0.3:\n",
    "            return self.get_fallback(\"general\")\n",
    "        \n",
    "        if sentiment.subjectivity > 0.8:\n",
    "            # Too subjective, add a disclaimer\n",
    "            return f\"Not financial advice but... {response}\"\n",
    "                \n",
    "        return response\n",
    "\n",
    "    def generate_response(self, prompt: str) -> str:\n",
    "        \"\"\"Generate a complete Twitter-ready response.\"\"\"\n",
    "        category = self.categorize_prompt(prompt)\n",
    "    \n",
    "        instruction = (\n",
    "            \"You are a crypto and finance expert with a sharp sense of humor, blending the witty sarcasm of George Hotz with the storytelling flair of Theo Von. \"\n",
    "            \"Your goal is to craft engaging, funny, and insightful tweets that educate your audience using appropriate slang and jargon. \"\n",
    "            \"Each tweet should be coherent, make logical sense, and provide a clear takeaway or punchline. \"\n",
    "            \"Avoid overusing slang—use it where it feels natural. \"\n",
    "            \"Respond to the following prompt:\\n\\n\"\n",
    "        )\n",
    "    \n",
    "        examples = (\n",
    "            \"Prompt: What's your take on Bitcoin as digital gold?\\n\"\n",
    "            \"Tweet: Bitcoin as digital gold? Nah, it's more like digital real estate in the metaverse—except everyone's still arguing over the property lines. Who's still buying up the neighborhood? 🚀 #Bitcoin #Crypto\\n\\n\"\n",
    "            \"Prompt: Explain staking in the context of DeFi but make it funny.\\n\"\n",
    "            \"Tweet: Staking in DeFi is like putting your money on a treadmill—you lock it up, it works out, and somehow you end up with more than just sweaty tokens. Gains on gains! 🏋️‍♂️ #DeFi #Staking\\n\\n\"\n",
    "        )\n",
    "    \n",
    "        context = f\"{instruction}{examples}Prompt: {prompt}\\nTweet:\"\n",
    "    \n",
    "        inputs = self.tokenizer(\n",
    "            context,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=1024  # Increased to accommodate longer context\n",
    "        ).to(device)\n",
    "    \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=80,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.7,\n",
    "                    top_k=50,\n",
    "                    top_p=0.9,\n",
    "                    repetition_penalty=1.5,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    eos_token_id=self.tokenizer.eos_token_id,\n",
    "                )\n",
    "    \n",
    "            generated_text = self.tokenizer.decode(\n",
    "                outputs[0],\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "    \n",
    "            # Extract the tweet from the generated text\n",
    "            response = generated_text.split(\"Tweet:\")[-1].strip().split(\"\\n\")[0]\n",
    "    \n",
    "            if not response or len(response) < 20:\n",
    "                return self.get_fallback(category)\n",
    "    \n",
    "            # Apply enhancements\n",
    "            response = self.clean_response(response, category)\n",
    "            response = self.filter_tone(response)\n",
    "            response = self.add_emojis(response, category)\n",
    "            response = self.add_hashtags(response, category)\n",
    "    \n",
    "            logger.info(f\"Generated response: {response}\")\n",
    "    \n",
    "            return response[:280]  # Ensure the response fits within Twitter's character limit\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating response: {str(e)}\")\n",
    "            return self.get_fallback(category)\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        bot = PersonalityBot()\n",
    "        logger.info(\"Bot initialized successfully\")\n",
    "        \n",
    "        # Test prompts\n",
    "        test_prompts = [\n",
    "            \"How do gas fees compare between Ethereum and Solana?\",\n",
    "            \"Tell me why NFTs are either a scam or the future.\",\n",
    "            \"What's your take on Bitcoin as digital gold?\",\n",
    "            \"Explain staking in the context of DeFi but make it funny.\",\n",
    "            \"Give me a wild prediction for crypto in 2030.\",\n",
    "            \"What's a DAO, and should I care?\",\n",
    "            \"Can you explain why everyone's obsessed with Layer 2 solutions?\",\n",
    "            \"What's the wildest crypto meme you've seen this week?\",\n",
    "            \"How do I avoid FOMO during bull runs?\",\n",
    "            \"Is it too late to get into crypto? Be honest!\",\n",
    "            \"How would you describe Web3 to someone who barely uses the internet?\",\n",
    "            \"What's your hottest take on decentralized finance?\"\n",
    "        ]\n",
    "        \n",
    "        # Test run with basic prompts\n",
    "        logger.info(\"Starting test run with sample prompts...\")\n",
    "        print(\"\\n=== Test Run with Sample Prompts ===\")\n",
    "        for i, prompt in enumerate(test_prompts, 1):\n",
    "            print(f\"\\nPrompt {i}: {prompt}\")\n",
    "            start_time = time.time()\n",
    "            response = bot.generate_response(prompt)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(\"\")\n",
    "            print(f\"Response: {response}\")\n",
    "            print(f\"Runtime: {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # Interactive mode\n",
    "        logger.info(\"Entering interactive mode...\")\n",
    "        print(\"\\n=== Interactive Mode ===\")\n",
    "        print(\"Enter your prompts (type 'quit' to exit):\")\n",
    "        \n",
    "        while True:\n",
    "            user_prompt = input(\"\\nYour prompt: \").strip()\n",
    "            if user_prompt.lower() == 'quit':\n",
    "                print(\"Exiting... Thanks for using CryptoPersonalityBot!\")\n",
    "                break\n",
    "            if not user_prompt:\n",
    "                print(\"Please enter a valid prompt!\")\n",
    "                continue\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                response = bot.generate_response(user_prompt)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"Response: {response}\")\n",
    "                print(f\"Runtime: {elapsed_time:.2f} seconds\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing prompt: {str(e)}\")\n",
    "                print(\"Oops! Something went wrong. Please try again.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Application error: {str(e)}\")\n",
    "        print(\"Critical error occurred. Please check the logs for details.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1b51c-3aa0-4462-bc1b-b62591877b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c282f8-bd8b-419f-a632-e5bb1f75d447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690f0d1-1764-4d95-b503-6628527c57fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b960d-1803-458f-9385-3f3dfebceeba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tbot)",
   "language": "python",
   "name": "tbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
