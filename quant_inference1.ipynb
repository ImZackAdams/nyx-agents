{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca7d66-07e0-4e74-8c6c-2c0fa5fa4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:54:38,862 - INFO - Setting up model from ./fine_tuned_personality_bot/\n",
      "2024-11-19 14:54:40,055 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f78b038816e4f93ab1c2c0833c8c019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:54:51,556 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "2024-11-19 14:54:51,557 - INFO - Model setup completed successfully\n",
      "2024-11-19 14:54:51,558 - INFO - Bot initialized successfully\n",
      "2024-11-19 14:54:51,558 - INFO - Entering interactive mode...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Interactive Mode ===\n",
      "Enter your prompts (type 'quit' to exit):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your prompt:  Think out loud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:55:59,598 - INFO - Generated response: Im thinking... what if we took all these blockchain games & turned them into decentralized reality TV shows Anyone can create their own character backstory (Ethereum-based), participate in wild challenges for NFT rewards...(how would this work?) Ideas welcome! üí°üì∫üíª #BlockchainGaming #DecentralizedRealityTV.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Im thinking... what if we took all these blockchain games & turned them into decentralized reality TV shows Anyone can create their own character backstory (Ethereum-based), participate in wild challenges for NFT rewards...(how would this work?) Ideas welcome! üí°üì∫üíª #BlockchainGami\n",
      "Runtime: 21.90 seconds\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your prompt:  think out loud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:56:44,433 - INFO - Generated response: What if I told ya... blockchain isn't actually secure because we're all secretly worried about 51% attacks & our moms know how many times she can withdraw cash from her ATM before they notice anything fishy üí∏üëµ The harsh truth behind decentralized security (kinda) üòú#BlockchainSecurity.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: What if I told ya... blockchain isn't actually secure because we're all secretly worried about 51% attacks & our moms know how many times she can withdraw cash from her ATM before they notice anything fishy üí∏üëµ The harsh truth behind decentralized security (kinda) üòú#BlockchainSecu\n",
      "Runtime: 23.93 seconds\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your prompt:  think out loud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:57:47,588 - INFO - Generated response: Not financial advice but... I'm thinking... If I invest all my 401k into Solana (SOL) now vs holding onto traditional stocks/volatility-adjacent assets for stability & growth potential what am't wrong w/ taking calculated risks? Is this an opportunity cost tradeoff at play?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Not financial advice but... I'm thinking... If I invest all my 401k into Solana (SOL) now vs holding onto traditional stocks/volatility-adjacent assets for stability & growth potential what am't wrong w/ taking calculated risks? Is this an opportunity cost tradeoff at play?\n",
      "Runtime: 24.51 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import Tuple, List, Dict\n",
    "import random\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Device and model configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"./fine_tuned_personality_bot/\"  # Update with your model path\n",
    "\n",
    "class PersonalityBot:\n",
    "    def __init__(self, model_path: str = MODEL_PATH):\n",
    "        self.model_path = model_path\n",
    "        self.model, self.tokenizer = self.setup_model()\n",
    "        \n",
    "    def setup_model(self) -> Tuple[AutoModelForCausalLM, AutoTokenizer]:\n",
    "        \"\"\"Initialize and configure the model and tokenizer.\"\"\"\n",
    "        logger.info(f\"Setting up model from {self.model_path}\")\n",
    "    \n",
    "        if not os.path.exists(self.model_path):\n",
    "            raise FileNotFoundError(f\"Model not found at {self.model_path}\")\n",
    "    \n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(self.model_path, use_fast=True)\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Tokenizer loading failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "        try:\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_path,\n",
    "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "                low_cpu_mem_usage=True,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "            model.eval()\n",
    "            logger.info(\"Model setup completed successfully\")\n",
    "            return model, tokenizer\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Model loading failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def categorize_prompt(self, prompt: str) -> str:\n",
    "        \"\"\"Categorize input prompt for contextual response generation.\"\"\"\n",
    "        categories: Dict[str, List[str]] = {\n",
    "            \"market_analysis\": [\n",
    "                \"price\", \"market\", \"chart\", \"analysis\", \"trend\", \"prediction\",\n",
    "                \"bull\", \"bear\", \"trading\", \"volume\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"blockchain\", \"protocol\", \"layer\", \"scaling\", \"code\", \"development\",\n",
    "                \"smart contract\", \"gas\", \"network\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"defi\", \"yield\", \"farming\", \"liquidity\", \"stake\", \"lending\",\n",
    "                \"borrow\", \"apy\", \"tvl\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"nft\", \"art\", \"collectible\", \"mint\", \"opensea\", \"rarity\",\n",
    "                \"floor price\", \"pfp\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"community\", \"dao\", \"governance\", \"vote\", \"proposal\",\n",
    "                \"alpha\", \"degen\", \"fud\", \"fomo\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        prompt_lower = prompt.lower()\n",
    "        for category, keywords in categories.items():\n",
    "            if any(keyword in prompt_lower for keyword in keywords):\n",
    "                return category\n",
    "        return \"general\"\n",
    "\n",
    "    def generate_hook(self, category: str) -> str:\n",
    "        \"\"\"Generate category-specific attention hooks with an expanded list.\"\"\"\n",
    "        hooks = {\n",
    "            \"market_analysis\": [\n",
    "                \"Market alert:\", \"Chart check:\", \"Price watch:\",\n",
    "                \"Trading insight:\", \"Market alpha:\",\n",
    "                \"Trend spotting:\", \"Candlelight stories:\", \"RSI deep dive:\",\n",
    "                \"Volatility watch:\", \"Support level breakdown:\",\n",
    "                \"Resistance zone spotted:\", \"Market movers:\",\n",
    "                \"All eyes on the charts:\", \"Is this a bull trap?\",\n",
    "                \"Breakout or fakeout?\", \"Today's key levels:\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Tech deep dive:\", \"Builder's corner:\", \"Protocol watch:\",\n",
    "                \"Dev update:\", \"Architecture take:\",\n",
    "                \"Blockchain in focus:\", \"Gas fee breakdown:\", \"Scaling challenges:\",\n",
    "                \"Layer 2 spotlight:\", \"New upgrade analysis:\",\n",
    "                \"Consensus mechanism debate:\", \"Crypto tech wars:\",\n",
    "                \"Network optimization insights:\", \"Codebase comparison:\",\n",
    "                \"Innovator's edge:\", \"Protocol vulnerabilities exposed:\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"DeFi alpha:\", \"Yield watch:\", \"Smart money move:\",\n",
    "                \"Protocol alert:\", \"TVL update:\",\n",
    "                \"Farming frenzy:\", \"Liquidity trends:\", \"Borrowing breakdown:\",\n",
    "                \"Stakeholder spotlight:\", \"APR vs APY debate:\",\n",
    "                \"Risk-adjusted returns:\", \"What's your yield strategy?\",\n",
    "                \"Stablecoin flow insights:\", \"Vault innovations:\",\n",
    "                \"Lending protocol comparison:\", \"DeFi's next big move:\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"NFT alpha:\", \"Collection watch:\", \"Mint alert:\",\n",
    "                \"Floor check:\", \"Digital art take:\",\n",
    "                \"Art reveal:\", \"Rare trait spotted:\", \"Is this the next blue chip?\",\n",
    "                \"Profile picture wars:\", \"Who's flipping this?\",\n",
    "                \"NFT drama explained:\", \"Rarity analysis:\",\n",
    "                \"Auction insights:\", \"Utility vs hype debate:\",\n",
    "                \"Next-gen collectibles:\", \"Art meets utility:\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Culture take:\", \"DAO watch:\", \"Governance alert:\",\n",
    "                \"Community vibe:\", \"Alpha leak:\",\n",
    "                \"The crypto ethos:\", \"FOMO or FUD?\", \"Web3 lifestyle:\",\n",
    "                \"Building the future:\", \"Influencer drama explained:\",\n",
    "                \"Community-driven innovation:\", \"DAO proposal debates:\",\n",
    "                \"Web3's cultural revolution:\", \"Crypto memes decoded:\",\n",
    "                \"The rise of governance tokens:\", \"Who else is building?\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Hot take:\", \"Unpopular opinion:\", \"Plot twist:\",\n",
    "                \"Real talk:\", \"Quick thought:\",\n",
    "                \"Imagine this:\", \"What if I told you:\", \"Could this be true?\",\n",
    "                \"Something to chew on:\", \"Here‚Äôs an idea:\",\n",
    "                \"Change my mind:\", \"Big picture time:\",\n",
    "                \"Food for thought:\", \"The future is calling:\", \"What comes next?\",\n",
    "                \"Let‚Äôs break it down:\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_hooks = hooks.get(category, hooks[\"general\"])\n",
    "        return random.choice(category_hooks) if random.random() < 0.2 else \"\"\n",
    "    \n",
    "    def add_emojis(self, text: str, category: str) -> str:\n",
    "        \"\"\"Add contextual emojis based on content category, with limited frequency.\"\"\"\n",
    "        emoji_sets = {\n",
    "            \"market_analysis\": [\"üìà\", \"üìä\", \"üíπ\", \"üìâ\", \"üí∏\", \"üéØ\", \"üì±\"],\n",
    "            \"tech_discussion\": [\"‚ö°Ô∏è\", \"üîß\", \"üíª\", \"üõ†Ô∏è\", \"üî®\", \"üßÆ\", \"üîã\"],\n",
    "            \"defi\": [\"üè¶\", \"üí∞\", \"üèß\", \"üí≥\", \"üîÑ\", \"‚öñÔ∏è\", \"üé∞\"],\n",
    "            \"nft\": [\"üé®\", \"üñºÔ∏è\", \"üé≠\", \"üé™\", \"üéüÔ∏è\", \"üéÆ\", \"üÉè\"],\n",
    "            \"culture\": [\"üåê\", \"ü§ù\", \"üó£Ô∏è\", \"üé≠\", \"üé™\", \"üéØ\", \"üé≤\"],\n",
    "            \"general\": [\"üöÄ\", \"üíé\", \"üåô\", \"üî•\", \"üí°\", \"üéØ\", \"‚≠êÔ∏è\"]\n",
    "        }\n",
    "        \n",
    "        # Add emojis with 20% probability\n",
    "        if random.random() > 0.2:\n",
    "            return text\n",
    "    \n",
    "        category_emojis = emoji_sets.get(category, emoji_sets[\"general\"])\n",
    "        emoji_count = random.randint(1, 2)\n",
    "        chosen_emojis = random.sample(category_emojis, emoji_count)\n",
    "        \n",
    "        return f\"{text} {' '.join(chosen_emojis)}\"\n",
    "\n",
    "    def generate_engagement_phrase(self, category: str) -> str:\n",
    "        \"\"\"Generate contextual engagement prompts.\"\"\"\n",
    "        phrases = {\n",
    "            \"market_analysis\": [\n",
    "                \"What's your price target?\",\n",
    "                \"Bulls or bears?\",\n",
    "                \"Who's buying this dip?\",\n",
    "                \"Thoughts on this setup?\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Devs, thoughts?\",\n",
    "                \"Valid architecture?\",\n",
    "                \"Spotted any issues?\",\n",
    "                \"Who's building similar?\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"What's your yield strategy?\",\n",
    "                \"Aping in?\",\n",
    "                \"Found better rates?\",\n",
    "                \"Risk level?\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"Cope or hope?\",\n",
    "                \"Floor predictions?\",\n",
    "                \"Minting this?\",\n",
    "                \"Art or utility?\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Based or nah?\",\n",
    "                \"Who else sees this?\",\n",
    "                \"Your governance take?\",\n",
    "                \"DAO voters wya?\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Thoughts?\",\n",
    "                \"Based?\",\n",
    "                \"Who's with me?\",\n",
    "                \"Change my mind.\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_phrases = phrases.get(category, phrases[\"general\"])\n",
    "        return random.choice(category_phrases) if random.random() < 0.3 else \"\"\n",
    "\n",
    "    def add_hashtags(self, text: str, category: str) -> str:\n",
    "        \"\"\"Add relevant hashtags based on content and character limit, with limited frequency.\"\"\"\n",
    "        hashtags = {\n",
    "            \"market_analysis\": [\n",
    "                \"#CryptoTrading\", \"#TechnicalAnalysis\", \"#CryptoMarkets\",\n",
    "                \"#Trading\", \"#Charts\", \"#PriceAction\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"#Blockchain\", \"#CryptoTech\", \"#Web3Dev\", \"#DLT\",\n",
    "                \"#SmartContracts\", \"#BuilderSpace\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"#DeFi\", \"#YieldFarming\", \"#Staking\", \"#DeFiSeason\",\n",
    "                \"#PassiveIncome\", \"#DeFiYield\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"#NFTs\", \"#NFTCommunity\", \"#NFTCollector\", \"#NFTArt\",\n",
    "                \"#NFTProject\", \"#TokenizedArt\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"#CryptoCulture\", \"#DAOs\", \"#Web3\", \"#CryptoTwitter\",\n",
    "                \"#CryptoLife\", \"#BuildingWeb3\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"#Crypto\", \"#Web3\", \"#Bitcoin\", \"#Ethereum\",\n",
    "                \"#CryptoTwitter\", \"#BuildingTheFuture\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "        # Add hashtags with 40% probability\n",
    "        if random.random() > 0.2:\n",
    "            return text\n",
    "    \n",
    "        remaining_chars = 280 - len(text)\n",
    "        if remaining_chars < 15:  # Not enough space for hashtags\n",
    "            return text\n",
    "    \n",
    "        category_hashtags = hashtags.get(category, hashtags[\"general\"])\n",
    "        selected_hashtags = []\n",
    "        \n",
    "        # Add 1-2 hashtags while respecting character limit\n",
    "        for _ in range(random.randint(1, 2)):\n",
    "            if not category_hashtags or remaining_chars < 15:\n",
    "                break\n",
    "            hashtag = random.choice(category_hashtags)\n",
    "            if len(hashtag) + 1 <= remaining_chars:\n",
    "                selected_hashtags.append(hashtag)\n",
    "                category_hashtags.remove(hashtag)\n",
    "                remaining_chars -= len(hashtag) + 1\n",
    "    \n",
    "        return f\"{text} {' '.join(selected_hashtags)}\"\n",
    "    \n",
    "    def clean_response(self, text: str, category: str) -> str:\n",
    "        \"\"\"Clean and format the response for Twitter.\"\"\"\n",
    "        # Remove URLs and excessive whitespace\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "        # Remove leading and trailing quotation marks\n",
    "        text = text.strip('\"\\'‚Äú‚Äù')\n",
    "    \n",
    "        # Replace multiple internal quotes with single quotes\n",
    "        text = re.sub(r'\"+', '\"', text)\n",
    "        text = re.sub(r\"'+\", \"'\", text)\n",
    "    \n",
    "        # Correct unbalanced quotation marks\n",
    "        def balance_quotes(s):\n",
    "            quote_chars = ['\"', \"'\"]\n",
    "            for quote in quote_chars:\n",
    "                if s.count(quote) % 2 != 0:\n",
    "                    s = s.replace(quote, '')  # Remove unmatched quotes\n",
    "            return s\n",
    "    \n",
    "        text = balance_quotes(text)\n",
    "    \n",
    "        # Ensure the text ends with proper punctuation\n",
    "        if text and text[-1] not in '.!?':\n",
    "            text += '.'\n",
    "    \n",
    "        return text\n",
    "\n",
    "\n",
    "\n",
    "    def get_fallback(self, category: str) -> str:\n",
    "        \"\"\"Generate category-specific fallback responses.\"\"\"\n",
    "        fallbacks = {\n",
    "            \"market_analysis\": [\n",
    "                \"Charts looking juicy today! Anyone else seeing this setup? üìà\",\n",
    "                \"Market's giving mixed signals but the volume tells a different story üëÄ\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Sometimes the best protocols are the ones no one's talking about yet üõ†Ô∏è\",\n",
    "                \"Imagine still building without considering Layer 2 scaling üíª\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"Your yields are only as good as your risk management üè¶\",\n",
    "                \"DeFi summer never ended, we just got better at farming üåæ\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"Art is subjective, but floor prices aren't üé®\",\n",
    "                \"Your NFT portfolio tells a story. Make it a good one üñºÔ∏è\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Web3 culture is what we make it. Build accordingly üåê\",\n",
    "                \"Sometimes the real alpha is the friends we made along the way ü§ù\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Just caught myself thinking about the future of crypto while making coffee ‚òïÔ∏è\",\n",
    "                \"Your portfolio is only as strong as your conviction üíé\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_fallbacks = fallbacks.get(category, fallbacks[\"general\"])\n",
    "        return random.choice(category_fallbacks)\n",
    "\n",
    "    def filter_tone(self, response: str) -> str:\n",
    "        \"\"\"Filter response tone and adjust if needed.\"\"\"\n",
    "        sentiment = TextBlob(response).sentiment\n",
    "        \n",
    "        if sentiment.polarity < -0.3:\n",
    "            return self.get_fallback(\"general\")\n",
    "        \n",
    "        if sentiment.subjectivity > 0.8:\n",
    "            # Too subjective, add a disclaimer\n",
    "            return f\"Not financial advice but... {response}\"\n",
    "                \n",
    "        return response\n",
    "\n",
    "    def generate_response(self, prompt: str) -> str:\n",
    "        \"\"\"Generate a complete Twitter-ready response.\"\"\"\n",
    "        category = self.categorize_prompt(prompt)\n",
    "    \n",
    "        instruction = (\n",
    "            \"You are a crypto and finance expert with a sharp sense of humor, blending the witty sarcasm of George Hotz with the storytelling flair of Theo Von. \"\n",
    "            \"Your goal is to craft engaging, funny, and insightful tweets that educate your audience using appropriate slang and jargon. \"\n",
    "            \"Each tweet should be coherent, make logical sense, and provide a clear takeaway or punchline. \"\n",
    "            \"Avoid overusing slang‚Äîuse it where it feels natural. \"\n",
    "            \"Respond to the following prompt:\\n\\n\"\n",
    "        )\n",
    "    \n",
    "        examples = (\n",
    "            \"Prompt: What's your take on Bitcoin as digital gold?\\n\"\n",
    "            \"Tweet: Bitcoin as digital gold? Nah, it's more like digital real estate in the metaverse‚Äîexcept everyone's still arguing over the property lines. Who's still buying up the neighborhood? üöÄ #Bitcoin #Crypto\\n\\n\"\n",
    "            \"Prompt: Explain staking in the context of DeFi but make it funny.\\n\"\n",
    "            \"Tweet: Staking in DeFi is like putting your money on a treadmill‚Äîyou lock it up, it works out, and somehow you end up with more than just sweaty tokens. Gains on gains! üèãÔ∏è‚Äç‚ôÇÔ∏è #DeFi #Staking\\n\\n\"\n",
    "        )\n",
    "    \n",
    "        context = f\"{instruction}{examples}Prompt: {prompt}\\nTweet:\"\n",
    "    \n",
    "        inputs = self.tokenizer(\n",
    "            context,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=1024  # Increased to accommodate longer context\n",
    "        ).to(device)\n",
    "    \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=80,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.7,\n",
    "                    top_k=50,\n",
    "                    top_p=0.9,\n",
    "                    repetition_penalty=1.5,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    eos_token_id=self.tokenizer.eos_token_id,\n",
    "                )\n",
    "    \n",
    "            generated_text = self.tokenizer.decode(\n",
    "                outputs[0],\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "    \n",
    "            # Extract the tweet from the generated text\n",
    "            response = generated_text.split(\"Tweet:\")[-1].strip().split(\"\\n\")[0]\n",
    "    \n",
    "            if not response or len(response) < 20:\n",
    "                return self.get_fallback(category)\n",
    "    \n",
    "            # Apply enhancements\n",
    "            response = self.clean_response(response, category)\n",
    "            response = self.filter_tone(response)\n",
    "            response = self.add_emojis(response, category)\n",
    "            response = self.add_hashtags(response, category)\n",
    "    \n",
    "            logger.info(f\"Generated response: {response}\")\n",
    "    \n",
    "            return response[:280]  # Ensure the response fits within Twitter's character limit\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating response: {str(e)}\")\n",
    "            return self.get_fallback(category)\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        bot = PersonalityBot()\n",
    "        logger.info(\"Bot initialized successfully\")\n",
    "        \n",
    "        # # Test prompts\n",
    "        # test_prompts = [\n",
    "        #     \"How do gas fees compare between Ethereum and Solana?\",\n",
    "        #     \"Tell me why NFTs are either a scam or the future.\",\n",
    "        #     \"What's your take on Bitcoin as digital gold?\",\n",
    "        #     \"Explain staking in the context of DeFi but make it funny.\",\n",
    "        #     \"Give me a wild prediction for crypto in 2030.\",\n",
    "        #     \"What's a DAO, and should I care?\",\n",
    "        #     \"Can you explain why everyone's obsessed with Layer 2 solutions?\",\n",
    "        #     \"What's the wildest crypto meme you've seen this week?\",\n",
    "        #     \"How do I avoid FOMO during bull runs?\",\n",
    "        #     \"Is it too late to get into crypto? Be honest!\",\n",
    "        #     \"How would you describe Web3 to someone who barely uses the internet?\",\n",
    "        #     \"What's your hottest take on decentralized finance?\"\n",
    "        # ]\n",
    "        \n",
    "        # # Test run with basic prompts\n",
    "        # logger.info(\"Starting test run with sample prompts...\")\n",
    "        # print(\"\\n=== Test Run with Sample Prompts ===\")\n",
    "        # for i, prompt in enumerate(test_prompts, 1):\n",
    "        #     print(f\"\\nPrompt {i}: {prompt}\")\n",
    "        #     start_time = time.time()\n",
    "        #     response = bot.generate_response(prompt)\n",
    "        #     elapsed_time = time.time() - start_time\n",
    "        #     print(\"\")\n",
    "        #     print(f\"Response: {response}\")\n",
    "        #     print(f\"Runtime: {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # Interactive mode\n",
    "        logger.info(\"Entering interactive mode...\")\n",
    "        print(\"\\n=== Interactive Mode ===\")\n",
    "        print(\"Enter your prompts (type 'quit' to exit):\")\n",
    "        \n",
    "        while True:\n",
    "            user_prompt = input(\"\\nYour prompt: \").strip()\n",
    "            if user_prompt.lower() == 'quit':\n",
    "                print(\"Exiting... Thanks for using tbot!\")\n",
    "                break\n",
    "            if not user_prompt:\n",
    "                print(\"Please enter a valid prompt!\")\n",
    "                continue\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                response = bot.generate_response(user_prompt)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"Response: {response}\")\n",
    "                print(f\"Runtime: {elapsed_time:.2f} seconds\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing prompt: {str(e)}\")\n",
    "                print(\"Oops! Something went wrong. Please try again.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Application error: {str(e)}\")\n",
    "        print(\"Critical error occurred. Please check the logs for details.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1b51c-3aa0-4462-bc1b-b62591877b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c282f8-bd8b-419f-a632-e5bb1f75d447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690f0d1-1764-4d95-b503-6628527c57fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b960d-1803-458f-9385-3f3dfebceeba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tbot)",
   "language": "python",
   "name": "tbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
