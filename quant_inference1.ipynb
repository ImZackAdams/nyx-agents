{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca7d66-07e0-4e74-8c6c-2c0fa5fa4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 09:08:36,895 - INFO - Setting up model from ./fine_tuned_personality_bot/\n",
      "2024-11-19 09:08:38,132 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df6dbde929e420cb0eb8d1f7de7f9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 09:08:59,109 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "2024-11-19 09:08:59,111 - INFO - Model setup completed successfully\n",
      "2024-11-19 09:08:59,111 - INFO - Bot initialized successfully\n",
      "2024-11-19 09:08:59,112 - INFO - Starting test run with sample prompts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt 1: How do gas fees compare between Ethereum and Solana?\n",
      "Response: Y'all want to know about gas fees? It's like asking which pizza topping is better â€“ ETH or SOL! ðŸ’»ðŸ”¨ #CryptoTech\n",
      "\n",
      "Runtime: 30.20 seconds\n",
      "\n",
      "Prompt 2: Tell me why NFTs are either a scam or the future.\n",
      "Response: Like, they're already changing game, making old art & collectibles hot again. But let's be real â€“ most ppl minting 'em don't even understand what they're doing. ðŸŽ¨ #NFTArt #NFTProject\n",
      "\n",
      "Runtime: 26.15 seconds\n",
      "\n",
      "Prompt 3: What's your take on Bitcoin as digital gold?\n",
      "Response: Not financial advice but... Your portfolio is only as strong as your conviction ðŸ’Ž ðŸŒ™ #Web3 #Ethereum\n",
      "\n",
      "Runtime: 28.17 seconds\n",
      "\n",
      "Prompt 4: Explain staking in the context of DeFi but make it funny.\n",
      "Response: Your yields are only as good as your risk management ðŸ¦ ðŸŽ° #YieldFarming #DeFiYield\n",
      "\n",
      "Runtime: 28.84 seconds\n",
      "\n",
      "Prompt 5: Give me a wild prediction for crypto in 2030.\n",
      "Response: Lowkey thinking we'll see MFTs replace ETH as devs' go-to choice by '30. The nostalgia is real, fam! ðŸ’¸ðŸ“± #CryptoMarkets #Trading\n",
      "\n",
      "Runtime: 28.57 seconds\n",
      "\n",
      "Prompt 6: What's a DAO, and should I care?\n",
      "Response: Sometimes the real alpha is the friends we made along the way ðŸ¤ ðŸŽ¯ðŸŽ² #CryptoTwitter\n",
      "\n",
      "Runtime: 29.26 seconds\n",
      "\n",
      "Prompt 7: Can you explain why everyone's obsessed with Layer 2 solutions?\n",
      "Response: Low-horizon vibes only! L2s are the OG HODLers of scalability â€“ they keep it real by giving DeFi apps some serious breathing room without burning ETH or gas like mad. ðŸ’»ðŸ”‹ #Blockchain\n",
      "\n",
      "Runtime: 28.64 seconds\n",
      "\n",
      "Prompt 8: What's the wildest crypto meme you've seen this week?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import Tuple, List, Dict\n",
    "import random\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from torch.quantization import quantize_dynamic\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Device and model configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"./fine_tuned_personality_bot/\"  # Update with your model path\n",
    "\n",
    "class PersonalityBot:\n",
    "    def __init__(self, model_path: str = MODEL_PATH):\n",
    "        self.model_path = model_path\n",
    "        self.model, self.tokenizer = self.setup_model()\n",
    "        \n",
    "    def setup_model(self) -> Tuple[AutoModelForCausalLM, AutoTokenizer]:\n",
    "        \"\"\"Initialize and configure the model and tokenizer.\"\"\"\n",
    "        logger.info(f\"Setting up model from {self.model_path}\")\n",
    "        \n",
    "        if not os.path.exists(self.model_path):\n",
    "            raise FileNotFoundError(f\"Model not found at {self.model_path}\")\n",
    "        \n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                self.model_path,\n",
    "                use_fast=True\n",
    "            )\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            \n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_path,\n",
    "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "                low_cpu_mem_usage=True,\n",
    "                use_safetensors=True,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "            \n",
    "            if device.type == \"cpu\":\n",
    "                model = quantize_dynamic(\n",
    "                    model,\n",
    "                    {torch.nn.Linear},\n",
    "                    dtype=torch.qint8\n",
    "                ).to(device)\n",
    "            \n",
    "            model.eval()\n",
    "            logger.info(\"Model setup completed successfully\")\n",
    "            return model, tokenizer\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Model setup failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def categorize_prompt(self, prompt: str) -> str:\n",
    "        \"\"\"Categorize input prompt for contextual response generation.\"\"\"\n",
    "        categories: Dict[str, List[str]] = {\n",
    "            \"market_analysis\": [\n",
    "                \"price\", \"market\", \"chart\", \"analysis\", \"trend\", \"prediction\",\n",
    "                \"bull\", \"bear\", \"trading\", \"volume\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"blockchain\", \"protocol\", \"layer\", \"scaling\", \"code\", \"development\",\n",
    "                \"smart contract\", \"gas\", \"network\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"defi\", \"yield\", \"farming\", \"liquidity\", \"stake\", \"lending\",\n",
    "                \"borrow\", \"apy\", \"tvl\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"nft\", \"art\", \"collectible\", \"mint\", \"opensea\", \"rarity\",\n",
    "                \"floor price\", \"pfp\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"community\", \"dao\", \"governance\", \"vote\", \"proposal\",\n",
    "                \"alpha\", \"degen\", \"fud\", \"fomo\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        prompt_lower = prompt.lower()\n",
    "        for category, keywords in categories.items():\n",
    "            if any(keyword in prompt_lower for keyword in keywords):\n",
    "                return category\n",
    "        return \"general\"\n",
    "\n",
    "    def generate_hook(self, category: str) -> str:\n",
    "        \"\"\"Generate category-specific attention hooks.\"\"\"\n",
    "        hooks = {\n",
    "            \"market_analysis\": [\n",
    "                \"Market alert:\", \"Chart check:\", \"Price watch:\",\n",
    "                \"Trading insight:\", \"Market alpha:\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Tech deep dive:\", \"Builder's corner:\", \"Protocol watch:\",\n",
    "                \"Dev update:\", \"Architecture take:\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"DeFi alpha:\", \"Yield watch:\", \"Smart money move:\",\n",
    "                \"Protocol alert:\", \"TVL update:\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"NFT alpha:\", \"Collection watch:\", \"Mint alert:\",\n",
    "                \"Floor check:\", \"Digital art take:\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Culture take:\", \"DAO watch:\", \"Governance alert:\",\n",
    "                \"Community vibe:\", \"Alpha leak:\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Hot take:\", \"Unpopular opinion:\", \"Plot twist:\",\n",
    "                \"Real talk:\", \"Quick thought:\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_hooks = hooks.get(category, hooks[\"general\"])\n",
    "        return random.choice(category_hooks) if random.random() < 0.4 else \"\"\n",
    "\n",
    "    def add_emojis(self, text: str, category: str) -> str:\n",
    "        \"\"\"Add contextual emojis based on content category.\"\"\"\n",
    "        emoji_sets = {\n",
    "            \"market_analysis\": [\"ðŸ“ˆ\", \"ðŸ“Š\", \"ðŸ’¹\", \"ðŸ“‰\", \"ðŸ’¸\", \"ðŸŽ¯\", \"ðŸ“±\"],\n",
    "            \"tech_discussion\": [\"âš¡ï¸\", \"ðŸ”§\", \"ðŸ’»\", \"ðŸ› ï¸\", \"ðŸ”¨\", \"ðŸ§®\", \"ðŸ”‹\"],\n",
    "            \"defi\": [\"ðŸ¦\", \"ðŸ’°\", \"ðŸ§\", \"ðŸ’³\", \"ðŸ”„\", \"âš–ï¸\", \"ðŸŽ°\"],\n",
    "            \"nft\": [\"ðŸŽ¨\", \"ðŸ–¼ï¸\", \"ðŸŽ­\", \"ðŸŽª\", \"ðŸŽŸï¸\", \"ðŸŽ®\", \"ðŸƒ\"],\n",
    "            \"culture\": [\"ðŸŒ\", \"ðŸ¤\", \"ðŸ—£ï¸\", \"ðŸŽ­\", \"ðŸŽª\", \"ðŸŽ¯\", \"ðŸŽ²\"],\n",
    "            \"general\": [\"ðŸš€\", \"ðŸ’Ž\", \"ðŸŒ™\", \"ðŸ”¥\", \"ðŸ’¡\", \"ðŸŽ¯\", \"â­ï¸\"]\n",
    "        }\n",
    "        \n",
    "        category_emojis = emoji_sets.get(category, emoji_sets[\"general\"])\n",
    "        emoji_count = random.randint(1, 2)\n",
    "        chosen_emojis = random.sample(category_emojis, emoji_count)\n",
    "        \n",
    "        return f\"{text} {''.join(chosen_emojis)}\"\n",
    "\n",
    "    def generate_engagement_phrase(self, category: str) -> str:\n",
    "        \"\"\"Generate contextual engagement prompts.\"\"\"\n",
    "        phrases = {\n",
    "            \"market_analysis\": [\n",
    "                \"What's your price target?\",\n",
    "                \"Bulls or bears?\",\n",
    "                \"Who's buying this dip?\",\n",
    "                \"Thoughts on this setup?\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Devs, thoughts?\",\n",
    "                \"Valid architecture?\",\n",
    "                \"Spotted any issues?\",\n",
    "                \"Who's building similar?\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"What's your yield strategy?\",\n",
    "                \"Aping in?\",\n",
    "                \"Found better rates?\",\n",
    "                \"Risk level?\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"Cope or hope?\",\n",
    "                \"Floor predictions?\",\n",
    "                \"Mining this?\",\n",
    "                \"Art or utility?\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Based or nah?\",\n",
    "                \"Who else sees this?\",\n",
    "                \"Your governance take?\",\n",
    "                \"DAO voters wya?\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Thoughts?\",\n",
    "                \"Based?\",\n",
    "                \"Who's with me?\",\n",
    "                \"Change my mind.\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_phrases = phrases.get(category, phrases[\"general\"])\n",
    "        return random.choice(category_phrases) if random.random() < 0.3 else \"\"\n",
    "\n",
    "    def add_hashtags(self, text: str, category: str) -> str:\n",
    "        \"\"\"Add relevant hashtags based on content and character limit.\"\"\"\n",
    "        hashtags = {\n",
    "            \"market_analysis\": [\n",
    "                \"#CryptoTrading\", \"#TechnicalAnalysis\", \"#CryptoMarkets\",\n",
    "                \"#Trading\", \"#Charts\", \"#PriceAction\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"#Blockchain\", \"#CryptoTech\", \"#Web3Dev\", \"#DLT\",\n",
    "                \"#SmartContracts\", \"#BuilderSpace\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"#DeFi\", \"#YieldFarming\", \"#Staking\", \"#DeFiSeason\",\n",
    "                \"#PassiveIncome\", \"#DeFiYield\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"#NFTs\", \"#NFTCommunity\", \"#NFTCollector\", \"#NFTArt\",\n",
    "                \"#NFTProject\", \"#TokenizedArt\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"#CryptoCulture\", \"#DAOs\", \"#Web3\", \"#CryptoTwitter\",\n",
    "                \"#CryptoLife\", \"#BuildingWeb3\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"#Crypto\", \"#Web3\", \"#Bitcoin\", \"#Ethereum\",\n",
    "                \"#CryptoTwitter\", \"#BuildingTheFuture\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        remaining_chars = 280 - len(text)\n",
    "        if remaining_chars < 15:  # Not enough space for hashtags\n",
    "            return text\n",
    "            \n",
    "        category_hashtags = hashtags.get(category, hashtags[\"general\"])\n",
    "        selected_hashtags = []\n",
    "        \n",
    "        # Add 1-2 hashtags while respecting character limit\n",
    "        for _ in range(random.randint(1, 2)):\n",
    "            if not category_hashtags or remaining_chars < 15:\n",
    "                break\n",
    "            hashtag = random.choice(category_hashtags)\n",
    "            if len(hashtag) + 1 <= remaining_chars:\n",
    "                selected_hashtags.append(hashtag)\n",
    "                category_hashtags.remove(hashtag)\n",
    "                remaining_chars -= len(hashtag) + 1\n",
    "        \n",
    "        return f\"{text} {' '.join(selected_hashtags)}\"\n",
    "\n",
    "    def clean_response(self, text: str, category: str) -> str:\n",
    "        \"\"\"Clean and format the response for Twitter.\"\"\"\n",
    "        # Remove unwanted patterns\n",
    "        text = re.sub(r'@\\w+|http\\S+|\\[.*?\\]|\\(.*?\\)|\"|Q:|A:', '', text)\n",
    "        text = re.sub(r'\\b(Note|Example|Rules).*?(?=[.!?]|$)', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Split into sentences and filter\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        sentences = [s for s in sentences if len(s) > 20 and re.search(r'[.!?]$', s)]\n",
    "        \n",
    "        if not sentences:\n",
    "            return self.get_fallback(category)\n",
    "        \n",
    "        # Combine sentences with proper spacing\n",
    "        response = ' '.join(sentences[:2])\n",
    "        \n",
    "        # Add engaging elements\n",
    "        hook = self.generate_hook(category)\n",
    "        if hook:\n",
    "            response = f\"{hook} {response}\"\n",
    "        \n",
    "        engagement = self.generate_engagement_phrase(category)\n",
    "        if engagement:\n",
    "            response = f\"{response} {engagement}\"\n",
    "        \n",
    "        return response[:240]  # Leave room for hashtags/emojis\n",
    "\n",
    "    def get_fallback(self, category: str) -> str:\n",
    "        \"\"\"Generate category-specific fallback responses.\"\"\"\n",
    "        fallbacks = {\n",
    "            \"market_analysis\": [\n",
    "                \"Charts looking juicy today! Anyone else seeing this setup? ðŸ“ˆ\",\n",
    "                \"Market's giving mixed signals but the volume tells a different story ðŸ‘€\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Sometimes the best protocols are the ones no one's talking about yet ðŸ› ï¸\",\n",
    "                \"Imagine still building without considering Layer 2 scaling ðŸ’»\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"Your yields are only as good as your risk management ðŸ¦\",\n",
    "                \"DeFi summer never ended, we just got better at farming ðŸŒ¾\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"Art is subjective, but floor prices aren't ðŸŽ¨\",\n",
    "                \"Your NFT portfolio tells a story. Make it a good one ðŸ–¼ï¸\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Web3 culture is what we make it. Build accordingly ðŸŒ\",\n",
    "                \"Sometimes the real alpha is the friends we made along the way ðŸ¤\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Just caught myself thinking about the future of crypto while making coffee â˜•ï¸\",\n",
    "                \"Your portfolio is only as strong as your conviction ðŸ’Ž\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_fallbacks = fallbacks.get(category, fallbacks[\"general\"])\n",
    "        return random.choice(category_fallbacks)\n",
    "\n",
    "    def filter_tone(self, response: str) -> str:\n",
    "        \"\"\"Filter response tone and adjust if needed.\"\"\"\n",
    "        sentiment = TextBlob(response).sentiment\n",
    "        \n",
    "        if sentiment.polarity < -0.3:\n",
    "            return self.get_fallback(\"general\")\n",
    "        \n",
    "        if sentiment.subjectivity > 0.8:\n",
    "            # Too subjective, add a disclaimer\n",
    "            return f\"Not financial advice but... {response}\"\n",
    "            \n",
    "        return response\n",
    "\n",
    "    def generate_response(self, prompt: str) -> str:\n",
    "        \"\"\"Generate a complete Twitter-ready response.\"\"\"\n",
    "        try:\n",
    "            category = self.categorize_prompt(prompt)\n",
    "            \n",
    "            instruction = (\n",
    "                \n",
    "            \n",
    "                \"You are a witty crypto influencer known for sharp insights and engaging tweets. \"\n",
    "                \"Your style combines tech expertise with modern internet culture. \"\n",
    "                f\"You're currently discussing {category}-related topics. \"\n",
    "                \"Write in a confident, casual voice using current crypto/tech slang. \"\n",
    "                \"Keep responses punchy and memorable - perfect for viral tweets. \"\n",
    "                \"Focus on providing unique perspectives that spark discussion. \"\n",
    "                \"Mix humor with genuine insight, avoiding generic takes. \"\n",
    "                \"Use conversational tone but maintain authority on the subject.\"\n",
    "            )\n",
    "            \n",
    "            context = f\"{instruction}\\n\\nQ: {prompt}\\nA:\"\n",
    "            \n",
    "            inputs = self.tokenizer(\n",
    "                context,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=256\n",
    "            ).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=100,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.92,\n",
    "                    top_k=50,\n",
    "                    top_p=0.95,\n",
    "                    repetition_penalty=1.2,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    eos_token_id=self.tokenizer.eos_token_id\n",
    "                )\n",
    "            \n",
    "            response = self.tokenizer.decode(\n",
    "                outputs[0],\n",
    "                skip_special_tokens=True\n",
    "            ).split(\"A:\")[-1].strip()\n",
    "            \n",
    "            if not response or len(response) < 20:\n",
    "                return self.get_fallback(category)\n",
    "            \n",
    "            # Apply enhancements\n",
    "            response = self.clean_response(response, category)\n",
    "            response = self.filter_tone(response)\n",
    "            response = self.add_emojis(response, category)\n",
    "            response = self.add_hashtags(response, category)\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating response: {str(e)}\")\n",
    "            return self.get_fallback(\"general\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        bot = PersonalityBot()\n",
    "        logger.info(\"Bot initialized successfully\")\n",
    "        \n",
    "        #Test prompts\n",
    "        \n",
    "        test_prompts = [\n",
    "            \"How do gas fees compare between Ethereum and Solana?\",\n",
    "            \"Tell me why NFTs are either a scam or the future.\",\n",
    "            \"What's your take on Bitcoin as digital gold?\",\n",
    "            \"Explain staking in the context of DeFi but make it funny.\",\n",
    "            \"Give me a wild prediction for crypto in 2030.\",\n",
    "            \"What's a DAO, and should I care?\",\n",
    "            \"Can you explain why everyone's obsessed with Layer 2 solutions?\",\n",
    "            \"What's the wildest crypto meme you've seen this week?\",\n",
    "            \"How do I avoid FOMO during bull runs?\",\n",
    "            \"Is it too late to get into crypto? Be honest!\",\n",
    "            \"How would you describe Web3 to someone who barely uses the internet?\",\n",
    "            \"What's your hottest take on decentralized finance?\"\n",
    "        ]\n",
    "        \n",
    "        # Test run with basic prompts\n",
    "        logger.info(\"Starting test run with sample prompts...\")\n",
    "        for i, prompt in enumerate(test_prompts, 1):\n",
    "            # logger.info(f\"\\nProcessing test prompt {i}/{len(test_prompts)}\")\n",
    "            print(f\"\\nPrompt {i}: {prompt}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            response = bot.generate_response(prompt)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"Response: {response}\")\n",
    "            print(\"\")\n",
    "            print(f\"Runtime: {elapsed_time:.2f} seconds\")\n",
    "            \n",
    "       \n",
    "        \n",
    "        # Interactive mode/twitter integrate\n",
    "        logger.info(\"Entering interactive mode...\")\n",
    "        print(\"\\nEnter your prompts (type 'quit' to exit):\")\n",
    "        \n",
    "        while True:\n",
    "            user_prompt = input(\"\\nYour prompt: \").strip()\n",
    "            \n",
    "            if user_prompt.lower() == 'quit':\n",
    "                print(\"Exiting... Thanks for using CryptoPersonalityBot!\")\n",
    "                break\n",
    "                \n",
    "            if not user_prompt:\n",
    "                print(\"Please enter a valid prompt!\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                response = bot.generate_response(user_prompt)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                \n",
    "                print(f\"Response: {response}\")\n",
    "                print(f\"Runtime: {elapsed_time:.2f} seconds\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing prompt: {str(e)}\")\n",
    "                print(\"Oops! Something went wrong. Please try again.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Application error: {str(e)}\")\n",
    "        print(\"Critical error occurred. Please check the logs for details.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1b51c-3aa0-4462-bc1b-b62591877b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tbot)",
   "language": "python",
   "name": "tbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
