{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ca7d66-07e0-4e74-8c6c-2c0fa5fa4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:46:21,810 - INFO - Setting up model from ./fine_tuned_personality_bot/\n",
      "2024-11-19 12:46:23,020 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050b9481965542089d1154b380d11304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:46:31,499 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "2024-11-19 12:46:31,501 - INFO - Model setup completed successfully\n",
      "2024-11-19 12:46:31,501 - INFO - Bot initialized successfully\n",
      "2024-11-19 12:46:31,501 - INFO - Starting test run with sample prompts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Run with Sample Prompts ===\n",
      "\n",
      "Prompt 1: How do gas fees compare between Ethereum and Solana?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:46:57,107 - INFO - Generated response: Gas fee game strong üëä Between @Ethereum &amp;@Solana - Eth's got $0-$50 for simple transacts (ouch!), while Sola costs ~$1-10 per tx (~100x less). Think of it this way, though... when life gives u lemons ($), grab some lemonade üí¶üëçüí∏ ‚Äì now pay 99. üõ†Ô∏è\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Gas fee game strong üëä Between @Ethereum &amp;@Solana - Eth's got $0-$50 for simple transacts (ouch!), while Sola costs ~$1-10 per tx (~100x less). Think of it this way, though... when life gives u lemons ($), grab some lemonade üí¶üëçüí∏ ‚Äì now pay 99. üõ†Ô∏è\n",
      "Runtime: 25.61 seconds\n",
      "\n",
      "Prompt 2: Tell me why NFTs are either a scam or the future.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:47:19,699 - INFO - Generated response: NFTs are art\" vs \"I can buy this pixelated cat for $100k\"... sounds about right when discussing modern society üòíüêà The truth lies somewhere between 'art' & market manipulation... let‚Äôs call it creative accounting üí∏#ArtificialIntelligenceForAll (just kidding) ArtMarketV2 üëëüí∞.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: NFTs are art\" vs \"I can buy this pixelated cat for $100k\"... sounds about right when discussing modern society üòíüêà The truth lies somewhere between 'art' & market manipulation... let‚Äôs call it creative accounting üí∏#ArtificialIntelligenceForAll (just kidding) ArtMarketV2 üëëüí∞.\n",
      "Runtime: 22.59 seconds\n",
      "\n",
      "Prompt 3: What's your take on Bitcoin as digital gold?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:47:39,989 - INFO - Generated response: The \"digital gold\" hype around BTC has me thinking... what if we traded bitcoin for pizzas instead? That'd actually increase its value by 1000% (just imagine having all those anchovies). Would pizza-lovers become wealthy investors overnight? Asking for a friend who loves deep dish üî•üçï $BTC. üî•\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: The \"digital gold\" hype around BTC has me thinking... what if we traded bitcoin for pizzas instead? That'd actually increase its value by 1000% (just imagine having all those anchovies). Would pizza-lovers become wealthy investors overnight? Asking for a friend who loves deep dis\n",
      "Runtime: 20.29 seconds\n",
      "\n",
      "Prompt 4: Explain staking in the context of DeFi but make it funny.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:48:04,446 - INFO - Generated response: So u wanna stake ur coins 4 some juicy returns... think again pal üòí U gotta put 'em down & hold for ages (think months) while they work their magic üíª This ain't no get-rich-quick scheme; this one requires patience + math skills üëìüí∏üî¢#stakeytime.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: So u wanna stake ur coins 4 some juicy returns... think again pal üòí U gotta put 'em down & hold for ages (think months) while they work their magic üíª This ain't no get-rich-quick scheme; this one requires patience + math skills üëìüí∏üî¢#stakeytime.\n",
      "Runtime: 24.46 seconds\n",
      "\n",
      "Prompt 5: Give me a wild prediction for crypto in 2030.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:48:28,715 - INFO - Generated response: By 2030 I predict we'll have decentralized social media platforms run entirely by AI-generated content creators who've stolen our memes...and also made us all wear VR headsets because 'authenticity' means something now üò±ü§ñ#FutureOfCrypto. üí∏ #PriceAction #TechnicalAnalysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: By 2030 I predict we'll have decentralized social media platforms run entirely by AI-generated content creators who've stolen our memes...and also made us all wear VR headsets because 'authenticity' means something now üò±ü§ñ#FutureOfCrypto. üí∏ #PriceAction #TechnicalAnalysis\n",
      "Runtime: 24.27 seconds\n",
      "\n",
      "Prompt 6: What's a DAO, and should I care?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:48:52,904 - INFO - Generated response: ADAO (Decentralized Autonomous Organization) - basically an AI-powered party planner for blockchain projects. Except instead of games & drinks, they're planning token distributions...or maybe not-so- autonomous decisions üòúüéâ Can someone explain why this sounds so cool until 3 AM when reality hits?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: ADAO (Decentralized Autonomous Organization) - basically an AI-powered party planner for blockchain projects. Except instead of games & drinks, they're planning token distributions...or maybe not-so- autonomous decisions üòúüéâ Can someone explain why this sounds so cool until 3 AM w\n",
      "Runtime: 24.19 seconds\n",
      "\n",
      "Prompt 7: Can you explain why everyone's obsessed with Layer 2 solutions?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:49:17,512 - INFO - Generated response: Everyone loves L2s 'cause they're all about speed & scalability... aka \"I wanna get my cake before someone else does\". It‚Äôs not greed; we‚Äôre talkin' throughput anxiety üò¨üí®üéâ#LayerTwoSolutions #ScalingUpwards. #SmartContracts #DLT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Everyone loves L2s 'cause they're all about speed & scalability... aka \"I wanna get my cake before someone else does\". It‚Äôs not greed; we‚Äôre talkin' throughput anxiety üò¨üí®üéâ#LayerTwoSolutions #ScalingUpwards. #SmartContracts #DLT\n",
      "Runtime: 24.61 seconds\n",
      "\n",
      "Prompt 8: What's the wildest crypto meme you've seen this week?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:49:41,932 - INFO - Generated response: Not financial advice but... I saw someone claim Satoshi Nakamoto was actually an alien from Zorgon trying to save humanity through cryptocurrency...and honestly, now my mind wanders every time we talk about FOMO üí´üëΩ Can't say if true (or ridiculous), only know 420% ROI wasn‚Äôt sustainable üòú. ‚≠êÔ∏è\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Not financial advice but... I saw someone claim Satoshi Nakamoto was actually an alien from Zorgon trying to save humanity through cryptocurrency...and honestly, now my mind wanders every time we talk about FOMO üí´üëΩ Can't say if true (or ridiculous), only know 420% ROI wasn‚Äôt sust\n",
      "Runtime: 24.42 seconds\n",
      "\n",
      "Prompt 9: How do I avoid FOMO during bull runs?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:50:01,502 - INFO - Generated response: Don't let fear turn into fuel... for 3 AM Twitter tantrums üò¥üí∏ When bulls run amok (pun intended), remember why you got involved & remind yourself 'I'm not gonna die from one bad market'. You're an adult now; time management = financial freedom üí™üëä. #PriceAction #CryptoTrading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Don't let fear turn into fuel... for 3 AM Twitter tantrums üò¥üí∏ When bulls run amok (pun intended), remember why you got involved & remind yourself 'I'm not gonna die from one bad market'. You're an adult now; time management = financial freedom üí™üëä. #PriceAction #CryptoTrading\n",
      "Runtime: 19.57 seconds\n",
      "\n",
      "Prompt 10: Is it too late to get into crypto? Be honest!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:50:26,214 - INFO - Generated response: Listen, if I'm being 100% transparent...it might already BE TOO LATE for most people getting rich quick (RIP FUD). But hey, at least there'll always be newbies willing to ride shotgun while we all play \"crypto roulette\" together üòÖüé≤ #GetInNowOrNever?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Listen, if I'm being 100% transparent...it might already BE TOO LATE for most people getting rich quick (RIP FUD). But hey, at least there'll always be newbies willing to ride shotgun while we all play \"crypto roulette\" together üòÖüé≤ #GetInNowOrNever?\n",
      "Runtime: 24.71 seconds\n",
      "\n",
      "Prompt 11: How would you describe Web3 to someone who barely uses the internet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:50:51,145 - INFO - Generated response: Not financial advice but... Imagine we're at an old-school arcade (think Pac-Man & Donkey Kong). You insert quarters, play games, collect tickets... now imagine those ticket-redemption systems became self-sustaining communities run by YOU ‚Äì welcome to web 2.x üòé That said, if they made 'em all blockchain-based instead...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Not financial advice but... Imagine we're at an old-school arcade (think Pac-Man & Donkey Kong). You insert quarters, play games, collect tickets... now imagine those ticket-redemption systems became self-sustaining communities run by YOU ‚Äì welcome to web 2.x üòé That said, if they\n",
      "Runtime: 24.93 seconds\n",
      "\n",
      "Prompt 12: What's your hottest take on decentralized finance?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 12:51:15,754 - INFO - Generated response: Decentralized Finance (aka \"adulting without humans\"): It sounds fancy because we're all secretly excited about being able to lend our own wallets instead of having actual friends who can help us pay back loans... Am I right?! üí∏ü§£#DecFin. #Bitcoin\n",
      "2024-11-19 12:51:15,754 - INFO - Entering interactive mode...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response: Decentralized Finance (aka \"adulting without humans\"): It sounds fancy because we're all secretly excited about being able to lend our own wallets instead of having actual friends who can help us pay back loans... Am I right?! üí∏ü§£#DecFin. #Bitcoin\n",
      "Runtime: 24.61 seconds\n",
      "\n",
      "=== Interactive Mode ===\n",
      "Enter your prompts (type 'quit' to exit):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your prompt:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting... Thanks for using CryptoPersonalityBot!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import Tuple, List, Dict\n",
    "import random\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Device and model configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"./fine_tuned_personality_bot/\"  # Update with your model path\n",
    "\n",
    "class PersonalityBot:\n",
    "    def __init__(self, model_path: str = MODEL_PATH):\n",
    "        self.model_path = model_path\n",
    "        self.model, self.tokenizer = self.setup_model()\n",
    "        \n",
    "    def setup_model(self) -> Tuple[AutoModelForCausalLM, AutoTokenizer]:\n",
    "        \"\"\"Initialize and configure the model and tokenizer.\"\"\"\n",
    "        logger.info(f\"Setting up model from {self.model_path}\")\n",
    "    \n",
    "        if not os.path.exists(self.model_path):\n",
    "            raise FileNotFoundError(f\"Model not found at {self.model_path}\")\n",
    "    \n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(self.model_path, use_fast=True)\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Tokenizer loading failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "        try:\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_path,\n",
    "                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "                low_cpu_mem_usage=True,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "            model.eval()\n",
    "            logger.info(\"Model setup completed successfully\")\n",
    "            return model, tokenizer\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Model loading failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def categorize_prompt(self, prompt: str) -> str:\n",
    "        \"\"\"Categorize input prompt for contextual response generation.\"\"\"\n",
    "        categories: Dict[str, List[str]] = {\n",
    "            \"market_analysis\": [\n",
    "                \"price\", \"market\", \"chart\", \"analysis\", \"trend\", \"prediction\",\n",
    "                \"bull\", \"bear\", \"trading\", \"volume\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"blockchain\", \"protocol\", \"layer\", \"scaling\", \"code\", \"development\",\n",
    "                \"smart contract\", \"gas\", \"network\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"defi\", \"yield\", \"farming\", \"liquidity\", \"stake\", \"lending\",\n",
    "                \"borrow\", \"apy\", \"tvl\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"nft\", \"art\", \"collectible\", \"mint\", \"opensea\", \"rarity\",\n",
    "                \"floor price\", \"pfp\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"community\", \"dao\", \"governance\", \"vote\", \"proposal\",\n",
    "                \"alpha\", \"degen\", \"fud\", \"fomo\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        prompt_lower = prompt.lower()\n",
    "        for category, keywords in categories.items():\n",
    "            if any(keyword in prompt_lower for keyword in keywords):\n",
    "                return category\n",
    "        return \"general\"\n",
    "\n",
    "    def generate_hook(self, category: str) -> str:\n",
    "        \"\"\"Generate category-specific attention hooks with an expanded list.\"\"\"\n",
    "        hooks = {\n",
    "            \"market_analysis\": [\n",
    "                \"Market alert:\", \"Chart check:\", \"Price watch:\",\n",
    "                \"Trading insight:\", \"Market alpha:\",\n",
    "                \"Trend spotting:\", \"Candlelight stories:\", \"RSI deep dive:\",\n",
    "                \"Volatility watch:\", \"Support level breakdown:\",\n",
    "                \"Resistance zone spotted:\", \"Market movers:\",\n",
    "                \"All eyes on the charts:\", \"Is this a bull trap?\",\n",
    "                \"Breakout or fakeout?\", \"Today's key levels:\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Tech deep dive:\", \"Builder's corner:\", \"Protocol watch:\",\n",
    "                \"Dev update:\", \"Architecture take:\",\n",
    "                \"Blockchain in focus:\", \"Gas fee breakdown:\", \"Scaling challenges:\",\n",
    "                \"Layer 2 spotlight:\", \"New upgrade analysis:\",\n",
    "                \"Consensus mechanism debate:\", \"Crypto tech wars:\",\n",
    "                \"Network optimization insights:\", \"Codebase comparison:\",\n",
    "                \"Innovator's edge:\", \"Protocol vulnerabilities exposed:\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"DeFi alpha:\", \"Yield watch:\", \"Smart money move:\",\n",
    "                \"Protocol alert:\", \"TVL update:\",\n",
    "                \"Farming frenzy:\", \"Liquidity trends:\", \"Borrowing breakdown:\",\n",
    "                \"Stakeholder spotlight:\", \"APR vs APY debate:\",\n",
    "                \"Risk-adjusted returns:\", \"What's your yield strategy?\",\n",
    "                \"Stablecoin flow insights:\", \"Vault innovations:\",\n",
    "                \"Lending protocol comparison:\", \"DeFi's next big move:\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"NFT alpha:\", \"Collection watch:\", \"Mint alert:\",\n",
    "                \"Floor check:\", \"Digital art take:\",\n",
    "                \"Art reveal:\", \"Rare trait spotted:\", \"Is this the next blue chip?\",\n",
    "                \"Profile picture wars:\", \"Who's flipping this?\",\n",
    "                \"NFT drama explained:\", \"Rarity analysis:\",\n",
    "                \"Auction insights:\", \"Utility vs hype debate:\",\n",
    "                \"Next-gen collectibles:\", \"Art meets utility:\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Culture take:\", \"DAO watch:\", \"Governance alert:\",\n",
    "                \"Community vibe:\", \"Alpha leak:\",\n",
    "                \"The crypto ethos:\", \"FOMO or FUD?\", \"Web3 lifestyle:\",\n",
    "                \"Building the future:\", \"Influencer drama explained:\",\n",
    "                \"Community-driven innovation:\", \"DAO proposal debates:\",\n",
    "                \"Web3's cultural revolution:\", \"Crypto memes decoded:\",\n",
    "                \"The rise of governance tokens:\", \"Who else is building?\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Hot take:\", \"Unpopular opinion:\", \"Plot twist:\",\n",
    "                \"Real talk:\", \"Quick thought:\",\n",
    "                \"Imagine this:\", \"What if I told you:\", \"Could this be true?\",\n",
    "                \"Something to chew on:\", \"Here‚Äôs an idea:\",\n",
    "                \"Change my mind:\", \"Big picture time:\",\n",
    "                \"Food for thought:\", \"The future is calling:\", \"What comes next?\",\n",
    "                \"Let‚Äôs break it down:\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_hooks = hooks.get(category, hooks[\"general\"])\n",
    "        return random.choice(category_hooks) if random.random() < 0.4 else \"\"\n",
    "    \n",
    "    def add_emojis(self, text: str, category: str) -> str:\n",
    "        \"\"\"Add contextual emojis based on content category, with limited frequency.\"\"\"\n",
    "        emoji_sets = {\n",
    "            \"market_analysis\": [\"üìà\", \"üìä\", \"üíπ\", \"üìâ\", \"üí∏\", \"üéØ\", \"üì±\"],\n",
    "            \"tech_discussion\": [\"‚ö°Ô∏è\", \"üîß\", \"üíª\", \"üõ†Ô∏è\", \"üî®\", \"üßÆ\", \"üîã\"],\n",
    "            \"defi\": [\"üè¶\", \"üí∞\", \"üèß\", \"üí≥\", \"üîÑ\", \"‚öñÔ∏è\", \"üé∞\"],\n",
    "            \"nft\": [\"üé®\", \"üñºÔ∏è\", \"üé≠\", \"üé™\", \"üéüÔ∏è\", \"üéÆ\", \"üÉè\"],\n",
    "            \"culture\": [\"üåê\", \"ü§ù\", \"üó£Ô∏è\", \"üé≠\", \"üé™\", \"üéØ\", \"üé≤\"],\n",
    "            \"general\": [\"üöÄ\", \"üíé\", \"üåô\", \"üî•\", \"üí°\", \"üéØ\", \"‚≠êÔ∏è\"]\n",
    "        }\n",
    "        \n",
    "        # Add emojis with 30% probability\n",
    "        if random.random() > 0.2:\n",
    "            return text\n",
    "    \n",
    "        category_emojis = emoji_sets.get(category, emoji_sets[\"general\"])\n",
    "        emoji_count = random.randint(1, 2)\n",
    "        chosen_emojis = random.sample(category_emojis, emoji_count)\n",
    "        \n",
    "        return f\"{text} {' '.join(chosen_emojis)}\"\n",
    "\n",
    "    def generate_engagement_phrase(self, category: str) -> str:\n",
    "        \"\"\"Generate contextual engagement prompts.\"\"\"\n",
    "        phrases = {\n",
    "            \"market_analysis\": [\n",
    "                \"What's your price target?\",\n",
    "                \"Bulls or bears?\",\n",
    "                \"Who's buying this dip?\",\n",
    "                \"Thoughts on this setup?\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Devs, thoughts?\",\n",
    "                \"Valid architecture?\",\n",
    "                \"Spotted any issues?\",\n",
    "                \"Who's building similar?\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"What's your yield strategy?\",\n",
    "                \"Aping in?\",\n",
    "                \"Found better rates?\",\n",
    "                \"Risk level?\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"Cope or hope?\",\n",
    "                \"Floor predictions?\",\n",
    "                \"Minting this?\",\n",
    "                \"Art or utility?\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Based or nah?\",\n",
    "                \"Who else sees this?\",\n",
    "                \"Your governance take?\",\n",
    "                \"DAO voters wya?\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Thoughts?\",\n",
    "                \"Based?\",\n",
    "                \"Who's with me?\",\n",
    "                \"Change my mind.\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_phrases = phrases.get(category, phrases[\"general\"])\n",
    "        return random.choice(category_phrases) if random.random() < 0.3 else \"\"\n",
    "\n",
    "    def add_hashtags(self, text: str, category: str) -> str:\n",
    "        \"\"\"Add relevant hashtags based on content and character limit, with limited frequency.\"\"\"\n",
    "        hashtags = {\n",
    "            \"market_analysis\": [\n",
    "                \"#CryptoTrading\", \"#TechnicalAnalysis\", \"#CryptoMarkets\",\n",
    "                \"#Trading\", \"#Charts\", \"#PriceAction\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"#Blockchain\", \"#CryptoTech\", \"#Web3Dev\", \"#DLT\",\n",
    "                \"#SmartContracts\", \"#BuilderSpace\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"#DeFi\", \"#YieldFarming\", \"#Staking\", \"#DeFiSeason\",\n",
    "                \"#PassiveIncome\", \"#DeFiYield\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"#NFTs\", \"#NFTCommunity\", \"#NFTCollector\", \"#NFTArt\",\n",
    "                \"#NFTProject\", \"#TokenizedArt\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"#CryptoCulture\", \"#DAOs\", \"#Web3\", \"#CryptoTwitter\",\n",
    "                \"#CryptoLife\", \"#BuildingWeb3\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"#Crypto\", \"#Web3\", \"#Bitcoin\", \"#Ethereum\",\n",
    "                \"#CryptoTwitter\", \"#BuildingTheFuture\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "        # Add hashtags with 40% probability\n",
    "        if random.random() > 0.2:\n",
    "            return text\n",
    "    \n",
    "        remaining_chars = 280 - len(text)\n",
    "        if remaining_chars < 15:  # Not enough space for hashtags\n",
    "            return text\n",
    "    \n",
    "        category_hashtags = hashtags.get(category, hashtags[\"general\"])\n",
    "        selected_hashtags = []\n",
    "        \n",
    "        # Add 1-2 hashtags while respecting character limit\n",
    "        for _ in range(random.randint(1, 2)):\n",
    "            if not category_hashtags or remaining_chars < 15:\n",
    "                break\n",
    "            hashtag = random.choice(category_hashtags)\n",
    "            if len(hashtag) + 1 <= remaining_chars:\n",
    "                selected_hashtags.append(hashtag)\n",
    "                category_hashtags.remove(hashtag)\n",
    "                remaining_chars -= len(hashtag) + 1\n",
    "    \n",
    "        return f\"{text} {' '.join(selected_hashtags)}\"\n",
    "    \n",
    "    def clean_response(self, text: str, category: str) -> str:\n",
    "        \"\"\"Clean and format the response for Twitter.\"\"\"\n",
    "        # Remove URLs and excessive whitespace\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "        # Remove leading and trailing quotation marks\n",
    "        text = text.strip('\"\\'‚Äú‚Äù')\n",
    "    \n",
    "        # Ensure the text ends with proper punctuation\n",
    "        if text and text[-1] not in '.!?':\n",
    "            text += '.'\n",
    "    \n",
    "        return text\n",
    "\n",
    "\n",
    "    def get_fallback(self, category: str) -> str:\n",
    "        \"\"\"Generate category-specific fallback responses.\"\"\"\n",
    "        fallbacks = {\n",
    "            \"market_analysis\": [\n",
    "                \"Charts looking juicy today! Anyone else seeing this setup? üìà\",\n",
    "                \"Market's giving mixed signals but the volume tells a different story üëÄ\"\n",
    "            ],\n",
    "            \"tech_discussion\": [\n",
    "                \"Sometimes the best protocols are the ones no one's talking about yet üõ†Ô∏è\",\n",
    "                \"Imagine still building without considering Layer 2 scaling üíª\"\n",
    "            ],\n",
    "            \"defi\": [\n",
    "                \"Your yields are only as good as your risk management üè¶\",\n",
    "                \"DeFi summer never ended, we just got better at farming üåæ\"\n",
    "            ],\n",
    "            \"nft\": [\n",
    "                \"Art is subjective, but floor prices aren't üé®\",\n",
    "                \"Your NFT portfolio tells a story. Make it a good one üñºÔ∏è\"\n",
    "            ],\n",
    "            \"culture\": [\n",
    "                \"Web3 culture is what we make it. Build accordingly üåê\",\n",
    "                \"Sometimes the real alpha is the friends we made along the way ü§ù\"\n",
    "            ],\n",
    "            \"general\": [\n",
    "                \"Just caught myself thinking about the future of crypto while making coffee ‚òïÔ∏è\",\n",
    "                \"Your portfolio is only as strong as your conviction üíé\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        category_fallbacks = fallbacks.get(category, fallbacks[\"general\"])\n",
    "        return random.choice(category_fallbacks)\n",
    "\n",
    "    def filter_tone(self, response: str) -> str:\n",
    "        \"\"\"Filter response tone and adjust if needed.\"\"\"\n",
    "        sentiment = TextBlob(response).sentiment\n",
    "        \n",
    "        if sentiment.polarity < -0.3:\n",
    "            return self.get_fallback(\"general\")\n",
    "        \n",
    "        if sentiment.subjectivity > 0.8:\n",
    "            # Too subjective, add a disclaimer\n",
    "            return f\"Not financial advice but... {response}\"\n",
    "                \n",
    "        return response\n",
    "\n",
    "    def generate_response(self, prompt: str) -> str:\n",
    "        \"\"\"Generate a complete Twitter-ready response.\"\"\"\n",
    "        category = self.categorize_prompt(prompt)\n",
    "    \n",
    "        instruction = (\n",
    "            \"You are a crypto and finance expert with a sharp sense of humor, blending the witty sarcasm of George Hotz with the storytelling flair of Theo Von. \"\n",
    "            \"Your goal is to craft engaging, funny, and insightful tweets that educate your audience using appropriate slang and jargon. \"\n",
    "            \"Each tweet should be coherent, make logical sense, and provide a clear takeaway or punchline. \"\n",
    "            \"Avoid overusing slang‚Äîuse it where it feels natural. \"\n",
    "            \"Respond to the following prompt:\\n\\n\"\n",
    "        )\n",
    "    \n",
    "        examples = (\n",
    "            \"Prompt: What's your take on Bitcoin as digital gold?\\n\"\n",
    "            \"Tweet: Bitcoin as digital gold? Nah, it's more like digital real estate in the metaverse‚Äîexcept everyone's still arguing over the property lines. Who's still buying up the neighborhood? üöÄ #Bitcoin #Crypto\\n\\n\"\n",
    "            \"Prompt: Explain staking in the context of DeFi but make it funny.\\n\"\n",
    "            \"Tweet: Staking in DeFi is like putting your money on a treadmill‚Äîyou lock it up, it works out, and somehow you end up with more than just sweaty tokens. Gains on gains! üèãÔ∏è‚Äç‚ôÇÔ∏è #DeFi #Staking\\n\\n\"\n",
    "        )\n",
    "    \n",
    "        context = f\"{instruction}{examples}Prompt: {prompt}\\nTweet:\"\n",
    "    \n",
    "        inputs = self.tokenizer(\n",
    "            context,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=1024  # Increased to accommodate longer context\n",
    "        ).to(device)\n",
    "    \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=80,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.7,\n",
    "                    top_k=50,\n",
    "                    top_p=0.9,\n",
    "                    repetition_penalty=1.5,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    eos_token_id=self.tokenizer.eos_token_id,\n",
    "                )\n",
    "    \n",
    "            generated_text = self.tokenizer.decode(\n",
    "                outputs[0],\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "    \n",
    "            # Extract the tweet from the generated text\n",
    "            response = generated_text.split(\"Tweet:\")[-1].strip().split(\"\\n\")[0]\n",
    "    \n",
    "            if not response or len(response) < 20:\n",
    "                return self.get_fallback(category)\n",
    "    \n",
    "            # Apply enhancements\n",
    "            response = self.clean_response(response, category)\n",
    "            response = self.filter_tone(response)\n",
    "            response = self.add_emojis(response, category)\n",
    "            response = self.add_hashtags(response, category)\n",
    "    \n",
    "            logger.info(f\"Generated response: {response}\")\n",
    "    \n",
    "            return response[:280]  # Ensure the response fits within Twitter's character limit\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating response: {str(e)}\")\n",
    "            return self.get_fallback(category)\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        bot = PersonalityBot()\n",
    "        logger.info(\"Bot initialized successfully\")\n",
    "        \n",
    "        # Test prompts\n",
    "        test_prompts = [\n",
    "            \"How do gas fees compare between Ethereum and Solana?\",\n",
    "            \"Tell me why NFTs are either a scam or the future.\",\n",
    "            \"What's your take on Bitcoin as digital gold?\",\n",
    "            \"Explain staking in the context of DeFi but make it funny.\",\n",
    "            \"Give me a wild prediction for crypto in 2030.\",\n",
    "            \"What's a DAO, and should I care?\",\n",
    "            \"Can you explain why everyone's obsessed with Layer 2 solutions?\",\n",
    "            \"What's the wildest crypto meme you've seen this week?\",\n",
    "            \"How do I avoid FOMO during bull runs?\",\n",
    "            \"Is it too late to get into crypto? Be honest!\",\n",
    "            \"How would you describe Web3 to someone who barely uses the internet?\",\n",
    "            \"What's your hottest take on decentralized finance?\"\n",
    "        ]\n",
    "        \n",
    "        # Test run with basic prompts\n",
    "        logger.info(\"Starting test run with sample prompts...\")\n",
    "        print(\"\\n=== Test Run with Sample Prompts ===\")\n",
    "        for i, prompt in enumerate(test_prompts, 1):\n",
    "            print(f\"\\nPrompt {i}: {prompt}\")\n",
    "            start_time = time.time()\n",
    "            response = bot.generate_response(prompt)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(\"\")\n",
    "            print(f\"Response: {response}\")\n",
    "            print(f\"Runtime: {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        # Interactive mode\n",
    "        logger.info(\"Entering interactive mode...\")\n",
    "        print(\"\\n=== Interactive Mode ===\")\n",
    "        print(\"Enter your prompts (type 'quit' to exit):\")\n",
    "        \n",
    "        while True:\n",
    "            user_prompt = input(\"\\nYour prompt: \").strip()\n",
    "            if user_prompt.lower() == 'quit':\n",
    "                print(\"Exiting... Thanks for using CryptoPersonalityBot!\")\n",
    "                break\n",
    "            if not user_prompt:\n",
    "                print(\"Please enter a valid prompt!\")\n",
    "                continue\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                response = bot.generate_response(user_prompt)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"Response: {response}\")\n",
    "                print(f\"Runtime: {elapsed_time:.2f} seconds\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing prompt: {str(e)}\")\n",
    "                print(\"Oops! Something went wrong. Please try again.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Application error: {str(e)}\")\n",
    "        print(\"Critical error occurred. Please check the logs for details.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f1b51c-3aa0-4462-bc1b-b62591877b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c282f8-bd8b-419f-a632-e5bb1f75d447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690f0d1-1764-4d95-b503-6628527c57fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b960d-1803-458f-9385-3f3dfebceeba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tbot)",
   "language": "python",
   "name": "tbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
